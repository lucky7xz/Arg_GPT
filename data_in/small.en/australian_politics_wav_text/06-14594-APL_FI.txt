 For social media, you can introduce inauthentic, deceptive, covert voices whose goal isn't to improve the quality of public debate in Australia. It's actually to degrade it. That's what we're seeing all around the world. And Australia would be pretty naive to think that we weren't a target of that sort of intervention. Well, hello, everybody, and welcome to another episode of Australian Politics Live. You are with Catherine Murphy, political editor of Guardian Australia. And this week in the Pod Cave, I am joined by two lovely Labour folks, Jenny McAllister. Hello. And Tim Watts. Great to be back with you. Now, the reason these guys are in the studio is Jenny is a Labour senator who is chairing the Select Committee on Foreign Interference through Social Media. And that's basically what we're here to discuss today. Tim is the Shadow Assistant Minister for Cybersecurity, so has a very close interest in these issues and also gave a very interesting lecture to the Lowy Institute last week sort of touching on some of the themes around this issue. And I want to get to that in the conversation. But I'm going to start with Jenny, who's running this inquiry. So let's just start the story at the beginning. Why are we having this inquiry? Why are we concerned about foreign interference through social media? Well, fundamentally, this is no less than a question about our way of life. Australia fundamentally defines itself as a democracy. It's part of our origin story. We were one of the earliest adopters of universal suffrage. The way we balloted and had elections was known around the world as the Australian ballot. It's a really big part of how we live and how we think about ourselves. And it's dependent on having a really robust public debate that involves civil society, media, citizens, parliamentarians. But that feature of our country is increasingly being identified by foreign actors as a vulnerability. I should say, I think they also identify it as a strength. And this is one of the things Tim's been talking about. But it also introduces vulnerabilities. Principally, that through social media, you can introduce inauthentic, deceptive, covert voices whose goal isn't to improve the quality of public debate in Australia. It's actually to degrade it. And that's what we're seeing all around the world. Australia would be pretty naive to think that we weren't a target of that sort of intervention. And the Senate inquiry is really about starting a national public conversation about the problem and providing a forum in which we can get all of those actors that I mentioned early into that conversation. Yeah. Well, this is why I've brought you on because I think this is a critically important issue. And I want to help you try and raise consciousness about it. And I'm sure listeners will have all sorts of thoughts and views about it. Just ask an obvious question, right? The concept of interference by foreign actors in other countries is not new or novel. It was a feature of the Cold War, anybody who's kind of read a Lekare novel or watched the Americans understands that there is foreign interference in other countries. So what are we worried about right now? What's the issue right now, Tim? Well, Catherine, you're right to say that foreign interference isn't a new thing. Indeed, there are some people that argue that the protocols of the elders of Zion was information operation by the czar of Russia to justify pogroms against the Jews then. And we've seen a series of information campaigns from the former Soviet Union against the Americans on the HIV crisis, on the drug epidemic in the US. So in that respect, it's not new. What is new now is the kind of merging of media systems that we're seeing. We're sort of stuck in one big media ecosystem with each other and these authoritarian nations. So nicely put. You know, some of the company on Twitter is peculiar to say the least. But I mean, so these authoritarian countries have been playing these information warfare games for a very long time. And it turns out they're pretty good at them. So when they come into contact with our open media system, our open democracy, we've seen them have some pretty significant success. I mean, the 2016 US presidential election, I assume, succeeded beyond the wildest expectations of the Russian intelligence agents that were driving it. But they were effectively able to disrupt a presidential election and really degrade the ability of the American political system to reach that kind of consensus you need to act to make decisions together as a country. Yeah, I'm glad you raised that, Jenny, because that sort of example, which I think would be familiar to most people listening and listening in. So the Russian interference in the presidential election in the States, even though there had been obviously discussion about it amongst security agencies and amongst the sort of intelligence community and on foreign policy blogs and all sorts of places. It seems to me, though, that that sort of interference operation kind of crept up on one of the greatest democracies in the world. And it is it's kind of worth talking through some of the examples because they make tangible what otherwise sounds like a pretty abstract idea. So in one of the most important of the Russian operations in that election, they basically sought to leverage existing community campaigns around Black Lives Matter. And so that's a really important community campaign about the relationship between African Americans and the police in the United States fundamentally. But what the Russians worked out was that it was also a very divisive issue. And they essentially sought to leverage the existing campaign. They sought to go and essentially scoop up all of the people who'd associated themselves with the official Black Lives Matter campaign. And they drove them onto specialist sites that they'd created themselves. And the most prominent of those was one called Blacktivist. It accumulated more than 500,000 followers. I think it was something in the order of 11 million engagements over the course of the election. And in the first instance, the objective, it seems, was to drive distrust and discord at a community level between citizens and between citizens and institutions like the police force. It was also sought to discredit the movement and to create content that the official Black Lives Matter campaign wouldn't have created. But its ultimate goal was a voter suppression effort. And ultimately, the relationship that these false, deceptive, misleading participants in the US political system, what they managed to do with those relationships was encourage people to stay home. And how did that happen? What were the messaging? Was it that you can't trust the system, you shouldn't participate in the system? Is that the essence of it? It's not worth engaging with the Democrats. It's not worth supporting Democratic candidates because they're not truly committed to your cause. And it's sort of extraordinary that that could happen in plain sight with nobody noticing. One of the interesting things from my perspective on this, Catherine, is that I sort of come from a technology background. So the conversation that I have online is with technologists and people working in this sector. And I can tell you, leading up to the 2016 election, these issues were being widely discussed in the technology sector. People knew exactly what was going on. And indeed, there were warnings from the US government before it happened. But it didn't really register with the mainstream consciousness. I think this is a really important part of the Senate inquiry that Jenny's leading. And that's why this inquiry is going to run for two years. It's an open-ended inquiry because that educative function, not rushing to policy solutions, but first having the conversation with the Australian public, is one of the most important things that needs to happen here, taking that technology, that national security discussion, and bringing it into the mainstream. Is there any evidence of interference in the Australian political system at this point? Look, what I'd say to that is that we have been affected by spillovers from international disinformation campaigns. So I'm a technologist. I work in the telco space. And one of the ones that has been identified by researchers in the UK is an international campaign around 5G. So there's a Stop 5G campaign. There are hundreds of pages and groups sort of pushing misinformation about the health risks supposedly associated with this technology. And on one particular week, all of these groups and pages across multiple social media platforms all increase their membership tenfold. You know, it's not an organic growth. Something happened that sort of in a coordinated way ticked that over. And that's a spillover that we see here. I should say that campaign hasn't been attributed to any country, but it does have a very strong echo to the misinformation campaign that's being run on Russian state outlets like RT. So we can infer potentially who is behind that. And is Australia the target of that? Probably not. It seems that defence analysts suggest that the objective of that campaign is sort of sabotaging industrial progress in the West. And we are sort of a peripheral victim of that. But we shouldn't kid ourselves. I mean, that the day will come when there is an attack that is targeted specifically at Australia. So Facebook is now publishing on a monthly basis reports and what it calls coordinated inauthentic behaviour. Yes, I'm aware of that. Torturous, torturous description for this. But you know, there are more than 100 of those networks taken down over the last year. And the first report that came out just this week had about half a dozen campaigns and they were weird and wonderful. They're in India, Vietnam, Myanmar. There's Qatari involvement, the US, UK. And these aren't all foreign intelligence agencies leading this. Sometimes governments contract this to PR firms. There are all kinds of objectives, all kinds of countries that are facing this challenge. And it will happen in Australia. Jenny? And the big risk is, Tim's right, that there's very diverse near term objectives. But the common thread that links it all often is the creation of uncertainty about truth, mistrust in official institutions and often division between citizens. And it is weird and wonderful stuff like the measles anti-vaxxer campaign is an interesting example. It's been assessed that Russian accounts were significantly more likely to be tweeting anti-vaxx messages or pro-vaxx messages in the US in a window between 2014 and 2017. Why would the Russians want to get into anti-vaxx campaigns, right? Why would that be a thing? Well, because ultimately the objective seems to be about encouraging people to distrust formal scientific or medical advice. In that respect, one of the most delightful books I've read recently, because it hits this on the head, the description of what's going on, is a book by a bloke called Peter Pomeransev, who worked as a propagandist in Russia. He has UK citizenship as well. And he titled that book to try and describe this Russian strategy as nothing is true and everything is possible. That's kind of that underlying thread that Jenny's talking about. But what's the end game? I get why creating a national crisis of confidence in America is beneficial to Russia strategically. I sort of get it at a high level, but where I struggle with this is what is the specific end game? Does Russia think that if citizens in America or citizens in Australia become so distrustful of democracies that other sort of systems, other alternatives will flourish? Or what do you think about this? I speculate that it's in part about domestic politics. So it runs in the other direction. In fact, if citizens in your own authoritarian country see dysfunctional problems in democratic countries. I see. What do you think about this in terms of your domestic objectives of hanging onto power or whatever? And that there were specific objectives the Russians had in 2016 around sanctions that the Obama administration had imposed on Russian individuals. I mean, because of the diverse motivations, there are diverse end goals. We've seen some campaigns that seem very closely associated with particular mining interests in Africa, for example, stopping government interventions around that. We've seen a series of campaigns trying to muddy the water around human rights discourses around what's really going on in particular regions of the world. That's another really common one. So the motivations are very diverse. I should say that we've been talking so far about misinformation, about sort of astroturfing, about projecting stuff out there. There's another thing that I've been thinking about a lot recently, and that's what are the rules of the road on these platforms? We're used to using these social media platforms that come from the US that share that kind of open democratic system. But increasingly, we're seeing platforms that are founded in authoritarian countries with different values to ours and with different approaches to managing information systems. And one of the questions that I'm sort of pondering is, do those platforms raise different questions? So if they're imposing censorship on political grounds of Australians using that platform in Australia, is that something that we should be concerned about? These aren't niche platforms. These are platforms with millions of users in Australia. And if you're sort of putting your thumb on the scale about what is and isn't allowed to be discussed on those platforms, I think that raises questions about democratic legitimacy of our public sphere as well. And will the inquiry go there, Jenny, in terms of where you're planning on turning our spotlight? Yes. So I think we're very interested in the misinformation campaigns that are conducted on the big platforms. And I think we'd hope that we'd have evidence from the Facebooks and the Twitters and the Instas that would come and talk to us about how they're approaching the problem. It'd be good to hear from some of the other platforms, like WeChat, like TikTok, who have big presence in Australia, but of course originate out of China and hear about how they think about these questions and what their governance arrangements are around how they use their platforms and how they allow information to be disseminated on their platforms. Yeah, because we've talked a bit, well, quite a bit actually over the last few minutes about Russia. I read a paper by the Australian Strategic Policy Institute around these issues and it identified Russia and China as the primary actors in foreign interference campaign or disruption campaigns. What about China? We don't see as much public analysis. The best documented examples are the Russian examples in the United States. And it's because Congress took such an interest in it. And it is in fact to the credit of in particular the intelligence oversight bodies in Congress and intelligence agencies in the United States that they made a decision, I think, to pursue things, document them and make what they could public. We don't know as much about some of the other regimes in our region and we're often left to organizations like, I think, tanks like ASPE, other kinds of analytics processes to get a glimpse of what's going on. I think we're a bit less clear about how the PRC might engage in our region, although obviously there was some speculation about PRC's interest in the Hong Kong uprising or in the elections in Taiwan. Yeah, I mean, transparency is a big sort of thing I think we're looking for here. There have been leaks and there's been sort of speculation and there's been inference about what might be going on in these platforms. And we've seen widespread reporting of the censorship of TikTok videos about human rights abuses against Uyghurs in Xinjiang. We've seen leaks of their content moderation policies that are much broader than anything that we would in the West view as things that you ought to be censoring. I mean, these are censoring political topics. Now, subsequently, they've said, well, that was all a mistake and now we're doing it differently. And they may well be. I don't know. I don't have any special insight there, but transparency is something that would be helpful here in understanding that. Same issue with WeChat. Classically, there's been a difference in the way that WeChat has been administered if you have an account registered in China or an account registered outside of China. So there's very heavy censorship on accounts registered in China. Messages will just be disappeared. And if you do too many disappearing messages, your account can be suspended and canceled. That hasn't been happening to the same extent internationally. Although there have been some reports, again, unconfirmed, we'd like to see some transparency, that this has been happening a little bit in response to the coronavirus, that messaging in the West has prompted the suspension of accounts in the West. Again, I'm not certain that that's happening. This has been reported in the media. But some transparency to understand, well, how do these platforms operate, I think would be helpful. What do you think, Jenny, about the attitude of the platforms? Certainly, there were many instances in the election, some of which I've documented. And this is sort of in the domestic sphere rather than in foreign interference, but the whole death tax falsehoods that were circulating during the election. Facebook says repeatedly, we don't want to be arbiters or censors of political discussion. Hashtag free speech. What do you think about their attitudes or their resting disposition to responsibility in this conversation? I realize we're talking about something bigger than the platforms here, but what do you think about them and their posture? I think that their posture is in a state of change. So I think that in the period, particularly after the 2016 election, the magnitude of the capacity for influence on their platforms has become apparent. And I do think that they are two different degrees starting to grapple with what those responsibilities mean. Tim pointed to transparency as one feature of a desirable response from platforms wherever they originate. I think another emerging idea is around their willingness to take input from civil society, essentially to acknowledge that there are drivers and obligations beyond their own corporate drivers that ought to shape how they respond to these problems. I think Facebook deciding to have a governance council, for example, is an interesting response and an attempt to remedy what is essentially a kind of democratic deficit in the way this incredibly important platform is operating. What do you think? I think that's a spot on observation. As someone who's been engaging in a policy sense with Facebook since its inception in Australia, they've come a long way, I mean, they used to be of the view, nothing to do with us. We're just a platform and go for your life. And they're increasingly changing that. So they'll stop anti-vaxxer ads now. After the Christchurch attacks, they finally made the decision to ban white supremacist, white nationalist material from the platform. And I think that has made a material difference. So they are getting involved in the content that they're distributing on their platform. But it's still early days. I mean, one of the things that interests me in this space is how we grapple with policies for advertising. So at the moment, there are different advertising policies on all the platforms between Twitter, Facebook, Instagram, the related platforms. But one of the things we're seeing in the US is this kind of industrial scale division of society, like breaking society down into segments of sometimes like a dozen or so people really micro-targeting and finding what's the one bias in this tiny, tiny, tiny little group that we can tweak their tail on. And then you automate that. You see tens of thousands of ads targeting tiny little groups and testing to see whether they work, whether they push their buttons or not, if they don't work substituting something else in. And that becomes this industrial scale division of our society. And Alex Stamos, who is the former security director at Facebook, he's now at the Internet Observatory at Stanford. He said that this is the thing that worries him the most because he says that once you have these 10,000 different messages going to 10,000 different groups, how can a civil society possibly hope to fact check that? Yes. It's beyond the scale and beyond the ability of any of us. So how do we grapple with that, I think is a really important question for civil society and democracy more broadly. And potentially for this inquiry, how do we grapple with it, Jenny? I know this is like massively kept before the horse. Well, I think here are some domains where you might go looking for answers because it's very unlikely that there's a single answer. So the first of which we've been talking about now, it's how the platforms manage the content on their platforms. They've started down a path, which is essentially a procedural one where they see coordinated behavior and it is inauthentic. Then they'll take networks down. And so they're looking, I think, at questions of scale and impact as well as content. And it remains to be seen how effective that is. Yeah. I mean, the second domain where we might go looking are legal answers. We've had a whole range of new laws introduced in the last two years, which seek to curb more traditional forms of foreign interference in a society and labor supported those. We thought that was an important step, but it probably didn't grapple with these more diffuse forms of influence where you're seeking to influence a lot of people just a tiny little bit. Maybe there are legal responses that need to be examined. But the final area is just citizen capability. We need a civil society that has a free and active media, strong community groups that are capable of having their voices heard, including through protests on occasion. We need individual citizens feeling that they can participate not just in elections, but in politics more broadly. And we kind of need a conversation between all of those institutions that's not hobbled by unnecessary tribalism. And I think talking with civil society through the inquiry process and with other parliamentarians about that final bundle of objectives might be a really useful field of inquiry. These campaigns exploit underlying problems of our democracy. So fixing the platform sitting on top of those underlying problems won't fix those underlying problems. And the way you can appreciate this is to look at the misinformation problems that we see in authoritarian countries. And we've seen this writ large in the coronavirus. In authoritarian countries, when you know that there aren't checks and balances, when you know that there's not accountability. Or just at a simpler level, where you know that the official version of events, whatever that has to be, is entirely untrustworthy. Exactly. So citizens then learn to sort of triangulate truth by listening to every rumor going along. And it's this sort of institutional collapse of trust. And so that the misinformation problem is vastly larger in authoritarian countries than the disinformation problem that we're facing here. So initiatives to restore public trust are things that I really believe in like fundamental democratic renewal. And I was really pleased that that's like a big priority for Anthony Albanese, one of his first vision statements, because I think it's vastly overdue in this country. I totally agree. I think the only way to sort of fix the institution is to fix the institution. But I reckon there's another challenge though. And that is just that general level of consciousness raising that I think even still there would be a lot of people out in the community who do not necessarily understand that some of the stuff they see on social media, be it anti-vaxxer material or other other forms of misinformation or disinformation are not things that are just happening organically, right? It's not your neighbor down the road who has a view. It's an orchestrated campaign of destabilization, particularly low information voters, people who are not very connected with democratic discussion or civil society discussion. I'm not meaning to be patronizing about this in any shape or form, but I just think there are people out there who wouldn't actually understand necessarily because this conversation that we're having here has not necessarily reached them that what they're looking at is not what it appears to be. I think you're right that the conversation needs to reach a lot more people. Let's agree that as the starting point. I do think that there's a role for citizens in taking responsibility for how they assess and view information, but it's very unlikely citizens can achieve this by themselves. If you think about all of the other institutions that might play a role, you know, government, national intelligence, community platforms, civil society groups, parliamentarians, there's a lot of people who are in a position to support citizens to make good judgments. I think what we're looking for is, I guess, some new agreement amongst ourselves about how best to provide that support because I think it's very unlikely that citizens, the odds are stacked against them. We need to provide some scaffolding and some support for people to be able to make those assessments. Citizens are potentially a really powerful part of the solution. The way I sort of conceptualize that is if you think of sharing crap online as polluting our information system, polluting our public sphere, you could view it as analogous to like littering in the physical environment. If you saw someone throw a Coke can on the street, walking down the street, you'd tat them, you know, you'd say, oi. It's a consequence of the Tidy Towns campaign. And it's a consequence, well, it is actually. Well, consciousness is generally. It's everything that creates that norm of behavior. And I think we're grappling with this new technology and we're trying to discover what are the norms of behavior in this new world we are, like what is expected of me as a citizen. I think like just an expectation of not sharing crap on the Internet. It's pretty good norm to start with. Well, it is a good norm, but I'm even a step back from that. And that's recognizing that it's crap, right? Actually understanding. I mean, obviously we all recognize crap, but that all propositions that are floating around there out on the platforms are not inherently equal. That, you know, some is genuine information, some is active misinformation. I hesitate before saying this because I feel like implicit in my observations is that I think people are dumb, which I really don't think people are dumb in any shape or form. But it's just I'm very conscious that the three of us are having a very privileged conversation in terms of information, right? We have a lot of information in front of us and not everybody has the same level of information. Here's a way of thinking about that proposition. You know, people are not dumb. People are used to working in a political environment where most of the actors were acting in good faith. I might not agree with what George Christensen thinks about the world. I'm reasonably confident he's acting in good faith, the war that Tony Abbott is acting in good faith. They've got different views about what the future might look like, not the same as my view, but they're participating in good faith. That's not true of these other actors. Their goal isn't to strengthen our democracy or to strengthen the tenor of our public debate or improve our capacity to make decisions. It's actually their goal is to degrade that capability. Yeah, yeah, yeah. And it's not just, oh, well, look, there's an interesting thing that I saw on the internet. It's like malign information. And it's not surprising that citizens aren't alert to that possibility right now. It's really a relatively new feature of our environment. At least having it at scale is a relatively new feature of our environment. And we're going to have to get used to it. We need a big public conversation about those risks and ways to respond to it. Well, even just listening to you now, Jeannie, I feel like I'm learning and being educated. You're persuading me as I'm listening. So it's a worthwhile conversation to have. Just one last question. Do you think, both of you are obviously members of a major political party, do you think that your own political organisation and political organisations in Australia are sufficiently concerned about this as a real life threat proposition? Yeah, I do. They're nodding, guys. Yeah, nodding doesn't show up on radio. No, it doesn't. No. I mean, I think we initiated this inquiry for a reason, and it received bipartisan support in the Senate. My expectation is that coalition colleagues will be interested in pursuing these ideas and running down some of the solutions to an end point. I think everyone recognises it's a newish problem. It's a greenfield site. We have to stand up some new architecture to deal with a new challenge. No one's got a monopoly on the answers just yet. Tim's nodding here, Grace. We will be following this inquiry closely on Guardian Australia over the next couple of years, so obviously stay tuned to the reporting. You can track down the Senate inquiry very easily on the parliamentary webpage. You can keep an eye on submissions that are going on if you've got an interest. There'll be lots of material that you can read and chew over and think about. Obviously, get in touch with these guys, they are very present on social media and other platforms if you've got any thoughts about it. Thank you from my perspective as always to my executive producer, Miles Martagnone, to Hannah Isard for services to editing this show. We will be back again next week with whatever big issue we wanted to over next week. Next one. Yes. Thank you.