 The pandemic has created a kind of existential crisis, a political crisis for the Chinese Communist Party regime in the People's Republic of China. And they have responded by launching waves of disinformation intermingled with diplomatic and state media messaging. And that's quite, that's quite easy to call out. But in the work that we've been doing over the last few weeks, in fact, is to identify that they have actually been running really large scale influence operations on social media platforms to amplify that diplomatic and state media messaging. Well, hello, lovely people of podcasts and welcome back to the show. It's Catherine Murphy with you, political editor of Guardian Australia and you are on the show Australian Politics Live. Now this week, I have two chaps in the pod cave with me. They're looking really worried now. With me, I have Jake Wallace and Tommy Wren. These fellows are senior analysts at the Australian Strategic Policy Institute. And they basically research all kinds of stuff really, but they research disinformation, which is what we're going to focus on in this episode. Now, regular listeners of the pod will may remember that last year I spoke to Jenny McAllister and Tim Watts because the parliament has embarked upon an inquiry into disinformation or foreign interference, basically, and disinformation through social media. I said to you guys last year, I think this is a really critically important inquiry that I would be following closely and that inquiry had its first public hearings this week. And these guys were one of many witnesses at the inquiry this week and raised some really interesting evidence about what's going on in the information environment. And so I thought it would be a good idea to bring them in and we could talk through it in some depth, given that not all tragics like me are watching Senate committees at all hours of the day and the time. So that's why Jake and Tommy here. Now, without further ado, I'll just set up the conversation by referring to a submission that you guys shared with the Senate inquiry. Now in that submission, you referenced some work you did about disinformation or interference operations during the last federal election. So I want to unpack that a bit because people listening may not even be aware that any of that stuff went on. So, whomever wants to start, start. What went on? What went on? Sure. So we should ensure that the credit goes to the right people, Catherine. We were noting an excellent ABC investigation that had identified that financially motivated actors from Eastern Europe, places like Kosovo, Albania, and the Republic of North Macedonia, targeted the heightened political sentiment and engagement that occurs during an election cycle and then targeted, specifically targeted the Australian federal election back in 2019. Now, it's important to note the diversity of motivations that can drive these kinds of operations. In this instance, we know that they were financially motivated. They were managing Australian audiences to engage with Islamophobic content in large Facebook groups. They were then injecting URLs, websites into those Facebook groups that could harvest audience out of the platform to content farms that would serve up advertising. And those each hit of advertising generates revenue for those actors. So for these kind of scammers that are at the base of the digital economy, that's a reasonable income depending on where you are in the world. But what's really interesting here is that the political sentiment that we experienced during an election is now a business model for financially motivated actors as well as all of the other players that may have other interests. And so why is that? Like we shouldn't assume people know what we're talking about. I think obviously, big, intense, all in conversation as occurs on social platforms during elections would be a magnet for this sort of activity because everybody knows people are heightened. They're engaging massively with one another in, according to their core beliefs and values and all of that sort of stuff. So is it just that that you mean that that provides a sort of convenient backdrop for creams and scammers and people of ill intent to sort of see what they can do during an election cycle? Yeah, that's right. You've got a number of factors there that are of interest and for those that are driving this kind of model. And it happens on all sorts of kind of topical discussions on social media. But during an election, you've got large audiences that are engaging on social media. And that's part of the fabric of political discourse in a 21st century democracy. But we also have that large scale engagement in combination with heightened political sentiment. A lot of what you find with a lot of disinformation actors, whether they're state or non-state, they're running on emotion. They want to manipulate people's emotions because that's what drives engagement online. So as much as we like the idea of political discourse is somewhat rational. It's an erudage. Yeah. It's not always the case. And they know that if they can inject content that is kind of volatile and drives emotional engagement, then people are going to click through. And that's what drives the next stage of the operation, which is that kind of our generated financial motivation. Yeah. Well, it's sort of like I'm conscious of this myself as a journalist and a digital journalist that emotion is the currency of the internet, right? Like that's the sort of foundational currency of the internet. So where there is emotional heightened sensibilities, you're going to see some of these sorts of activities. So you said like they're basically appearing on platforms, engaging discussions that are happening or organically sort of pushing them in particular directions and then hoping you might click through onto their revenue generating website. Is that basically it? That's right. That's the model. And we've seen it replicated in an investigation by the Guardian in fact, who identified it as really driven operation that used pretty much the same model. This was in Israel. That's right. Yeah. Nationalistic content, Islamic phobic content to drive engagement and get click throughs to content forms. So we know that political discourse itself is being targeted by a spectrum of actors, obviously famously in the US presidential election by a state sponsored operation by Russia. But there are a spectrum of actors that will engage in these kinds of practices now. And so the point being, you know, maybe Tom, a lot of people in Australia might think, yeah, well that happened in America. Obviously I've read about that or I've seen it on TV or whatever, but they may be unaware that similar things are happening in Australia. I'm not suggesting on the same scale as occurred in the presidential election, but people may not necessarily be aware of what's going on. I think there's elections as a point in time and they generate a lot of interest in the people who are, you know, harvesting these audiences, but they're also generate a lot of attention from government and also from journalists. So we tend to see the stories that are focused around elections and we, you know, they're a natural point to narrow in on, but it actually occurs all the time, all the time. So those groups that are harvesting, you know, xenophobic sentiment, they do it all the time. Elections just happen to be a time where they can do better. Profit, more. Yeah, more. And they're the time when we discover them because journalists focus in at that time. And so a xenophobic group on Facebook now is not such a news story as one around an election. Yes. Yeah, I see what you mean. So it gets, yeah, there's more eyes looking at what's going on and why and trying to pull that apart. So we've identified in the Australian context people with commercial motivations, but the focus of the Senate hearing this week was predominantly really about overseas actors, so state actors and what interests they may have in the Australian political domain, which is of course the focus of the hearing. So we're meeting at a time everybody knows we're in the middle of a, well, who knows if we're in the middle of it, COVID. I mean, God knows. Yeah, so one of the interesting things about the committee was there is this focus on foreign interference, but it came out during the committee that most of the actors that are actually fully invested in Australian politics are actually Australian. But it becomes a much harder conversation to have about how do you, well, what do you even do about that? About, yes, about local disinformation, deliberate political disinformation and other disinformation. Yeah, and I guess perhaps anti-vaxxers fall into that category, racist groups within Australia, extremists on both sides. Politicians sometimes. No comment. They're both gulping deeply, the sort of being so rude, imagine being so rude. But obviously, politicians and political groups are also part of the story in terms of disinformation and disinformation activity online, let's be honest. It's an interesting question where to draw the boundary. The other interesting kind of boundary related issue is, can we separate off Australian political discourse on a medium that is networked, where geographic boundaries don't essentially exist and discussions flow across networks that are international? So it's really hard to delineate what constitutes interference in Australian political discourse or influence, because the government's line obviously is that influence is good. We influence other governments and that's reasonable, but where it becomes problematic is when it becomes coercive or deceptive, and then it becomes interference. There's so many gray areas here that we have to make real time decisions on if we want to effectively mitigate the risk of serious interference by a state actor. It's a really challenging space. So I can see why it's problematic for the platforms, who often the frontline for these kinds of operations, the co-face at which this state-sponsored and financially motivated activity is happening. And then governments are a layer on top of that. So how does everybody ensure that we're reasonably representing the best interests of the Australian public within this problem set? Yeah, we'll get to solutions or ideas for solutions in a little bit. But that's sort of touched down. Obviously, we are in the COVID environment. A lot of the witnesses of the committee hearing this week were saying that the COVID pandemic is an accelerant for not only great power tensions, which is obviously a backdrop to this pandemic and the backdrop to all of our shared world at this point, but also for this kind of activity. So what can you tell us about what's going on during the pandemic in terms of interference or disinformation online? What's going on? I think at the very big picture level, the two, I'll call them superpowers, the US and China, they both feel that this is an existential threat to them. So the US as a whole, it's clearly not an existential threat, but to the Trump administration it is. So he's going all out sending out messages that try to shift the blame to China. At the same time, the PRC is very worried about, I mean, I think it's overriding internal concern is internal security and that's number one, but that because it relies on the global economy to keep its people employed, a collapse of the global economy where it gets blamed is also hugely problematic. So both players there are super concerned about what's going on. And at the same time, the people all over the world are tremendously worried, rightly, about COVID-19 and that just leaves a fertile playing field for them. So I think that's the backdrop. So there's covert behaviors and then there's overt behaviors. We probably should explain that to people. There's a difference, right? Like there's sort of activities that don't reveal themselves or disclose themselves for want of a better term, right? Like our Macedonians, right? They're not actually disclosing their true intentions as they want to harvest you through to their money making website, right? So there's that kind of disinformation. Then there is overt disinformation, which is being prosecuted by governments, both in the online environment and every time we turn on our television. So do the differences matter? Well, so Facebook has a definition for, they call it coordinated inauthentic behavior and that's what they use from a terms and services point of view to get people off their platform. So there's coordinated. And so that means you're working together. Inauthentic means you're not representing who you truly are. And putting those together means that the Macedonians in the case we talked about are not representing themselves. So you get booted off. But if you're a government and you're saying this is all, you know, I'm the Ministry of Foreign Affairs, that's fine. But what's interesting is that that definition doesn't map very well to disinformation. So I can stand up, you know, I'm Tom, I can get together a group of my friends and we can say, you know, we're who we really are. And we don't believe in vaccination, say, and because it's coordinated, and if I actually believed I was if I was actually an anti-vaxxer, that would be fine because you're representing your true self. So that's convenient from a platform point of view to be able to get rid of people, remove accounts from your platform. But I don't know that it's particularly, it doesn't seem to me like the right answer for a democracy as a whole. Well, this is a difficulty, isn't it? I mean, and I would say this because I'm a journalist, but what sort of amazes me about the platforms, and I sort of say this as a free speech person genuinely, but I work in a public environment where I publish material all the time in the public environment. And I work in an editorial structure where we are responsible for what we produce. We are, if our information is found to be incorrect, or defamatory, or, you know, whatever, we are, we are responsible, we are held responsible. Yeah, the platforms are the biggest publishers in the world by a massive stretch, yet deny that they are publishers on the basis that they don't want to take editorial responsibility for stuff that's circulating on their platform. Now, I sort of get the whole free speech kind of head explosion about, you know, Mark Zuckerberg being the arbiter of truth and how scary that might be. Fine, I totally get it. But why do they get to be utilities and we publish it? It's sort of, do you understand this? Like, do tell me if you understand this. Yeah. There's a rationale for it. So there is a rationale, and the rationale is that back in the past, well, I'll step back, the internet enables people to do good things and bad things. And so on every platform, there is a range of people doing fantastic things and a range of people doing absolutely horrible things. And I can't remember what the system was, but in the States, a system, they might have been AOL, but they were removing people from the platform because they were being terrible. Right. And that ended up in court, and they were found liable because they hadn't removed someone. At the same time, another company was operating, not removing people from their platform at all. And they were not liable because they weren't making any effort at all and therefore were not responsible. So there's a law in the States that removes platforms from liability if they're doing their best. Well, I guess it doesn't have to be the best effort, but making some effort to moderate their platform. So overall, I think that rule's a good idea because it encourages platforms to at least try and make the internet a better place. But this is, I think this is an unintended consequence of a fundamentally good law. I think there's a whole tremendous, and looking at it in context, the internet is tremendously a boon for society. But there are problems caused by that. Yes. I also think that the platforms had no idea of the scale at which they would be operating within such a rapid period of time. So, you know, population level in every part of the world and having to solve the problems of hate speech and ethnic competition in every single socio-cultural context in the world is just a problem set they probably hadn't engaged with when they started out. So they're grappling with problems that we just don't have a kind of textbook on how you deal with problems like this. So we have some principles that emerge from the context in which the platforms kind of were developed. But trying to apply those principles at a universal scale is just so challenging. Yeah. Well, yes, it sort of makes my head explode. But nonetheless, it is like it's a real problem that does require solutions anyway, we'll get to the solution. So what has China done? That's where we can return to the Donald in a minute. But what's China done during this period? So Tom noted that the pandemic has created a kind of existential crisis, a political crisis for the Chinese Communist Party regime in the People's Republic of China. And they have responded by launching waves of disinformation intermingled with diplomatic and state media messaging. And that's quite that's quite easy to call out. But in the work that we've been doing over the last few weeks, in fact, is to identify that they have actually been running really large scale influence operations on social media platforms to amplify that diplomatic and state media messaging. So how does that work? How does it what? What do they do? What do they do in order to amplify that message? Well, one technique they use is to just retweet things. So we looked at the specific data set around Twitter. So they should just hang a tick because Twitter gave you guys access to their database, didn't they? And for this research, so we should tell people about that. But yeah, one of the platforms, Twitter that I was just defaming, gave you guys access to your database. Yeah, so since the 2016 elections, sometime maybe nine months after that, Twitter released a really, really quite large data set of the Russian activities. And since then, they've regularly released activities from related to other countries. So I think the one that we looked at, we looked at the China part, but there was also Turkey. Was it Indonesia? We've looked at Indonesia. And more broadly, there was Russia, quite a bit in the Middle East, some other European countries. So there's really quite a large list of data sets that Twitter has released. So they go around looking for these operations that are run by states but aren't branded. Yes. Well, don't fully disclose themselves. Yeah, they're covert. Okay, so yeah, sorry. So I disrupted the flow. Anyway, so what are they doing? How are they amplifying by retweeting? What else are they doing? They'll just put out messages. They create memes and just tweet them and retweet them. And the... Like dad jokes or... So one of the powerful ones we came across, so Twitter gave us all the media associated with these tweets, was a kind of rough Photoshop job of the Statue of Liberty kneeling on George Floyd. I guess it was George Floyd. Was it his neck? Yeah. Now this was extrapolating from the Twitter data set. We identified that the network had pivoted to focus on domestic protest and civil unrest in the US. And the aim there is to create a perception of moral equivalence with the suppression of protest in Hong Kong. And it's really important to note as well that this is in Chinese language. So the kinds of audiences that we think are being targeted here are in Hong Kong and potentially in the Chinese diaspora more broadly. Yeah, yeah, yeah, yeah, yeah, right. Okay, so that's really... That is well, everywhere. Well, everywhere, indeed everywhere. That's really interesting, that point of moral equivalence. Was it now, forgive me, was it you guys or one of the other witnesses? Somebody said in the hearing this week that basically since the Hong Kong protests that the Chinese government has rapidly escalated its disinformation capacities to communications in English, like a lot more communications in English. And this one of the witnesses said that their belief was that it was sort of more designed to influence discourse in Southeast Asia than perhaps in Australia. But that there had been this kind of struggling for the right description. Evolution? An evolution that is sort of adding a new capacity to the arsenal that I think you said a second ago, Jake, that there's Chinese language communication, right? But that there was more communication or more of these activities in English since the Hong Kong protests. So I don't know. Well, it obviously wasn't you guys by the looks of things. I wish I could remember who it was. Anyway, it was... It's certainly true to say that there's a much more forward leaning effort from the People's Republic of China to contest the information environment using the full range of diplomatic state media and covert influence operations. So there's, we've seen over the last year, a massive spike in PRC diplomats and state media on Twitter. So the shift to Western platforms to contest the international discourse. And again, I think it is in order to try and pressure regional alliances and to pressure where different parts of the world may perceive their best interests to lie. Who is the preferred international partner? Right. Okay. And so there's obviously external influence, but picking up from your theme about the pandemic presenting an existential crisis to the regime in Beijing in terms of their hegemony in their own country, is the audience also domestic? I think they've got a different set of tools that they use domestically. So famously, there's what's known as the 50 cent army. That mostly it seems... Explain, explain to people who don't know about the 50 cent army or who they are. Yeah. So the story is that there's a really quite a large group of native Chinese who get 50 cents, wu mao, for each post on internal domestic Chinese social media that is favorable to the government. So they're kind of like influences. Yeah. So the research seems to say that they don't so much promote the government so much as distract from anything that might look make the government look bad. And they also internally have a whole lot of censorship apparatus that can prevent dissent from boiling over. So the kind of engagement they got on Twitter was not very good. And it seems like they don't really understand how to operate in a different kind of environment. There is this just huge difference between inside and outside. Yeah. Well, obviously, I don't know what the difference is in terms of platforms and censorship, but you mean culturally that they don't really understand the environment or what do you mean? I think all of those things. So from a Western point of view, people understand advertising and they understand propaganda and they understand the nature of appealing to people. Whereas I think internally, that doesn't seem to be a thing that happens. Right. So you don't develop the fluency to understand the cues or whatever. Yeah. So if you look at the Russian operation in 2016, they spent a lot of time building up audiences based on themes that were nothing at all to do with politics. They tried a wide range and they found many that appealed to groups of people. So they had both Black Lives Matter and groups that supported police. So for a long time, those groups were just appealing to their base and it wasn't until close to the election that they were actually swayed in a political way. Yes. Right. So you sort of, well, get us back to Macedonia. I mean, totally different objectives, but sort of gets us back to that sort of influence building you accumulate. You go to where the crowds shouting at the other crowds are and you start hanging around there and you infiltrate generally. Okay. So that's China. Now what about the Donald? What's happening in America? The example I think of most is the Wuhan lab. Yeah. And there's, so I'm a biologist originally, so there's actually a plausible but unlikely theory that the COVID-19 escaped from a lab. Yeah. And it doesn't have to be a malicious... Could have been an accident. Could have been an accident. Right. Now in a responsible grown up adult world that we don't live in, that story wouldn't... That none of us even recognise anymore. Oh no, it's crazy. That story would have been, okay, this is something we need to investigate to find out how to avoid it happening again. And it would have happened behind the scenes. In today's world, it ends up, you know, there's a dossier, which is just a kind of recollection of... Press clips. Press clips, basically. And it gets a lot of prominence and play without it, without anyone knowing any facts, basically. And so that's the question is, is that disinformation? Because it's plausible, but not untrue. I think it's definitely... Is it? Is it? Come on, Jake, you're being very quiet. Well, I think I'd go back to some of those finding definitions that we use in this country, which is about that you tip from influence into interference where it's potentially coercive or just deceptive, deceptive, manipulative. Well, it's deceptive and manipulative, isn't it? I mean, accepting your point, Tom, that it is entirely plausible that perhaps this was an accident, although the science doesn't seem to point to that. Pretty unlikely. Right. Just as they've studied the genome of the virus, it doesn't look laboratory made looks. Yeah. Well, it could be a natural virus that just happened to be... I'm not totally discounting it. I mean, anything could happen. There's enormous capacity in Wuhan for this lab research, which is why the theory began. So accepting your basic point that this is on the plane of possible. But if you are the president of the United States with access to one of the most sophisticated security services in the world and all kinds of top shelf information coming to you as the person at the apex of power, you fully understand whether or not the information is a fact or something that can be ripened up and deployed in a political mud fight. Right? Given that Donald Trump has been fact checked by Twitter a number of times, I'm not sure. I'm not so sure. No, no, no. I'm not going to accept a diminished responsibility plea. I'm just not. I'm sorry. You do know, you do know, you do. And you have access to information and you have people around you who can say, this is a probable thing. This is a possible thing. This is science. Right? So Trump has obviously deliberately, as we've all recognised, inflamed this situation by making this a kind of like a sox fable, but like a monstrous no, more like a grim fairy tale than a fable. Yeah. So one of the definitions of disinformation is that it's deliberate and this is certainly deliberate. And he's certainly twisting what he knows to get for him. I think he thinks of it as a political advantage. So from the current definition of most of the platforms use that's that's not coordinated in authentic behaviour. It's just no authentic behaviour. It's just bullshitting. And I think we're never going to solve the problem of politicians behaving badly unless we have better politicians. Look, as someone who has watched this particular, you know, subculture at close range for nearly 25 years, I agree, right? Like that. I totally agree. And again, the only thing I fear more than, you know, this the information, the very toxic information environment we currently inhabit is Mark Zuckerberg being the arbiter of what's what's true and what isn't right. So it's complicated. I'm totally with you guys. I get it. But still, the concern that the slippage creates, right? I mean, there's an autocracy in China, there's an authoritarian regime, I suppose we should expect, you know, methods of information control that have always been a feature of autocracies. It's just the internet gives you a new tool, right? This is not disinformation in an autocracy is not a new phenomenon. It's not something in the internet, go for something that's always existed, right? But in a democracy, I mean, America is not an autocracy. We don't generally sort of run states by basically, you know, who can bamboozle the most. Yeah. So what that makes me think of is Do you think of something at this point? The incentives that social media provides to people. Yeah. So you can go on Twitter and you can probably and certainly Trump has generate a huge following by being extremely controversial, nonsensical, racist. And that I think you can make an argument that that's what got him the presidency, right? So he's being rewarded for his behavior. So then stepping back, what is the you know, do we want a society where politicians get rewarded for? Exactly. Exactly. Well, this is this is a foundational question that's much bigger than the conversation in this podcast, but it's sort of but that's the that's the point to which we inevitably get in this conversation. Right. So let's do solutions for a couple of minutes. Right. We've sort of got to this kind of nihilistic world where we've got full nihilism, but that's that's that often happens in this in the studio. People know that that we are kind of creeping towards this world where it's really difficult to detect what is true and what isn't where autocratic regimes don't look actually that different from democratic regimes in this sort of activity. Right. So do you Jake's taking issue? I can see. So I would draw distinction here. All right. Go for it. I understand that the the comparison that Trump and Pompeo have created has not been particularly helpful. But I do see a distinction where you have the full weight of the state driving and manipulating audiences at scale. So that's not just diplomats who are influences their bread and butter. That's their that's their day job. Yeah. But also large state media apparatus supported and amplified by massive, massive scale influence. No, no, that's fair. That's the operation we were looking at was like one hundred seventy four thousand faked accounts. And that's probably a conservative assessment. Right. So where you've got that kind of really centralized power and the full focus goes on manipulating the information environment and also potentially controlling the information and the information architecture itself. Yes. Given the context between us. You're right. You're right to say that's a bit of an overstatement. That's fair enough. But it is. But it's sort of it does. It does. I do find it irritating, though, that different standards of judgments are applied sometimes for very similar behaviors, although not identical behaviors, as you've correctly said. So but anyway, God, time anyway, we could rave on all day, but we won't. I'll just give it. I'll make this simple for you, right? If I'll give both of you an opportunity to tell me one thing, if you were the, you know, in charge of the world, one thing that you would do to make the environment better. In charge of the whole world. Well, I'm going to stick to Australia. So I think that one of the foundational pieces we need is a vibrant media ecosystem. Praise the Lord. So if it was just one thing I would really fund more than just the ABC in Australia. I think that the traditional media is going to is being destroyed by COVID-19. So advertising is collapsing. The solution the government currently has is for Facebook and Google to come up with, you know, some revenue sharing deal. I think this encourages all the wrong kind of journalism, the emotive journalism that probably will be fine anyway, because that generates a lot or large audiences that you can advertise to. It's the high quality investigative journalism, the journalism that deals with issues that affect democracy. I think that needs to be supported. And part of that is just giving giving money. I think part of it is that we could have a large effort to try and find business models that actually work in the new era. And I think the government could support that without signing up to necessarily pay for the media indefinitely. And it's also sort of supporting R&D for want of a better term around a business model also removes some of the conflict of government funding for journalists, says the journalist in this. Yeah, so I mean, Facebook is a platform that people come to and then they get news. Maybe we should have a platform that is for news that people come to that is somewhat government supported. I'm going to make a small statue of you and put you in my office and put little flowers at you. Anyway, Jake, what's your idea? So I'd love to see substantially more transparency around both content moderation and the algorithms that platforms use to both amplify and suppress content. And I think that's important because we have a range of platforms that are popular in Australia with degrees of transparency across those platforms. And I think that would go a long way to helping us understand how these environments shape our sense making. And I think that could lead into some enhancement of our population level digital literacy. Yeah, and digital literacy, I reckon, is at the heart of it. I mean, some of this presumably, you know, as this inquiry goes on, doubtless, we will verge towards regulatory options. But I think digital literacy is the most important, which is in part why we're having this conversation. So thank you both for your time and your jokes. I do appreciate it. It's been delightful. Thank you to my executive producer, Miles Martin-Yurney, who looks after this show and to Hannah Isard. Anyway, on we go. We'll be back with you next week.