 The Guardian Do you feel comfortable with what we're about to do? I've no idea what I don't know what we're going to do. We're going to play a game. Yeah. I have in my hand some beautiful artworks. Okay. And I'm going to show you them one by one. And you have to tell me whether it was created by a human or by a computer. Okay. Are you prepared? I'm as prepared as I'll ever be. Okay. Keep your mind open, okay? So this lovely specimen here. Um, AI? Yes, absolutely. You're right. Can you describe what you're looking at? So it looks like a knight with a like a walrus head and like wolf puppets on his hands or something and a dog for an arse and... Can we say arse?...little people and all sorts of weird fairy type things going on in the background. It's weird. And you're pretty sure a human wouldn't create that. I hope a human wouldn't create that. Okay. Here's the next one. Oh. So this looks like a sort of a... I'm not even sure if that's a boy or a girl or a man or a woman, but it's sort of a youngish person with white, long white hairy face. Person in a wig. Yeah. I mean, it looks really realistic. So I will say person, but you... I would say person, an artist, didn't I? That one is a real human being. And finally... Doing okay. How about this one? Well, I know this one and I know this one is an AI. But to be fair, if I hadn't known, I probably would have said it was a human artist, to be honest. Really? It's basically got no face. I know. I know. But have you seen the weird things artists produce? Yeah. No artist weird. Some of them have two faces. I can kind of see in this that the signature at the bottom of the painting is this code. Yeah. I didn't look at that. Oh, yeah. That's true. Bit of a giveaway. But yes. No, you're right. This one is an AI. It's the portrait of Edmund Bellamy. So, Jordan, why are you getting me to play this guessing game? Well, I think it might be important to hone your ability to tell whether an artwork was made using artificial intelligence or not, because AI art is becoming more and more popular. And actually, that raises questions about what counts as a work of art. Back in October 2018, the British auction house Christie's became the first to sell a work of art created by an algorithm. The painting is called Portrait of Edmund Bellamy and was sold for $432,500, which is about Â£337,000, which was a lot higher than anyone had been expecting. As you might expect, this groundbreaking sale created some controversy, not least in the AI art world itself. The actual kind of code that you can use to create the artwork that was developed by an artist called Robbie Barrett. And he put the codes out on GitHub and didn't imagine that it would be used for commercial purposes. Right. But I mean, looking at it here, it's one of the examples you just showed me. I'm not sure I want to spend hundreds of thousands of pounds on it. It's a canvas. There's lots of white space around the edges. And then we have this blurry image of a man with no nose, a blob for a mouth. And he's in black with a white collar. It did, though, get me thinking about what makes something creative. Because the brilliance of a new artist or of any artist is in originality and in coming up with something different, not in just mimicking something that has been done before. And traditional computer programs haven't been able to go beyond that. Exactly. Christie's website boasted that the portrait, quote, is not the product of a human mind and specifically states that it was created by an artificial intelligence. But it's not that simple. And throughout this week's episode, we're going to explain why it's so difficult to determine who is the true artist, the code or the humans behind it. I'm Ian Sample, and in our latest collaboration, The Guardian Science Weekly has teamed up with Jordan Erica Webber of Chips with Everything. Together, we'll look at why artwork produced using artificial intelligence is forcing us to look at how we define creativity. This is Science with Everything. My name is Luber Elliott and I'm a curator and researcher specializing in A.I. art. I invited Luber into the studio to talk about this portrait of Edmund Bellamy. She has been looking at the field of A.I. art since 2015 when Google launched Deep Dream, a generator that used a neural network to convert normal images into something far trippier, like this picture of the night with the dog for a rear end. That's quite the light way of saying it. Luber explains that there are many artists working with A.I. so the sale of the Edmund Bellamy portrait took them all by surprise. Before this painting got to auction, I probably wouldn't have thought that this painting is particularly special because if you've been looking at these paintings for a couple of years, you will realize that in many ways the portrait has kind of low resolution and the textures are not particularly refined. There are many more examples of artists like Mario Klingerman or Robbie Barrett who are able to harness the technology and produce works which look much more interesting and high quality. But I think ultimately what makes this particular example from obvious special is that, well yeah, they made it to Chrissie's auction but also they printed it, they put it in a golden frame and they signed it with the equation which is supposed to represent the algorithm. Luber suggests that the painting would have come out looking more realistic had the humans in charge been better at working with the algorithm behind it. And we'll talk more later about how exactly the portrait came to be. Before that though, could creativity like this be seen as a way of solving the problem of art? I decided to ask someone who knows a lot more about this than me. I'm Leonard Miladnove, I'm a theoretical physicist and author. Thankfully for us, Leonard's most recent book, Elastic Thinking, looks at how we humans solve the problems we come across. In humans, I put our thinking and our problem solving on the spectrum where at one end you have logical reasoning which follows rules that take you from A to B to C and to a certain conclusion. And at the other end of the spectrum you have elastic thinking. Elastic thinking is not rule based, it's not about how to follow rules, it's how you make the rules, how you even frame the question or decide what question to ask. It's a much more fundamental kind of thinking than analytical thinking. Analytical thinking is very useful in a situation that you've encountered before where you're applying tried and true methods. And elastic thinking is useful when you face a novel situation or a situation where your analytical thinking hasn't worked and you have to try new things out. Elastic thinking involves things like imagination, integrating information, how you rise above conventional mindsets and reframe the questions that you ask. And what we call creativity, for example, that involves a lot of elastic thinking to generate your new ideas that give you the new approach, but also that involves logical thinking in order to channel and focus your development of those ideas into something useful. So is this different to the kind of emotional responses, hunches that we might have? When you say it's the opposite end of the spectrum from logical reasoning, I tend to feel that might be gut feelings, gut responses. Well, elastic thinking happens to a great extent on the unconscious level. Not that you can't control it and nurture it and call it into play, but a lot of the processing that goes on is unconscious and we call that hunches or gut feelings. But what's going on is under your level of awareness, your mind is constantly making associations. When you see something, it stimulates the thought of something else. Or when you think something, it stimulates the thought of something else. Ideas are constantly being generated. And your brain has filters that keep most of those ideas and thoughts from coming into your conscious mind because your conscious mind has a limited bandwidth that you can only handle so much. And if every idea that your mind never came up with came into your consciousness, you just drown in crazy ideas. So you have filters that decide on an unconscious level what is most likely to be useful and they let those things through to your consciousness. So Leonard boils down our ability to solve problems to two distinct kinds of thinking. Yeah, and this is no new theory. You may have heard about Daniel Kahneman's now famous System 1 quick, fast, but often biased thinking and System 2, the slower, more logical and rational thinking. Well, this is similar, but while Kahneman urged us to focus more on System 2 thinking, that logical stuff, Leonard argues that System 1 might not be the villain it's often made out to be. Sounds like a nice tidy theory, but is there evidence to back it up? Well, there is according to Milodino. He believes it's in the structure of the brain itself. Analytical thinking and elastic thinking have come from far different processes in the brain. Analytical thinking is what scientists call a top-down process. That means that someone, the programmer, sits down and figures out the approach to solving the problem and how using analytical, logical rules, a problem could be solved. So data is put in and the computer crunches through certain algorithms and comes out with an answer. And your brain can work in that mode also. You have structures in your brain called executive structures, which more or less order other structures of what to do. And you follow a pretty linear rule-based reasoning and you get your answers out, just like when you're adding 3 plus 3 and then you multiply by 10 and then you divide by 6 and you just go step by step. And you get an answer and a lot of problems in the world can be attacked that way. Elastic thinking is far different from that. It's a kind of processing we call bottom-up processing, which is far more complex and rich than the top-down processing. A good way to think of bottom-up processing is to look at ants. In bottom-up processing, the individual components of your brain or of the information processing device, the computer, or the ant colony, these individual components are executing very simple programs or algorithms. And those algorithms don't do much in the individual level. But when you put dozens or hundreds or billions of them together, then what you end up with is something where the whole is greater than the sum of the parts. And an ant colony is a great example because the ants just have a simple program like move backward, move forward. They're very simple algorithms about what the ant does given the situation. And that's not very intelligent. It doesn't come up with a lot of deep results. But when you put hundreds or thousands of ants together, they do amazing things. For example, if ants are on a leaf of a tree and they want to cross to another leaf but there's a gap, they manage to form a bridge from their own bodies and then crawl over them and to get from one leaf to the next, they form an ant bridge. And our brains work like that because our brains are made of 100 billion neurons, which are just switches that have some inputs. And when they reach a certain level of input, they give output to other neurons. It's a very simple thing. But collectively, all these billions of neurons that are interconnected with each other come up with ideas and thoughts and that's bottom up thinking. And that's the way elastic thinking comes. So theoretically, if we were to make an AI that used bottom up or elastic thinking, Leonard argues that it could potentially be creative. After the break, we'll look at why this future might be closer than we think. If we do get to strong AI, so an AI that is able to make very complex decisions and can equal humans, then yes, of course, that could be possible. We'll be back shortly. Hi, this is Jordan Erica Webber, the presenter of the Guardian's Digital Culture podcast, Chips with Everything. As you know, this week we've teamed up with the Guardian Science Weekly podcast to talk about why artwork produced using artificial intelligence is forcing us to look at how we define creativity. This means that I get to work with the wonderful Ian Sample. It's always fun to get to work with colleagues from other teams. I always feel like I've come away knowing something I didn't before. Guardian Jobs, which is sponsoring this week's collaboration, can help you find your good company. It promotes a world of work where potential flourishes by connecting people with rewarding careers at like-minded organizations where values make the difference. Whether you're looking for a new job or you're a recruiter looking for the perfect addition to your team, you can trust Guardian Jobs to help you find your perfect match. So find your good company at gu.com slash good company. Now let's get back to AI art. Welcome back to this special collaboration between two of the Guardian's best podcasts, Science Weekly and Chips with Everything. I'm Jordan Erica Webber. And I'm Ian Sample. Before the break, I spoke to the author, Leonard Modineau, who talked about what he calls elastic thinking. It's the style of thinking he believes gives rise to creativity, among other things. And it's driven, he explains, by bottom-up processing. But is this what AI does already? And if so, does that make AI creative? To figure this out, I needed to go back to Luba Elliott to find out more about the actual process of how AI was used to make the portrait of Edmund Bellamy. So this GAN, or Generative Adversarial Network, is a type of machine learning technology that is actually quite popular in the artistic community right now. And the way it works is you have two neural networks, and one generates images based on a dataset, and the other one tries to determine which images are real, i.e. they came from the dataset, and which ones are fake. GANs, or Generative Adversarial Networks, were the brainchild of researcher Ian Goodfellow, who came up with the idea of making two neural networks work together, one generating candidates like images and the other evaluating them. In the case of the kind of AI art we're discussing, one network acts like a talented art forger, who also wants to make their own original art, making both copies of original paintings and a few of its own invention. The second network is a kind of art detective, whose job it is to find the images that are more than just copies. As the detective finds these fakes, the forger learns from its mistakes, and trains itself to trick the detective by tweaking its formula to create better and better new paintings that the detective can't catch. There are lots of different models and variations and implementations of the algorithm, and the actual kind of code that you can use to create the artwork that was developed by an artist called Robbie Barrett. And this is where it gets a bit controversial, right? Right, so Robbie Barrett is a young artist who works with artificial intelligence. When he was just 17, he developed a code that he then shared on GitHub, a website developers often use to build on each other's work. Robbie has since said in interviews that he didn't think anyone would sell it as it was because it isn't the best quality. But that's what happened. Yes, a French collective called Obvius compiled a dataset of 15,000 portraits painted between the 14th and 20th century and applied bits of Barrett's code and Goodfellow's GANs. The algorithm produced thousands of results and Obvius picked the one they thought was best, put it in a gold frame and signed it with a section of the algorithm's code. Right, but Barrett had put his code online for everyone to see and use as they like. So why are people so annoyed? I guess because it sounds like Obvius didn't really do a lot of work but have made a lot of money. But if you look at the art world as a whole, and there are plenty of artists, starting with Marcel Duchamp, who of course put up a toilet and created it as a ready-made artwork. So I didn't think it's always necessarily so much the amount of effort involved because it can actually take a long time to compile a dataset, to assign different categories and classifications to all the images and ultimately to train and fine-tune the algorithm. But yeah, I think in their particular case they seem to have just experimented with a basic dataset, the basic algorithm and with basic results without thinking too much about what can be improved at each stage to make their piece as high quality as possible, which is what most other artists do in the field. I should point out that the people at Obvius have thanked Barrett for being an influence for their work and admitted to using elements of his code but say they made their own modifications. So it wasn't really a computer who created this painting. Humans trained the computer to do it. Right. This same tension came up in my conversation with Leonard. He's skeptical of an AI becoming the next Michelangelo, at least anytime soon. There are programs that can create wonderful music in certain styles like Mozart, let's say, that sound very good, Mozartian type of music. But those programs are designed by a programmer. They are top-down programmer. They are instruction where someone is putting into the program rules for creating music that sounds a certain way. It's not really the computer creating this music. It's the computer executing a program that's been put into it, telling it how to generate music along these lines. But they're really music that was defined by the programmer. And that is not what we would call creative. That would be like if I'm an artist and I start painting paintings that look like Van Goghs, you would say, wow, those are wonderful Van Gogh-like paintings, but they're not really artwork in a deeper sense. Because the brilliance of a new artist or of any artist is in originality and in coming up with something different, not in just mimicking something that has been done before. And traditional computer programs haven't been able to go beyond that. In just the last few years, there's been exciting developments where programmers have started using more and more these neural network computers and what they call deep learning, where they arrange for a set of components to interact with each other much in the way that the neurons in your brain interact or the anton and ant colony interact, where each of these components is very simple, but they're connected in a way that they can communicate and affect each other. And then the programmer arranges for this system to be put in a position where it can do something and learn from what it did. And when they're done, the programmers don't even know what it did. All they know is that they set it up in a certain way and it learned. And this is really the amazing thing and the key to the future of computers, to where computers then can have imagination or make original music and have original ideas in the same way that our brains do. So I think that's very exciting. I don't think that they're going to get to a situation anytime soon where they can compete with the human brain at doing that. Maybe they can in very restricted structured situations like chess game, but we have 100 billion neurons connected each to a thousand or between a thousand and ten thousand others. And that's quite an amazing system, far, far, far more complex and more components than they can do in a computer in the foreseeable future. Okay, but look at how GANs work. You pit two neural networks against each other, teaching the forger to adapt in order to trick the detective. And that kind of matches this idea of bottom-up thinking that Leonard is talking about. Surely it isn't totally inconceivable that in future, computers will be able to create this kind of art without human beings. If we do get to strong AI, so an AI that is able to make very complex decisions and can equal humans, then yes, of course, that could be possible. So what do we think, Jordan? Are AIs going to be creative? You should never ask a philosophy graduate a question like that. It all comes down to how we define creativity. Ian, I think it's interesting. If you look back at the pictures that I showed you at the start, when I was saying, was this an AI or was it a human? In all cases, a human was involved, right? So we can never say this painting was created entirely by an AI. And I wonder if maybe our definition of creativity would be a future in which a robot just decides to paint a picture by itself, like no one's told it to. This is kind of like a discussion I was having the other day, actually, about the idea of play and computers that play. So computers that play chess. I think it only really is relevant when we get a computer that chooses to play a game instead of doing what it's supposed to be doing. You know, a computer that procrastinates. And it's the same thing here. We won't have a creative computer until one day a computer that's supposed to be bottling things in a factory decides to go make a sculpture instead. I totally agree. I mean, for me, that moment of a computer being creative will be when it decides to go off and think, think, I'm going to make art. I'm going to decide what my inputs are and I'm going to generate some outputs. And it's maybe not what I'm supposed to be doing. At the moment, for me, these AIs are tools to make art. Where will it leave us, Jordan? That's a good question. Where will it leave us? Will we lose our jobs? Well, this is it. If you have computers that are having imaginations that are doing creative acts, even if they're not really genuinely, you know, sort of creative, genuine art, it's interesting what that will mean for the jobs market. I mean, if you read any paper that comes out on what AI will do for jobs, they always say the safe jobs are the creative ones because AI is rubbish at that. I don't think that's particularly true. I think there's a lot of things that AI will be able to do in the creative realm that will be good enough. And that means end of your job. Yeah. I mean, we've done an episode on robots, singers and kind of robot Instagram influencers and things. So even those kinds of jobs could go to AI in future. Well, obviously, all rebaligates the robots and what our human singers and artists back and poets and all the rest of it. And we'll all be brought together by it and it'll be harmonious. And we'll write war poetry. I'll sound the robots. Special thanks to Leonard, Melodino and Luba Elliott for making time for us this week. You can find links to everything we've talked about here on our website. Head over to theguardian.com forward slash podcast. I'm Jordan Erica Webber. And I'm Ian Sample. Until next time. Goodbye.