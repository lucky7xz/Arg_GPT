 The Guardian. My name is Christopher Wiley. I'm a data scientist and I help set up Cambridge Analytica. It's incorrect to call Cambridge Analytica a purely sort of data science company or an algorithm company. It is a full service propaganda machine. In March 2018, a whistleblower called Christopher Wiley revealed to the observer that a company called Cambridge Analytica had used personal information harvested from Facebook to target voters with personalised political advertisements. The story was so huge that it triggered a movement represented by the hashtag DeleteFacebook, which garnered support from big names like WhatsApp co-founder Brian Acton, SpaceX and Tesla CEO Elon Musk, and even Playboy. Ordinary Facebook users like me and, I presume, many of you were prompted to rethink our relationship with this social media platform. But it feels like most of us just tutted a few times and then continued to scroll through our news feeds. This is hardly a new trend. Take Uber. Uber's chief executive, Travis Kalanick, has taken a period of leave from the billion dollar taxi company, which is under a cloud of sexual harassment claims. And Uber's director. The company has received no end of negative press for things like sexual harassment and its workplace culture. But it's still the first place many people go when they need to ride home after a night out. Or look at Twitter. After facing widespread criticism for verifying a man who was literally run out of town for the harm his rally of intolerance caused, Twitter halted all new verifications and is now claiming to be working on establishing rules which may remove verification on currently verified accounts. Whose users have a long list of complaints about things like harassment and abuse and deal with these complaints by tweeting about them. Often, we direct our anger at the people behind the tech. Those at the top of some of the biggest companies in the world have gone from being revered for creating opportunities and innovations that we didn't know we needed, to being vilified as consumers lose faith in their companies. But how did this happen? How did the creators of some of the most impactful technologies of the 21st century go from hero to zero? You know, these companies and these entrepreneurs at the beginning were Mavericks. They were challenging the status quo. They were celebrated as heroes. They were providing opportunities to people to make their lives more efficient, to democratize opinion, to give kind of them access, to have their voices heard, to make their lives easier. And why is it that despite our indignation at how the tech companies have wronged us, we continue to buy what they're selling? It's everywhere you look. It's on, you know, every poster, every billboard, every advert, everything that you are watching and seeing and doing. And there's a lot of pressure to be involved in that world. So cutting yourself off becomes quite difficult. This is Chips with Everything. I'm Jordan Erica Webber. Yes. I know that Jeremy's in the room. Yes. But try not to look at him. Okay. Because then you'll go off. But he's giving me secret signals. He's giving me. And then... Brad Stone is a senior executive editor for technology at Bloomberg News and the author of several books about technology and startups in Silicon Valley. I've been covering technology for about 20 years. I started in San Francisco in the mid-90s. So I really saw the initial boom in the tech community and then the prolonged bust starting in 2000. And now really for the last 10 years, a sustained boom that has elevated the major technology companies into the ranks of the largest companies in the world. My producer, Danielle Stevens, sat down with him and asked why perceptions of Silicon Valley bosses have changed over the years. You know, these companies and these entrepreneurs at the beginning were mavericks. They were challenging the status quo. They were celebrated as heroes. They were providing opportunities to people to make their lives more efficient, to democratize opinion, to give kind of them access, to have their voices heard, to make their lives easier. That's still all true, but these CEOs, they are the status quo now. These companies are the status quo. When you talk about Amazon and Google and Microsoft and Apple and Facebook, you're talking about five of the 10 largest companies in the world. So tech has come to represent power. You know, there's not only an inherent distrust of power, but I think that we're beginning to become more aware as users and, you know, as society in general of some of the kind of negative externalities, maybe the unanticipated secondary consequences of using these technology. There's a lot of good, but there's also a lot of bad. Who are some of the big players in the tech industry that have seen their reputations damaged by company scandals? You know, I'm very hesitant to lump. I think it'd be premature to put like a Mark Zuckerberg in that category. I think he's right in the middle of it now. He'll be testifying before the U.S. Congress in April. He certainly has to justify the role and explain the role the company played in the 2016 presidential election and in the Brexit campaign here in the U.K. I think it's probably too early to say that he has kind of suffered a decline in his reputation. We'll see. We'll see how lasting the damage is. When you look at some of the maybe some of the characters that have suffered irrevocably, well, you know, I mean, there obviously is a sort of handicast of characters there. The CEO of Theranos, the blood draw firm in Silicon Valley, you know, the CEO of Autonomy, the London based company that Hewlett Packard bought and then was the subject of some accounting scandals. Yeah, certainly in this kind of sort of slow moving shakeout of the past few years, there have been some casualties. Marissa Meyer at Yahoo! maybe is another good example. Of course, she sold her company to Verizon. But, you know, her tenure there wasn't necessarily seen as a success. And that was someone who really was celebrated and who now is probably looking for her next act. What are maybe then what are some of the biggest mistakes made by these people that the consumer expected more from them? Well, I mean, I think that in this respect, tech isn't all that different from regular business. You know, these are the outcome is not always necessarily positive. And I think some of the names we just mentioned, you know, when there was sort of when there was just plain fraud, like with Elizabeth Holmes and Theranos, it seemed to be the case or accounting fraud, a company like Autonomy, you know, then that then that obviously is, you know, has led to a very bad outcome. But, you know, in general, like the mistakes that tech companies, CEOs make, it's it's the classic, you know, moving fast and breaking things that sort of ethos that was celebrated in Silicon Valley, but which now has had some sort of real world side effects where, you know, a company like Facebook move very fast, set up a platform now five years ago, allowed third party apps to come in and use some users. And now we find out that that basically, you know, led to a little bit of a chain reaction where people's personal information that they were trusting Facebook with ended up in the wrong hands. And so, you know, if we were going to kind of talk about a broad mistake that the tech community was making, it was moving fast, fueled by kind of competitive instincts to go and try to build businesses very quickly. And then the end result was that, you know, they ended up harming the trust that their users placed in them. A week after the Cambridge Analytica story broke, Facebook stock was down by 95 billion dollars. But Zuckerberg, he still had a job. You've covered Travis Kalanick, the former CEO of Uber, who was eventually forced to resign. So should Zuckerberg be worried? Well, I mean, I think on one level, yeah, Mark Zuckerberg has a lot of job security. He is a founder of Facebook and he has an inordinate share in the company. And he also has, you know, what's called a dual class stock situation where he has enough voting power that his situation is very secure. But even aside from that, I think that the you know, he's personally responsible for, you know, the remarkable rise of Facebook over the last 10 years. You know, yes, the stock is down this year, but it's up a couple hundred percent over the past few years. We're right in the middle of a very bad media cycle. And it remains to be seen what the rest of the year looks like for Facebook. There is a lot of fundamental optimism in the in the advertising business and how it has grown. And of course, along with Google, Facebook is seen as increasingly having a kind of iron grip on the online advertising industry. But yeah, I mean, I think with the Uber situation and Travis, we saw that, you know, there is such a thing as making too many mistakes. You know, I just I don't think Facebook is there. But certainly they have some work to do to restore user trust. Was it a warning, though, say that the Travis story, was it a warning to other bosses or was that specific to his mistakes or the company's mistakes? I think, yeah, the Uber situation was absolutely a warning, not only to founders in Silicon Valley, but to investors and the venture capitalists who had just put a lot of trust in the almighty CEO. Now, Travis wasn't necessarily the founder of Uber. That was his friend Garrett Camp. But and for that reason, he didn't have the same stock protections that Mark Zuckerberg had. But it was a it was a it was a warning and investing too much in these headstrong founders. You know, Travis said Uber, in retrospect, created a culture that had a lot of sort of bias in it, was almost irresponsibly fast moving. It wasn't very ethical and it was competitive to a fault. And so I think all the values that he sort of publicly expressed at Uber, the way in which that led Uber to disaster, I think, has been fairly well watched in Silicon Valley. And hopefully the lessons have been learned, one of them being that you just need to express a little bit of humility. Right. And that's something that Travis at Uber was never able to do. And as a result, you know, I think people, even though they used Uber, they tended to dislike or distrust the service and him in particular. Silicon Valley can seem or has seemed in the past like an exclusive club. The people working there are in this bubble. They have beanbags for chairs and they were a group that kind of protected each other and kept within themselves or kept themselves to themselves. Now people are breaking ranks. So the creator of WhatsApp is saying delete Facebook. Elon Musk is deleting his Facebook pages and Tesla's Facebook pages. So why are they choosing to call out others? Well, first, I think that Silicon Valley was never the uniform community that maybe it seemed. You know, this is an area of the West Coast of the United States that started really as a center for microchip development, you know, then gave birth to the first wave of Internet companies and now more recently to the wave of online to offline companies like Uber and Airbnb. Lots of different micro communities, lots of different views, drawing people from all over the world, frankly. And so I don't think I don't know that there was a uniformity of thought. But now, you know, as these companies have kind of graduated into the top echelon of organizations that are changing the way we work and live, you know, people just have different opinions and are reacting to the controversy in different ways. You know, Twitter gives everyone a kind of pedestal to go and express their opinion. And so we see things like Elon taking a stand on Facebook. You know, I think there's an element here that we can't dismiss either, which is that, you know, a lot of these people are also sort of natural self-promoters. So they seize on the moment and the opportunity to kind of divide and separate themselves from the mainstream of Silicon Valley and the sentiment that might be shifting against some of these other companies. You know, Elon doesn't want Tesla lumped in with the negative associations that are occurring around Facebook. So he kind of takes advantage of that. There is an anger and a distrust around these people and Silicon Valley as a whole. Is there a benefit to consumers to have an air of skepticism? Absolutely. First, let me just say that the the distrust and the anger is absolutely justified. I mean, the fact that, you know, we we, you know, we trust a company like Facebook with their personal information and they're not great protectors of it, you know, that a friend of mine took a quiz. And maybe for that reason, I was exposed to like a sort of nefarious subset of advertising trying to sway my opinion in the most important election of my lifetime. You know, that's I think that's frustrating for a lot of people. But I also think that like these companies, you know, they're money making, profit seeking, growth oriented or even growth obsessed organizations. And so we should be coming to them really with a sort of skeptical eye, you know, in much the same way where we look at an advertisement on TV, you know, and we know that we're being sold to. And hopefully we bring a kind of critical lens to that. You know, nobody should be logging on to Google or Facebook or buying anything from Amazon without, you know, a firm understanding of what you're getting into that, you know, you're you know, might be it might they might say it's free. But obviously they're making money somewhere. And oftentimes your data is the is the asset that's being sold. And so I think people coming to these Internet services with a little more sophistication is actually a good thing. Is there a way back for Silicon Valley? They will always sell tech. People will always buy tech. But can they salvage a reputation of being conscientious? I think so. I think so. I think it's going to take a little a little bit of humility, a little kind of hat in hand, authentic apology apologizing and and then probably the firmer hand of government and figuring out, you know, what what's fair game like the fact that political advertising on television is regulated. But it's really not online is a sort of double standard and contradiction that's really hard to justify. And the fact is that these political battles and elections are being fought and won online now, not on TV or on other medium. So, you know, I think that there is a role for the government to play in regulate, you know, regulating, creating a little bit of a more balanced playing field. But then certainly the Mark Zuckerberg's of the world have to do a little bit better and taking responsibility and addressing some of the secondary negative effects that their companies have unleashed. So these companies that have wronged us need to make amends for their betrayal and the government needs to start introducing legislation to protect us. But what about us? Should we shoulder any of the responsibility for signing away our data? And why is it that no matter how angry we are at these social media companies, we're never quite angry enough to disconnect? Well, because social media has a hold on us. We'll look into that more after this short break. Or everything we've ever known isn't true. Psychology and science in general is self-correcting, but only if we actually do the correcting. And it's great to see that there's more emphasis on doing this correcting and being sure about our hypotheses. To have a listen, head over to theguardian.com forward slash podcasts or search a neuroscientist explains on your favorite podcast. Welcome back to Tips With Everything. I'm Jordan Erica Webber. Before the break, we spoke to tech journalist and author Brad Stone about the scandals that have rocked the Silicon Valley boat and the notion that the people at the helm of many tech companies seem to have gone from hero to zero. But I wondered if the users were also partly to blame for letting companies get away with activities that are laid out in the terms of service. And in the sense of recording, I still have my Facebook account and I bet many of you do too. So why haven't we deleted them? How's your day been so far? A little bit crazy. I've been going back and forth between second and third years, but it's all right. Dr Bianca Wright is an associate of the Center for Post-Digital Cultures at Coventry University and the course director for its BA in journalism. She's been writing about technology for more than 20 years. I wanted to know why when it comes to Facebook, we find it so hard to actually quit. Well, because social media has a hold on us that I suppose we are complicit in a way in that relationship. I mean, how many of us really read the terms and conditions of service when you sign up to a social media network like Facebook or any other kind of application app on your phone? Most of us, we're giving away data as we're doing that and we're not always aware of that. I think certainly Facebook is not the only one that would be guilty of similar kinds of use of data in terms of consumers, but also in terms of how advertisers and marketers use data about individuals, communities, groups of people to target them with particular products and ideas and concepts. So I don't think Facebook is alone in being guilty of this kind of use of data. I suppose the difference is that they've been outed in this particular way. How much blame do you think we can place on consumers then for doing things like not reading the terms of service, like you said? Well, it's about common sense, actually. I don't think it's a matter of blaming consumers because there is a responsibility on the part of tech companies to ensure that what they're doing is ethical and transparent and that consumers are empowered to know what is being done with the data that they are giving to these technology companies. So yes, there is a sense that there is some responsibility on the part of consumers for not reading terms and conditions, for not understanding what data is being collected and how. But at the same time, the buck doesn't stop with the consumer. It stops with the platforms, with the technology companies, with the people who are making decisions about how this data is collected, stored, managed, and then used. And there needs to be questions asked about what we're agreeing to because the average person might not understand, even if you do go through the terms of service, what that actually means and what that may mean in the future. We don't know what the possibilities for data use are in five years, ten years time. And yet we're agreeing to use a service which is collecting a lot of information about ourselves. So what do we do now? Are people supposed to delete their accounts? You know, what's the action we take right now? You know, I don't necessarily think delete Facebook is the answer because it's only one part of the social media ecosystem. And it's a large part, but it's still only one part. And these kinds of applications are going to continue to gather data. Big data isn't going anywhere. It's not something that's just going to disappear because something's happening with it that we don't like. Companies have recognized that it's valuable and that it has the potential not only to offer new services and ways of doing things, but also to be able to target things to particular groups of people. So I think that kind of educational awareness of when I sign up to one of these platforms, when I use this particular app, when I download this thing, when I visit this website, I should be aware, I should be conscious of the fact that information is being collected about me. And I should look for details on what that information is and how it's going to be used so that I can make an informed decision about what I'm doing. So maybe deleting Facebook isn't the answer after all. But what is? Earlier on, we heard Brad suggest that the government needs to step in and better regulate the tech industry, which seems obvious. So I asked Bianca, why hasn't it been done yet? Well, I think in general, legislation and regulation tends to lag behind technological innovation. And I think that's the case across a range of different areas. If you think about the kind of legislation around hate speech and the way that cyberbullying has been approached in various places around the world, not just in the UK. There has been a sense that things lag behind. So I think it's slower to take on as we understand, start to understand what these technologies actually mean. You know, although it feels as though social media has been part of our our media landscape for a very long time, it's actually relatively new. Certainly, if you compare it to things like radio, television and print. And so grappling with the implications of those technologies and what they mean for connecting people takes time to understand what what needs to be done. And I think I think that's part of the issue. I also think potentially there's there's a resistance to wanting to regulate an industry which has been so lucrative, has been so it's grown so quickly. It's resulted in a change in the way that we interact with each other. And and it changes to that will be met with resistance with whichever side of the line you you kind of fall on. And so I think that's probably part of the issue. So what do you think it would take for all of us to say enough? We're all angry about the Cambridge Analytica story, but what would be the last straw that would make us delete our Facebook profiles? It remains to be seen whether people will really abandon social media in droves. I think we've become so used to having it as an option and being so connected all the time. You just have to you know, I'm a mother as well. And and I look at my my daughter's relationship with her devices, her mobile devices from her phone to her tablet to her computer. And I suppose she's lucky. She's 12 years old and she's got access to all of these things. But in a way, she wants to be in that screen all the time. And I've grappled with that as a parent. You know, why does she want to be in there? And then I look at myself and I think, but I'm doing it. I'm modeling that for her. And it's very difficult if you've ever tried to have a social media fast. It's actually quite difficult to do. But I suppose maybe I'm a bit of a skeptic that I think people are, if not addicted, at least so embedded within the social networks that they're engaged with. That it's difficult for them to let go even when they they're aware of the things that are going on. So you implied there that you've tried to do a Facebook fast. How did it go? It didn't go very well. I think part of the problem is that we've blurred the line between this idea of the social and the professional. And going off social media is not an easy thing to do. Certainly it wasn't for me and people that have tried it. Those who've managed to stick it out, and I suppose they're better people than I have found it quite liberating. But it's everywhere you look. It's on every poster, every billboard, every advert, everything that you are watching and seeing and doing. And there's a lot of pressure to be involved in that world. So cutting yourself off becomes quite difficult. When we were discussing this episode in The Office, I learned that one of my colleagues has, in fact, recently deleted his Facebook account. So I'm intrigued. Have any of you joined the movement? And if so, have you felt the call of your newsfeed, or have the inundations of email reminders about what you've been missing during the 90-day deletion process only further confirmed your belief that you've made the right decision? I want to thank Brad Stone and Dr Bianca Wright for joining me this week. You can find a link to Brad's book, The Upstarts, How Uber, Airbnb and the killer companies of the new Silicon Valley are changing the world in the description for this episode on the Guardian website. This week's random tech fact comes from China. Ali Baba and Ford have teamed up to create a cat-themed car vending machine where people with a good credit score can test drive the featured cars for free. If you have any interesting tech facts for us, questions or feedback on the show, or ideas for cool digital stories that we should cover in future episodes, email us at podcasts at theguardian.com. I'm Jordan Erica Webber. See you next time.