 The Guardian. Happy Birthday! Welcome to the world of 29ers! Thank you very much. Oh yeah, I forgot that you're like slightly older than me and this is a bane of our friendship. Yeah, a few months older than you. If you don't follow me on Twitter, which you can do, at jerecaweber, you might not know that it was my birthday recently. In fact, I'm still celebrating it because I like to keep the festivities going for a whole birth month. But I share my birth month with another well-known member of the tech community. You may have heard of it. So this month, Facebook turned 15. I'm Jodhanaerika Weber and this week we look back at how Facebook has grown into the teenager it is today, through the lens of one of its early investors, who feels the company and its creator have lost their way from the original dream. I love Facebook as a product, but I don't know how this is going to come down. We also look at the generation of teenagers who have grown up alongside the likes of Facebook, Instagram and Twitter, and ask whether or not the apps they use today are safe. In a physical playground, it's fairly straightforward that you need to have equipment which is in good shape, that is repaired regularly, that it's been tested to ensure that it's broadly safe to use, doesn't have sharp edges, etc. But in the online context, it's not quite so obvious how that equates. And with a lot of fear about children spending lots of their time on these digital devices, we take a look at how some researchers are suggesting we change the way we measure the psychological effects that screen time can have on children. On the one hand, we have this huge amount of concern covered daily almost in the media and the national and international press, but then we also live in this other world where we look at this numerical evidence on a day-to-day basis and see that there is not actually this compelling evidence which you would expect if you would be looking at the headlines. This is Chips with Everything. So it's celebrating its quinceanera. Yes, I really had to translate that in my head. I do not speak Spanish. Yeah, for those who don't know, the Latin America celebration for when a young woman reaches 15 and enters adulthood. I hope to God Facebook thinks of itself as having come of age before now. I invited The Guardian's UK tech editor, Alex Hearn, into the studio to talk me through the ups and downs of Facebook's life to date. We started all the way back in 2004. Where is this narrative that Mark Zuckerberg as a Harvard student decided to firstly to build this Face Mash app, which was a hot or not game created using images scraped from Harvard student database that let people rank their fellow students and then pivoted maybe at the suggestion of the Winklevi twins, maybe not, into building the Facebook that was a digital version of the Harvard Facebook, a place where students could go to connect and chat with other students. It was fairly different from the Facebook we know now, actually, although on the surface quite similar, it was still profile pics. It was still a wall you post on. There was more poking back then. And I think there was quite a lot less rampant data harvesting. You know, it was blue. So who's Roger McNamy? How does he fit into Facebook's early days? So I've been a technology investor since 1982 and a tech optimist until very recently. So he was one of the earliest investors in Facebook. He I think first got involved with the company about 2009. And probably his biggest link to Facebook is he's the person who introduced Mark Zuckerberg to Sheryl Sandberg, his longtime second in command, Facebook's chief operating officer for more than a decade. Marx recently interviewed Roger for an article for The Observer, where the investor talks about his new book, Zucked, waking up to the Facebook catastrophe. What I was really trying to do was to use my personal narrative to help people understand what matters so that as new news came along, they could interpret it for themselves. He did want to emphasize that, yeah, it's not a hit job on Mark Zuckerberg, but it is not a not happy reading for Facebook either. In his narrative, he watched Facebook from afar for five or six years after he kind of stepped back because, as he put it once, Sheryl came in Zuckerberg didn't really need an external mentor with a lot of business experience. He had an internal second in command with the business experience. He had he had stepped back and been a bit of an external cheerleader for a long time until his views changed. So obviously a big turning point for Facebook and for the world came in 2016, but we will talk about that in a second. Facebook had suffered setbacks before the likes of Brexit and Trump. Can you give us some of the highlights or lowlights, I guess? Well, I mean, so one of the most consequential ones these days is when Facebook was slapped with the FTC's consent decree. Basically, Facebook sat down one day and changed everyone's privacy settings. It decided that everyone had their accounts to lock down. There wasn't enough sharing and it changed them. The US Federal Trade Commission came in and said, no, no, no. If if someone tells you that they want their profile to only be visible to friends, you cannot come in and go, whatever everyone's profile was visible to everyone. That would boost Facebook use and take up. Yes, let's change that. The FTC said, no, if someone gives you a privacy setting, it has to stay that way and you can't justify it by going, oh, well, we introduced a whole graph of new privacy settings. So we reset everyone's to the new defaults, which are weaker. So Roger McNamy was watching all this from the sidelines back in the day. Do we know how he felt about these kind of crises in Facebook's history? We had a wonderful relationship. I liked him enormously. So his feeling about Facebook until he reached these systemic problems that have led to the current huge backlash was basically that Facebook was firstly a really solid business. And he is a tech investor first and foremost. And secondly, that in some ways it was significantly better than the competition. A big thing that he felt was hugely important for it as a social network was it had what he calls authenticated identity. In other words, compared to MySpace or Friendster, the social networks that came before Facebook, in the early days when you signed up for Facebook, you signed up for it very explicitly as part of a real life network of people. And you needed to be verified as part of that real life network. You needed to be at Harvard and say you were at Harvard and other people at Harvard needed to kind of okay that later on that extended to other American schools and then worldwide schools. By the time I joined it, it was quite open, but I joined it as part of my secondary school. And that was a link to a real world identity that no other social network had really done by then. And so for a long time, it looked like a force of good, I think it looked like someone bringing respectability and real world values and making people put their name next to their online speech. The British people have voted to leave the European Union and their will must be respected. The time for empty talk is over. Now arrives the hour of action. Then came 2016, the year the UK voted to leave the European Union, otherwise known as Brexit, and Donald Trump was elected President of the United States of America. This was a turning point in Roger's relationship with Facebook. So in January 2016, I was on vacation with my wife and I imagine that I was a huge cheerleader for Facebook and really proud of the small role that I had played in success. And suddenly I saw things originally around. So he cites the 2016 election, which I think is not uncommon as an example of why people fell out of love with Facebook. He says there were two things that happened around that time that really changed his view of the social network. Well, three, two things in his response to them. The first was that he started seeing a lot of misogynistic abuse of Hillary Clinton on Facebook and he just couldn't understand why and how this strain of what he thought was horrible attacks on Clinton, why it had come seemingly out of nowhere, why it was going so viral on Facebook. And that made him really start to question the value of Facebook in democracy, the role Facebook has to play in the political culture. And the other big thing was the discovery that there was a data mining effort on Facebook to find Black Lives Matter supporters, harvest their profiles and sell that information to police departments. It was a blunt profiling thing. It was absolutely squashing legitimate protest. And again, it wasn't entirely clear that Facebook was really doing much about this. It certainly didn't seem to be actively pushing back against it in a huge way. We should make clear that both of the practices Alex mentions were examples of Facebook being abused rather than Facebook being abusive. Facebook never approved the selling of data from supporters of Black Lives Matter to police departments. Users were simply annoyed that they didn't do more to stop it. And those two things, he says, made him worry for the first time that Facebook might not be a force for good, both in terms of its systemic effects and also the company itself. And the real thing that forced his hand, he says, was he wrote up these concerns in a memo to Mark and Cheryl, which is included in the appendix of his book, the original memo that he wrote. He wrote it for publication and sent it to his friends to say, hey, here is a heads up. I want to publish this. What do you think? And they came back and they basically said, there's not a problem. We've got this under control. Don't publish it because we're going to fix it. But there's not really a problem. And we're dealing with this. He came out going, OK, well, if they've got it under control, and they never fixed it. And he said that for him was kind of the moment he decided that this wasn't something that you could fix from inside the tent that he needed to get a bit public. Eventually I gave up. I just realized that, you know what, they really aren't ever going to change. And so that's when I decided I'd better figure out exactly what happened. To date, neither Mark Zuckerberg nor Sheryl Sandberg has responded to Roger's story about this memo. However, Roger never did publish the blog. He subsequently stopped advising Zuckerberg. And in 2017, he started working with Tristan Harris, who was once a Google design ethicist but left the company in 2016. So the two of us teamed up in April of 2017 and set out to see if we couldn't raise awareness enough to get a conversation going. So Roger and Tristan joined forces to push more generally for Facebook and Google to start thinking about how they have these systemic effects on the world and how maybe actually designing for maximal engagement isn't the only thing that these companies should be doing. So he doesn't speak to Zuckerberg or Sandberg anymore. But unlike Alex, who quit Facebook and thinks we'd all be better off without it, Roger believes that Facebook could be better and more beneficial to society. You know, Mark is an authoritarian leader of an organization that built enormous economic success through a combination of hardwood and billion insights. However, with that economic power came unprecedented political influence and political power. He still thinks that Zuckerberg is a phenomenally talented businessman. I mean, I asked him, does Facebook need to be destroyed? He's the only way out of this, the end of it. And he said no. I think he thinks that a Facebook that paid more attention to disinformation, that prioritized fighting these problems on its platform rather than burying its head in the sand, that one that was just slightly less laser focused on expanding and burying its competitors and more focused on serving its consumers could be good. And he thinks that with, you know, a mixture of consumer and government pressure from the outside, maybe that will get through. So for Roger, Facebook still has some growing up to do. But what about the human beings who have grown up in Facebook's connected world? I think we do owe them, you know, more secure, more safe, more positive environments online. But, you know, perhaps as you know, it's very hard to check the age of young people and children online, exactly. More on that after this short break. It's time to focus. The mood in the UK right now, it seems to me, is a huge set of tensions and contradictions and emotions and feelings about our past. And we're not thinking very much about the future. Today in Focus is the new daily podcast from The Guardian. Join me, Anushka Rastana, for the best stories from our journalists around the world. Subscribe now to Today in Focus from The Guardian. Welcome back to Tips with Everything. I'm Jordan Erica Webber. Before the break, The Guardian's UK tech editor, Alex Hearn, talked us through the history of Facebook, based on the accounts of former investor Roger McNamy. I mentioned at the top of the show that I just celebrated my birthday. I turned 29. If you're around the same age as me or older, then you probably remember a time when the likes of Facebook, Twitter and Instagram didn't exist, when you connected with friends and family by calling them on the phone or meeting them in person. For teenagers today, it's a different story. They've grown up with social media and all sorts of apps that let them connect with people all over the world. Critics have expressed concerns over the safety of these apps, from the possibility of bullying to child grooming. In keeping children connected to the wider world, some apps have let in harm. I am in my 40s, in my mid-40s, a lot of these things are associated with age. So I primarily use Facebook and Twitter and Instagram. If I were 20 years younger, or even 30 years younger, it's quite likely looking at the data that I would use rather different social media. So my kids, for example, would be more likely, if they were typical third-age groups, such as 12 and up, to be using things like Kik, TikTok, Snapchat, I guess, and possibly Instagram. Facebook, I believe, is on the decline. Vicky Nash is the deputy director of the Oxford Internet Institute, with a particular interest in policy around children's use of the internet. Lisa Danielle spoke to her about some of the newer apps that are particularly popular among adolescents. It's probably worth noting that I think often as adults we're a bit behind the curve, so we have to rely on survey data and then market research data to tell us exactly what kids are using. First up, Vicky breaks down the social networking app Houseparty, which is specifically aimed at tweens who want to connect with friends, but whose guardians might consider them too young for other apps. You know, on the one hand, I think Houseparty is good because it doesn't have a search function. So I think it was initially sort of advertised as a way of having safe conversations, video chats with your friends. On the other hand, you know, we all know that an important part of being a tween, being a teenager as you're growing up is taking risks and having live chats, having video chats with friends, but also friends of friends is increasingly a part of that. So the idea that something like a Houseparty to a child, to a parent, is only going to enable them to speak to their direct friends if you like, you know, they're the school friends, their family, is I think a bit naive. So as far as I can see, you know, it is a sort of helpful step. It's trying to discourage the possibility of strangers out of the blue contacting children. On the other hand, it still enables them if they want to have, you know, strangers who contact them, say via Facebook, for example, to add them to their chats on Houseparty. So, you know, none of these things are ever as entirely safe as perhaps they, you know, they initially seem. And there's kick, or as Vicky puts it, Perhaps a sort of riskier version of something like Houseparty in that it is eminently searchable. It enables conversations, you know, not based on your address, but not based on your contact list, but simply searchable. I think there are recommendation systems whereby it will suggest to you people who are nearby, for example. You know, I find that sort of worrying the possibility of combining location information about young people with strangers possibly nearby. One incredibly popular app is TikTok, the Chinese answer to the late, great vine. This app encourages people to upload short 15-second videos of themselves, singing, dancing, or doing any number of things. The app has raised concerns for the safety of younger users, and TikTok recently introduced a feature called digital wellbeing. So yes, as I understand it, there are two elements. One is I think about excessive screen time. So I can't remember, I think it's, I think it's around two hours, you can set it for, and it will tell you if you're not too long. So that's one part. The other is in theory, a sort of restricted mode, which would filter out inappropriate content. You know, a lot of music, a lot of pop videos use, you know, very adult content, or it's very sexualized content. So to me, this was actually one of the worries about TikTok. I have to say I've yet to see exactly how effective that filtering is. I would have thought it was quite difficult to make this completely effective, but at the very least, I suppose it is an improvement on what we had before. Going back to the first aspect of TikTok's digital wellbeing feature, the concept of too much screen time has worried parents since children started to gravitate towards phones and tablets from a younger age. Experts and politicians are often quoted in the media telling the public that use of digital devices can have serious psychological effects for kids. But others aren't so sure. I'm Amy Orbin, and I'm a college lecturer at the University of Oxford. My colleague, Andrew Chubilsky, at the Oxford Internet Institute, and I published a paper in early 2019 where we had a look at why we know so little about digital technologies and how it affects adolescents. It was published in Nature and Behaviour, and it's called Association of Digital Technologies and Adolescent Wellbeing. Amy said that the two academics were interested in exploring this idea that screen time somehow decreases wellbeing in adolescents. And I think what makes screen time such an easy thing to talk about in the media, in the public debate, and in the political debate, is that we can measure it. We can put a timer on it, and we can provide a numerical estimate of screen time. And so it's a very easy entity to work with. That doesn't mean that it's the best entity, but it's definitely the easiest. So how did you conduct your research, and how did it compare to previous studies that you'd seen? So at the moment, researchers don't do enough to safeguard themselves from their own little biases when examining very powerful large data sets. And it has been shown that if they don't safeguard themselves, there can be biases in the results that they find. And this is what we try to address. So it's a very nerdy methodological point. So the research we carried out examines not only one data set, but multiples. So we have three data sets spanning the UK and the US, and we have over 300,000 adolescents data cross-sectionally. So we can't make causal claims, but we can look at a great number of adolescents and see what the association is between digital technologies and well-being. There were thousands of different ways to show in the same data set and with the same research question that there is a negative association between digital technologies and well-being, but there were also thousands of ways that could have found a positive relationship between those two variables or a non-significant relationship. This explains why we're maybe seeing all these conflicting results on a weekly basis. And it also gives suggestions of how we can move forward and actually start understanding what screen time is doing to adolescents. So did you find any indication from your research that there might be these negative effects associated with long periods of screen time, or is it just that we had loads of possible results and you can't really tell which is right? So what we were able to do is we could take a sort of average of all these possible results that researchers could have found and get an indication of what the effect might be that is the actual true effect underlying all of this. And what we did find is that there is a small negative association between digital technologies and well-being. So an adolescent that uses more digital technologies shows lower questionnaire responses to do with mental health. And crucially, this effect is extremely small. So for example, if you would introduce me to a teenage girl who uses X amount of screen time, I could only predict from the amount of screen time she uses 0.4% of her well-being. And we tried to put that into perspective by comparing digital technology use to other things that teenagers do. So we know that teenagers, some eat breakfast and some don't. And we see that eating breakfast regularly has a much more positive effect than digital technologies has a negative effect. And we also know that some teenagers take drugs or drink alcohol, and that has a more negative effect than digital technology use has a negative effect. So we show that when we take digital technologies in general and look at adolescent well-being in general, there is only that very small effect. And we say in the paper that we don't think that merits this great amount of discussion that we have about screen time. And it raises the prospect that we as scientists, but also as a society, need to change the conversation to something that's more worthwhile about digital technologies and how they're affecting the youngest in our population. Amy and Andy's study doesn't lay out all of the effects, negative or positive, that screen time has on young people. It just suggests a different way of finding out what they might be. And I think what this research supports is this notion that parents should really think about what types of digital technologies their children use and what types of people their children are. And adapt how they limit or how they parent these technologies with their child at the heart. So more or less a key takeaway message is that at the moment the evidence doesn't exist to say that screen time is inherently harmful for adolescents. And we need to ask more nuanced questions about what sort of screen time children are looking at and which adolescents might be negatively affected and which adolescents might be positively affected to kind of pinpoint those that we should be worried about in future. And for parents looking for ways to better protect their children who, like many children, do use social media and other popular apps, Vicky Nash has a suggestion. It's something called netaware.org.uk. The NSPCC link is also from their website. And it basically gives you a summary of the most popular apps available that are used by kids and teens. And then it gives you a rundown of the various risks and features. And it's quite a good one because actually it tells you what kids and parents think about it. That's all we have time for this week. There will be a link to Alex Hearn's work, Roger McNamy's book and Amy Orban's study on this week's episode description on The Guardian website. Feel free to send us any ideas for future episodes. Just email us at chipspodcastattheguardian.com. I'm Jordan Erica Webber. Thanks for listening. For more great podcasts from The Guardian, just go to theguardian.com slash podcasts.