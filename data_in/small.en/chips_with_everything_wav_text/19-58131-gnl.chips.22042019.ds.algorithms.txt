 The Guardian. One of these companies called Newswhip put out a report in March that looked at the most viral stories of the year on English-language Facebook, and the story at the top of the list stuck out to me. Last month, just before journalist Will Arimas moved onto his new role as senior writer for Medium's new tech publication, One Zero, he published one of his last stories for Slate, about a particular headline from a chain of local radio stations over in the US. This headline is obviously pretty dramatic, and conveyed the urgency to find the suspect. But it was only meant to have direct consequences for people in that particular local area, a small city in Texas called Corpus Christi. So what made this local news story so important? The person who first shared this story never expected this 119-word news brief to go viral, but it did. No one knows why, not even Will, but it did get him thinking. In 2018, Facebook announced some major adjustments to its algorithms, meant to change what users saw on their news feeds. But just over a year after Facebook announced these changes, this short but alarming headline managed to spread across the platform so quickly and so thoroughly that Will decided to explore further. I'm Jordan Erica Webber, and this week, we look into what a local news story about a suspected predator can tell us about Facebook's algorithms. And I talked to the author of the original study on Facebook Trends so far this year, who helps to shed some light on what it is that makes content most likely to go viral on Facebook in 2019. One of the big things I would say is the fact that love is a much higher proportion of reactions than angry in the top 10,000 Facebook posts is something to be optimistic about. This is Chips with Everything. So when you sat down to start writing this story, what's the first thing you did? Well, I wanted to figure out what was the story. I didn't know that it would be a story, right? It was just a hunch at first. This is odd. One of the first things Will decided to do was to try to reach out to the man behind that original Facebook post. Yeah, his name is Aaron Savage. It took me a little bit to track him down. He writes all of the web content for a chain of five local radio stations in central Texas in the United States, and he is not a person who's accustomed to being in the national news or the national spotlight. He's not even really in the spotlight locally. He kind of works behind the scenes. He grabs news here and there where he finds it, just items that he thinks the station's listeners might be interested in. I take it he was surprised that his story went viral. He was. He had no idea that it was the most viral story on Facebook, but he certainly knew that it went viral, and he was as stumped by it as anyone. He subscribes to some analytics tools himself, and he was able to see the night after he posted it that the numbers were just off the charts. I mean, it was on a scale unlike anything he had ever posted on these sites before. His Facebook post was getting shared at a rate he'd never seen before, so he had pondered this mystery a little bit himself by the time I got to him. I had talked to him about a month and a half after he wrote it. Now, you said that you have a particular interest in Facebook and its algorithms. It seems like this story going viral is kind of counter to what the company has been trying to change about its newsfeed lately. Can you maybe take us back to January 2018 when Facebook announced that it was making some changes and tell us what exactly they did? Right. So the context is that Facebook is always making changes to its newsfeed algorithm, but it made a very big one at the beginning of 2018. This was at the height of the backlash over fake news on Facebook. There was concerns that the social network had broken the media in some ways, and it responded by, in part, saying that it was going to step back from the news a little bit. They wanted to prioritize content from friends and family, reduce public content from businesses, brands and media, and ensure that what public content people did see would, as Mark Zuckerberg said, encourage meaningful interactions between people. The idea would be maybe you'd see more baby photos and wedding announcements and fewer sort of click-baity stories from publishers who were just trying to make a buck getting you to click on their piece and view their ads. It didn't entirely work out that way. People still read a lot of click-baity stuff in their Facebook feeds, but now they're reading it more from stuff that their friends and family are sharing as opposed to from the publishers that they have intentionally followed on the social network. This local story made it past the algorithm. Or perhaps a better way to put it is that it ticked all of the algorithm's boxes, even if it wasn't meant to. The first thing that I thought was, that's a funny headline. You know, it says, our area. Well, if I'm reading that in Delaware, which is where I live, or if I'm reading it in California or Canada or another country, it still says our area. So I'm going to think that there's a child predator and human trafficker in my area. So my hunch was maybe people all around the country, maybe all around the world were sharing the story without actually reading it, because that is the thing that people do on Facebook. They read the headline and they think, oh, I should share this. I should let my cousin know about this. I should let my spouse know about this, because if there's a child predator in the area, maybe our family's in danger. So that was my strong suspicion from the start. That was borne out by the data. It was also borne out when I called the Texas Rangers, the Law Enforcement Authority. In the story, there was a tip line where you could call the Rangers and let them know if you had any information about this suspect. I called that tip line and the person who answered at first didn't want to talk. He said, oh, I can't tell you about any individual suspect or case. That's not my job. And I said, oh, okay. But I told him a little bit more. And you could tell it just rung a belly. I said, oh, is that the Facebook guy? Man, I got calls from all over the country on that guy for weeks afterwards. He said the tip line lit up like a Christmas tree. And he had people calling in from all over the place, not just Texas, because they thought that the story was about their area. So I think that was probably the biggest factor. There are also some secondary factors, because to be the most viral story on all of Facebook, it's got to be a huge confluence of things all working in your favor at once. And we were talking about a story that was more popular than TMZ's exclusive report that Luke Perry had died, more popular than a breaking news story that the US government shutdown had ended, more popular than the viral Momo challenge on the Daily Mirror. This was a wildly popular story. So there are also other aspects of Facebook's algorithm that I think helped to play into this. So you mentioned there that you talked to one of the officials who worked on this case. The suspect has been arrested, right? Yes. The suspect was arrested fairly soon after the story ran. It was not because of any tip from anybody who read the story, although certainly that in theory could have helped. They had leads on the suspect anyway, and they took him into custody. And the tips kept coming in long after the suspect was in custody. And an amazing thing is that no one actually ever wrote the follow-up to say that this person was in custody. So people all around the country, maybe all around the world, were still sharing this story about this guy being on the loose long after he had been locked up and was going through the judicial process. Now Facebook has tried very hard to assure the world that they've heard concerns about how their platform has been used to spread stories. So whether that's worries about influencing important political moments or just clogging up the newsfeed when all we'd want to see really is posts from our friends and family. Do you think that this story going viral is a sign that Facebook's attempts haven't worked or was it just a kind of random fluke that we can't really draw any conclusions from? I think it was a sign that they have worked but maybe not quite as intended. So if the goal of Facebook's newsfeed changes was to make sure that every story we see in our feed is from a reputable news outlet, that it's well sourced, that it's credible, that you can really trust it, then no, it didn't work. And I think it's probably impossible. It's just never going to happen on a network, on a platform that is driven by people seeing headlines and reacting to them on a moment's notice and then scanning through the rest of their feeds. I just think that's impossible. So if that was the goal, it hasn't worked. But the goals were actually, the goals of Facebook's big algorithm change in 2018 were a little more granular than that. This was shared by a local news outlet. So for people who were in the central Texas area, it almost certainly got a boost from Facebook's algorithm that's trying to show more local content. It was absolutely a straight news story. It was informative. So I don't know if it got a boost from that, but it could have. And some of the outlets sharing it were traditional mainstream media organizations. Again, Facebook can't tell us, I can't tell you whether the trusted sources, part of the algorithm played a role in this particular story. But in a way, this story managed to check all of the boxes that Facebook's trying to prioritize with its algorithm and yet still look totally unlike what you might hope Facebook's algorithm would be promoting. One of the other things Will did was reach out to Facebook to see what they thought of the story. What they told me was, yeah, you know, stories, sometimes stories that we don't expect are going to go viral. And that's part of being a social network. I mean, Facebook can make these changes to its algorithm, but it can't control what people want to share with each other. And again, this was a story that people were voluntarily sharing with each other because they thought it might be irrelevant to their friends and family, even if that wasn't in fact the case. Do you see there being a call for another change to the algorithm in the future? So maybe if people use the example of this headline as a way to manipulate how their story might get shared and seen. I'm sure there will be further changes to the algorithm. As I said, Facebook is always tweaking. I think they're at least somewhat earnest in their goal of improving the quality of news that you see in your feed. I wouldn't say it's Facebook's top priority company wide, but within this newsfeed team, this has certainly been a genuine goal for a long time. The levers that they have to pull tend to be cruder than you might expect. So Facebook decides that it wants to show you more stories from trusted sources. Well, how does it decide what sources are trusted? There's no list you can go to that everyone will agree on as to what is a trusted source. And so it did this reader survey that I mentioned earlier. Some enterprising reporters got ahold of the survey and found out that it had only two questions on it. It said, have you heard of this particular outlet and do you trust it? And that was what Facebook was basing its whole trusted sources push on. Obviously you can imagine the flaws in that methodology. It certainly wouldn't pass muster in most academic social science departments. So they're trying, but no, I don't think that they will fix this. And I think it's just an example of the unpredictability of this algorithm and of the entire Facebook dynamic. I think even if Facebook really wanted to tightly control what people saw in their feeds, it's just not built to do that. It's an automated system and it takes input from all kinds of different sources and its outputs that, you know, the results of that algorithm are often going to be unpredictable. So Will came across this story in a study about the broader trends associated with publishing on Facebook. After the break, we chat to its author. It's not just limited to local stuff. It's also a Gillette's new ad, a story about Gillette's new ad from a blog called Scary Mommy was one of the top 10 most shared as well. So there's no hard and fast rule, but local stories often do do really well. We'll be right back. It's time to focus. I think ultimately that ideology is fading, but it will have a sting in the tail and we see that sometimes with these flare ups and violence. Today in Focus is the new daily podcast from The Guardian. Join me, Anushka Resthana, for the best stories from our journalists around the world. Subscribe now to Today in Focus from The Guardian. Welcome back to Tips with Everything. I'm Jordan Erika Webber. This week we're looking at the curious case of how a local news brief about a suspected child predator in a small city in Texas quickly became the most shared news story on English-speaking Facebook globally in 2019 so far. Before the break, tech writer Will Oremus told us how the post went viral. And he came across the story when he was reading a report on Facebook publishing trends. Hello. Hello. Hi there. Hello. Hi, that was a very quick answer. You shocked us there. How are you? I'm good, thank you. How are you? I'm good. This is Jordan, the presenter, by the way. Naturally, I wanted to see what else we could learn from this study, so I called up the person who wrote it. My name is Benedict Nicholson and I am the managing editor at Newswhip. So what exactly does Newswhip do? So Newswhip is a company that tracks social content, basically. So we look at content that's created on the web and natively on social and we see how it's performing on the social channels. So how many engagements a web link might get, for example, or a Facebook post or a tweet or how many pins a web link might get on Pinterest. So we track those social channels and how content performs on those social channels. You recently published a report that looks specifically at Facebook. So can you tell me when you released the report and what it was called? So in the middle of March, we published a report that looks specifically at how content is performing on Facebook. We called that the 2019 Guide to Publishing on Facebook. On the web, we looked at two things. We looked at web content and how that was performing on Facebook. So URLs, content that was written specifically for the web and how all English language content was doing and picked out the top publishers, some of the top stories, the top types of content that were involved in that. And then we also looked at Facebook native publishing. So when I say Facebook native publishing, what I mean is native videos, photos that pages upload or links to content that pages post specifically. And we looked at the top Facebook pages that were doing that, the formats that were performing the best, what was driving the most shares, comments, all that sort of stuff. So the primary goal of this was to look at the ecosystem kind of what's performing well. Simply on Facebook, we do often do other things, but this report was just focused on Facebook. In case there's anyone listening who's a little bit confused by this, can you explain what native means? So native video is a video that is essentially, for all intents and purposes, hosted on the Facebook platform. So it's not a link out to another website. It's not a link out to YouTube. It is in the Facebook post as part of the Facebook post, if that makes sense. Okay, so who has been the most successful publisher on Facebook so far? Well, I should caveat this with the fact that our data from this tool includes local affiliates as well. So when I say Fox News, that also includes Fox 5 DC and the New York local channels, but it has been Fox News followed by NBC and then the BBC. So the top English-speaking publisher on Facebook so far this year was Fox News. Most of the top publishers fell into the so-called hard news ranking. The Guardian was 13th on the list. Behind LadBible and Breitbart News. Benedict also looked at the publishers with the highest proportion of comments and shares. So that does change it. So then you get sites like the LadBible and Delish.com, which is the food publisher most of the time, and The Sun. And they've all got over 25% of their engagements to their web content comes from comments. We do the shares as well, and that changes the picture again. And for the shares, you often get more local stuff. So the publisher with the highest proportion of shares is actually Reuters. And 50% of Reuters' engagements come from shares rather than likes or comments. And Patch.com is similar, which is another local news site in the US. And that's nearly 50% of their engagements come from shares as well. So this is where we get to the crux of today's episode then, which is that the most shared story on Facebook so far in 2019 is this small local crime brief that was originally attended just for local people to see, but which went viral with more than 800,000 shares in its first six weeks. So what other kinds of stories make it to the top 10 by shares? Shares often, local stories will do really well because people will be driven to share it with their community of friends on Facebook, and specifically, if it's something that affects their community, they will do really well. So there were a couple in there about the Amber Alerts, and I'm sure you saw the Momo Challenge that went viral too a little bit. But also other things, so it's not just limited to local stuff. It's also a Gillette's new ad, a story about Gillette's new ad from a blog called Scary Mommy was one of the top 10 most shared as well. So there's no hard and fast rule, but local stories often do do really well. Those stories that saw the highest level of engagement on Facebook were often those that might invoke a strong emotion, whether that be a shared sense of sadness, like the death of actor Luke Perry, or even anger, which stories about topics such as abortion can provoke. Benedict looked into which publishers garnered the angriest responses to what they posted. So yes, that's a little bit different, so that came only on Facebook native content, which is, as I said, native videos, photos and links. And we looked at the publishers with the most angry reactions, yes. I would say that while some of these publishers do have a baseline of angry reactions, it tends to be political publishers. The top 10 for these includes Fox News, CNN, The Daily Mail, Breitbart News and The New York Times. But if you actually look at the top 10,000 Facebook posts, the amount of angry reactions to those posts is actually very limited. There are approximately eight times more love reactions on the top 10,000 Facebook posts than there are angry reactions. So while some publishers do have quite a high proportion of angry reactions, in terms of the very top content, it's not anger necessarily that is there. And talking about native content, is it true that the most popular Facebook posts are native video still? Yes and no. So if you look at the top 10,000 Facebook posts, about half of them are photos and about 40% of them are native videos. Now obviously there are far fewer native videos, so the fact that there are just more photos in the top 10,000 posts is partly because there are just a lot more photos. If you look at the average engagements by post type, native videos, this is among the top 10,000 posts, native videos have the highest average engagements and then followed by photos, followed by live videos, followed by links. But actually that changes if you look at the average shares or the average comments. So shares native video is still top, but if you look at the average comments by the post type, and it's a smaller sample size, but live video has the most comments by a long way. What would you say is the most important takeaway from this report? Do you think that we should be worried about how we engage with Facebook or is it maybe getting better? I think there's a few things to take away from this. I think we're certainly, there is more engagement to content on the platform, both in terms of web content, particularly in terms of web content, actually native content is around the same. There is a lot of political stuff, particularly among the web content, but I think that's just a reflection of where we are as a society right now or a group of societies. But also I think that there is a lot less anger than maybe we think there is. And I think one of the big things I would say is the fact that love is a much higher proportion of reactions than angry in the top 10,000 Facebook posts is something to be optimistic about. So engagement on Facebook went down in 2018, but has increased again in 2019. Whether or not this is because the company changed the way their algorithm works is uncertain, but I went back to Will to see what he thinks. It suggests that the impulse to share news on Facebook is real and it's not going away. And even if Facebook tries to become more of a social network again and less of a place to read stories from the web, that's not going to be easy to do. People like to share stuff that they find online and that's a behaviour that has continued even in the face of Facebook's attempts to step back from being a news source. That's all for this week. Thanks to Will Arimis and Benedict Nicholson for joining me. If you have any thoughts on this story, make sure to send us an email at chipspodcastattheguardian.com. Chips is produced by Danielle Stevens. I'm Jordan Erica Webber. Thanks for listening. For more great podcasts from The Guardian, just go to theguardian.com slash podcasts.