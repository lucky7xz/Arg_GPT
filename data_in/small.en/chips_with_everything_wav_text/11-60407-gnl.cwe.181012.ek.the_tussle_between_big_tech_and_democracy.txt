 The Guardian Big tech. You've probably heard the term. We've almost definitely used it on this podcast. But you might not have known that it's commonly understood to stand for just four companies. A small group of giants, credited with driving growth in technology and thus societal change. No prizes for guessing who these four are, but if you do want to play along anyway, I'll give you a moment. Google. Apple. Facebook. Amazon. There are plenty of ways to consider the power these Silicon Valley giants have, the compulsive holds they have on us, the sheer volume of users and the data that comes along with them. And one area in which this power has come under particular scrutiny recently is in the influence big tech has on our elections. That's the culture of today, that things in our lives as consumers seem so easy and yet politics remains so hard. Last week we talked about one of the tools of big tech, as we looked at the power of algorithms when combined with big data. Today, we take a closer look at the effect this data-fueled big tech is having on politics. Is the brave new digital world actually affecting our political process? Could it even render democracy obsolete? Unfortunately if you're completely overwhelmed with information 24 hours a day, you can only really start to make sense of that. If you use your emotional heuristics, if you say, well I don't agree with those people, these are my people, that opinion suits my pre-existing view. I'm Jordan Erica Webber and this is Chips with Everything. To answer these questions, I wanted to talk to someone who spends his life thinking about the effects of technology on society. My name's Jamie Bartlett, I'm the author of The People vs Tech and a couple of other books, Radicals and The Darknet, and I run a research centre at the Think Tank demos. Jamie joined me in studio, where I began by asking him about what he describes as a bitter conflict between technology and democracy, and what exactly he means when using these terms. Good question, because obviously both democracy and technology are sort of malleable terms. So I really use democracy to mean the system of democracy we have at the moment, so liberal representative democracies in advanced economies. And frankly, that just didn't seem that good of a title on the cover. So I use shorthand a democracy. And for technology again, I don't mean the power loom or a cooker, I mean those sorts of technologies, digital technologies that are associated especially with Silicon Valley. So social media, internet enabled devices, artificial intelligence, networks, mobile phones. And the reason that those definitions are actually quite important to get right is because essentially the argument is, pretty simple one, the democracy that we have now was built at a very particular time, particular set of institutions and norms and rules. And suddenly this new technology comes along, digital technology, it doesn't follow the same rules or norms. And the two things are just in a sort of bitter clash. And we see that in lots of different places. Okay, so I'll ask you for some examples in a second. But first of all, so you're saying that it's this very specific kind of modern technology then that's odd with democracy. It's not the case that inevitably all democracy and all technology are at odds with each other. No, no, no, of course not. And to be honest, to be even more specific, I suppose, the way that the internet in particular as currently constituted is at odds with how our democracy works at the moment. It's getting more and more specific every minute, the longer we talk, isn't it? But that is essentially the argument. And I think that's more useful as a frame than saying, oh, there's these rapacious capitalists in Silicon Valley and they're evil and they're doing these bad things. Because I think it's just, it's a lot more fundamental than that. I mean, we're going through such a great revolution in our information system and our production system that it's almost inevitable that a set of governing institutions that we have that were built a very long time ago aren't going to work that well. So give me some specific examples then of particular battles between democracy and technology. Oh, I mean, okay. There's so many. What's your favourite? My favourite that's most topical is the obvious one of Cambridge Analytica. The fact that we can now have targeted adverts at unique individual users that can fly below the radar of the regulators who have been set up essentially to monitor billboards and TV ads and leaflets. They're not set up to be able, and the rules aren't there, to be able to monitor highly personalised targeted adverts through digital networks. And that to me is the kind of core of the problem. There's a lot of stuff talked about, including in your newspaper, may I say, about the way that elections have been sort of swung one way or the other with some of these techniques. I think the biggest story beneath it though is actually how it's fragmenting politics. If you imagine in 10 years' time, the continued development and advance of personal profiling, targeted advertising through smart devices in your home, ever more personalised to your sort of specific interests and concerns, how in 10 years one candidate will be able to send a million different messages to a million different people. How on earth do we hold that candidate accountable? How do regulators see the adverts? That's the big story. And that's partly a problem of regulation not catching up, as much as it is a problem of data analytics firms acting in a shady way. So that's a very obvious one with rules, but you can also think about it in terms of culture. I sometimes use the example of, do you remember when you used to get your photographs developed at Boots, at pharmacies? Are you old enough to remember that? You're not. You got me. Not quite. Okay, okay. Well, I remember after your holiday, you would come back and you'd spend three quid in Boots getting your photos developed and you'd wait two weeks and most of them would be rubbish because they'd be overexposed or underexposed or whatever. And I think young people looking at that must think, that is crazy that you did that because now we're on Instagram and it's simple, immediate, quick, perfect. You can retake as many as you want. You can send them to anywhere in the world. Politics is still like going into Boots to getting your photographs developed, but the world has moved on to Instagram. And I think those cultural norms about having things as you want, when you want them, without compromise stands in great contrast to the plodding realities of a representative democracy where you vote once every five years. And I think that is partly what is fueling a sort of growing frustration and anger with mainstream politicians and helping people on the fringes who promise the world. I mean, essentially the populace of the world as I see them are basically Tinder politics, you know, swipe left or right, but you will get exactly what you want with no questions asked. So this is, this is both a question of rules and norms and how they're just out of sync with each other. The term Tinder politics might prompt mental images you'd rather avoid. But what Jamie is talking about is the sort of instant gratification that technology has led us to expect. Like beautiful photos on Instagram and instant hookup on Tinder. Traditionally, democracy doesn't work like that. But if we have those expectations, that's bound to have an effect on the kinds of politicians we end up electing. Okay, so Tinder politics, as you just described it, that is that how we got Trump? And is that what you're saying? Yes, it is what I'm saying. Yes. Okay. But as if you listen to the way that he speaks, if you listen to the way that his supporters speak, it's incredible, amazing promises. It's things that are just unrealistic and impossible. But play to that sort of notion that there's people in charge making things slow and difficult and they're corrupt and they're part of the swamp in Washington. You just need to vote for me and I'll solve all of this and swiftly deal with all of these problems. Whoever knew that health was so complicated, said Trump. That's the word of somebody that spends his life on Tinder. I'm not saying he spends his life on Tinder. But that's the culture of today, that things in our lives as consumers seem so easy and yet politics remains so hard. So I think that Trump, in a sense, is the first digital politician. He sort of understands the medium. And this is even before we get into the fact that what tends to spread well online, this is now old hat, but it probably wasn't a couple of years ago, is stuff that's outrageous and emotive and sort of furious and angry and polarizing. Whether it's true or not is secondary to how likely it is to spread. And he specializes in that sort of content. So you're kind of painting this as an inevitable future. You know, if technology keeps moving along at the pace it is, then these things will just happen. But it seems like there must be a way to stop it, especially if the problem is as simple as, oh, democracy just hasn't kept up with technology. That's not simple. Well, I mean, it's a short sentence. Some of the hardest problems are condensed into short sentences. So how much have you thought about how we solve this problem then? I guess the conceit of it is to take everything else out and just say, if we just carried on, this is where we end up. And I know that's not how politics works. We come up with solutions. And the purpose of the book really was to get people to think about those solutions and those problems and sort of give a sort of push to the movements out there that are saying, right, what are we going to do in response? How do we retain our free will? And how do we do this? And how do we regulate these ads and worry about big monopolies? And it's actually amazing since the book came out. There's been so much change. I mean, people are really motivated and doing stuff. And that's not because of the book. Actually, a lot of it is due to the observers reporting on Cambridge Analytica. I mean, I think the way that story exploded really put into people's minds that weren't thinking about this at all, the risks of some of these techniques, these big data techniques. So what I did was to put in 20 sort of recommendations at the end, 20 things to save democracy, partly because... It's very BuzzFeed. Yeah. Oh, God, thanks for that. Kiss of death. I mean, I guess I had to sort of put in some ideas, some suggestions, like here's some things to do. But I couldn't be too detailed about it because if you get into the real nitty gritty, it's a short book. So a lot of them were quite generic. And the editor said, you've got to say some positive things. People want answers. They don't want you to just moan about problems. So some of them are for regulators and for governments, but some of them are for people. For example, you, reader, are partly complicit in this because you, dear reader, are also sharing all of your data all the time and trading convenience for privacy. And I'm culpable too. And you may consider that your data use has political ramifications. Maybe think about it in the same way you do about going shopping and buying fair trade, coffee and free range eggs, that your political, your data choices really matter. So you talked there about people giving their personal data away and the challenge that that presents to liberal democracy. You warn in the book that this might lead to a moral singularity. What do you mean by a moral singularity? Yeah, I made that one up and I'm quite proud of it. So technologists sometimes talk about the technological singularity. And the idea is that at some point around 2050, says Ray Kurtzweil, the great futurist, computers will be able to make faster and faster versions of themselves, better versions of themselves. And at that point, it spirals off into a sort of self-replicating cycle and humans are left in the dust. And I think more likely, or at least something we can do something about, is a moral singularity where machines are capable of making important moral decisions for us better than we can, whether it's who we should vote for, what trainers we should buy, you know, what, I mean, a little bit like these voter apps that tell us in which party would be most aligned to our interests. I can well imagine a personal assistant giving you actual advice about moral quandaries in your life. And the problem with that is, if we don't constantly and repeatedly use our critical faculties to make moral choices, we just become less able to do them and we'll rely more and more on machines to do them for us. And that's something that you see people rely on Google Maps all the time already. And I'm saying that that kind of thing can happen in our moral lives as well as our sort of practical lives. So have human beings already relinquished control to the technology we've created? Or do we just need to re-educate ourselves and fast? With the ever-increasing effect that social media and other Silicon Valley products have on our lives, the risk for exploitation continues to grow. Will someone step in and solve this problem for us? And who can we blame in the first place? I think they're as surprised as all the rest of us. They didn't think it was going to turn out this way. They're not evil geniuses trying to overthrow democracy. I think they've been surprised by how their technology's been used, but that doesn't make the responsibility of them. Don't go anywhere. We'll be right back. In this week's Books Podcast, we celebrate Super Thursday, the biggest day of the year in UK publishing, with travel journalist Simon Reeve and his memoir Step by Step, and Neil McGregor on his successor to the history of the world in 100 Objects. We bring you talking mummies, mammoth horn sculptures, ethical tourism, and the joys of Bill Bryson. Where else can you find that kind of range? All in this week's Super Guardian Superbook Super Podcast. Welcome back to Tips with Everything. I'm Jordan Erica Webber. Before the break, Jamie Bartlett broke down the bitter conflict he sees between technology and democracy, and explained how our desire for instant gratification has led to a kind of Tinder politics, where we elect politicians who make promises they can't keep. Now we'll rejoin Jamie in the studio to discuss another damaging effect he thinks technology has had on democracy. An increase in tribalism, a state in which people are divided into distinct groups. Here in the UK, we got a stark example of tribalism in politics in mid-2016, when voters were split roughly down the middle over whether or not to leave the EU. Loyalty to one's chosen side was, and is, as firm as support for one's favourite football team. Our tribes even have names, levers and remainers. So how has Silicon Valley, as Jamie puts it, let tribalism out of its cage? I don't know if you've sort of noticed that politics feels like it's getting more stable. And this is again, it's something that's very hard to sort of measure precisely. But the idea that you're either on this team or you're on that team, and whatever your team says is great, and whatever the other team says is bad. This is not a smart way of conducting politics. There's some tribalism inherent in all politics, especially two-party systems, but you have to be able to compromise with other people. You have to be able to believe that they're acting from principled differences of opinion, rather than they're evil, Machiavellian or stupid. The problem I think is that Silicon Valley accidentally let that tribalism back out of its cage by connecting everyone all the time. So the assumption was if you connect everyone, and if you give people unlimited information, we'll all sort of become wiser and more informed, nicer, kinder. Politics will become less tribal because we'll all be connected. But unfortunately, if you're completely overwhelmed with information 24 hours a day, you can only really start to make sense of that. If you use your emotional heuristics, if you say, well, I don't agree with those people, these are my people, that opinion suits my preexisting view. And even when you see opposing views, when you see them briefly online, rather than when you're talking to a friend about it, you're much quicker to dismiss it as wrong or moronic because you don't engage with it fully. So I think this idea that we're in echo chambers is completely wrong. I'm surrounded by other ideas all the time online. I just don't pay much attention to them. I just think they're all crazy. And so this is, I think, what's driving a kind of tribalism that's making compromise more difficult. And you can see in voting records in the US that the parties have never been further apart since the war. You can see in voters across a range of issues, US voters are now more polarised and more extreme in their positions. So it's almost like you're saying the more we're exposed to opposing views, the more we oppose them. Unfortunately, if you look at literature and why people change their minds, it finds that people will change their minds on important moral questions if they discuss it with somebody, but only if they discuss it seriously, sensibly, over a long period of time, if they can gain the trust of each other. The more we can, unfortunately, the way the internet is set up does not facilitate that form of discussion. It facilitates quick smash and grab discussion. So it does, I think, drive us apart. Yes. The more we are exposed to views that are short, shouty, immediate, condensed, then the more we do disagree with each other. But that's not to say that there's no way around these problems or we can improve the way that the system is set up. Because I think for many people, the opposite is true. There are a lot of people that have found they've learned things from other people. I feel like I have learned lots of things from other people and my horizons are constantly opened. But I'm also subject to the same problem, which is I start to dismiss other people quicker than I used to. I think they're wrong. I think they're bad. There's an old phrase which I think is not picking, which is finding the craziest person who is part of the political movement you disagree with and then assuming everyone thinks like they think. And electing him to be president. Well, yeah. Right, exactly. So, I mean, it sounds like maybe a solution to this then would be to limit the number of people we can interact with online and also to have a minimum character length for tweets. So we have to have really in-depth discussions and we're only allowed to have them with a smaller amount of people. But this is not something for governments to tell us. This is something for us as citizens to realize is happening and think, you know what, I'm going to go and read other people's views on this and I'm going to listen to them properly and with respect. And I'm not just going to dismiss them as crazy Marxist or evil racist or whatever. I'm actually going to listen to them and try to understand where they're coming from because it's never been easier to find different political opinions as it is now. We can find them all the time. But we need, this is what I'm saying about the norms changing. We haven't learned in school how to engage with information like this properly. We haven't learned either the critical thinking or the psychological weaknesses that we have when we deal with information online or why we change our minds or how to engage with complex arguments with different people. These are the kinds of norms that we need to adjust in schools. This is another example of how we haven't kept up with the technology. Nowadays, we have immediate access to more information than we could ever possibly consume. This change happened so suddenly that we didn't really have time to sit back and consider what effect it might have on us. Jamie thinks that we each need to make that consideration now and try to be more patient and engage more thoughtfully with that information and, importantly, with other people. But can we really place all this blame on the internet? Haven't human beings generally thought and acted more or less the same for centuries? I asked Jamie why it's so important for us to focus in on modern technologies. I think it's important to focus in on it because we're still really at the beginning of the revolution, the digital revolution. So it's only going to play a deeper and deeper and more important role in our lives. And it's quite important at this point that we kind of get it right, how we've shaped the incentives, how we have regulated the way information moves. These are incredibly important and difficult questions. And I know it sounds like I'm blaming the internet, but this is why I sort of use this idea that there's just two worldviews clashing because I think it takes some of the blame away from the internet and puts it on democracy or the way we govern ourselves. It's just not having caught up yet with it. And that's sort of everybody's fault. And it's our fault as citizens as well, like the way that we behave. So I think everyone's got a little bit of blame in there. But there are things where, unfortunately, the internet, the way that the incentives work, especially the ad systems, they don't change human behavior, but they turbocharge some of our kind of weaknesses. They've turned our tendency to enjoy clickbaity stuff, which we always have, into an industrial scale assault and worked out ways of monetizing it. And they've got to take some of the responsibility for that. So it's not all of their fault, but there's definitely some things they can do. And the thing is, I think they're as surprised as all the rest of us. They didn't think it was going to turn out this way. They're not evil geniuses trying to overthrow democracy. I think they've been surprised by how their technology's been used, but that doesn't take the responsibility of them. OK. So you've got this conflict between technology and democracy. We want to keep them both. So both sides of this war need to make some changes. What's the one big change that technology needs to make? What's the one big change that democracy needs to make? Well, I mean, I think the bigger change is the one big thing citizens have to make in understanding the choices they make are complicit in this system. But the one thing that technology has to make, I suppose, looking ahead, there are some moves that need to be strongly encouraged to really figure out how they are going to build artificial intelligence responsibly, use it responsibly, regulate it responsibly. I think they need to be far more open with allowing, like no longer seeing government regulation as just some kind of meddling in their wonderful kit, but an important way of living together with this tech. So algorithmic accountability, the idea that algorithms will make important decisions and we as a society need to hold them to account, means they are going to have to open up their, they're going to have to lift up their bonnet and let government people in to look at how their systems work. And they really don't want to do that, but they are going to have to do that, especially as AI plays a bigger role. And as for governments, well, the one obvious thing is, I mean, firstly, we have to make sure that the regulation of digital advertising is up to the same standards as television and billboard advertising. That's not even very hard. The irony is all this stuff about Cambridge Analytica, in my view, it's the easiest thing to regulate. All we need to do is pass some piece of legislation that basically says every political party has to publish every online advert that it runs, who it's targeted and how it's targeted them. It's not that hard. And at the very least, that would introduce a bit more confidence in the way that the elections are being run. Do you think that's likely? You know what? That I actually think that is likely because the electoral commission is saying it, the information commissioners office is saying it, the Labour Party is saying it. So I think this is one of those few things that we can all agree on and we will get done. As far as citizens, then, since writing this book, how have you changed the way you live your life to help with this conflict? Well, I, like many of us, am engaged in a constant and endless battle with my smartphone for my attention. And I've sort of started to see this as my duty as a citizen to work on, like you would your fitness or your diet or anything, your ability to concentrate and focus. So the usual stuff about switch off times and not checking at this time and not bringing the phone into the bedroom and dah, dah, dah, dah, dah, dah, lots of different techniques that you can use. And I think that's, I think everyone needs to do that. Everybody needs to do that. So that's the number one thing I try to do. And I think that the rest of us should too. Big tech is incredibly powerful. But perhaps it's wrong to place all the blame on Silicon Valley and better to consider Jamie's characterization of the problem as a conflict between them and democracy as it currently stands. So big tech needs to be transparent and accountable and governments need to regulate, which Jamie thinks should be relatively easy. But we regular citizens can't just leave it up to the powers that be. The internet may turbo charge human behavior, but if we're not going to get rid of the internet, then it's up to us humans to take more care over how we use it. I'd like to thank Jamie Bartlett for joining us on the show this week. You can find out more about his book, The People vs Tech, on the episode description on The Guardian website. What do you think about my idea to have a minimum character length for tweets? Let me know by emailing chipspodcast at theguardian.com. This episode of Chips with Everything was produced by Eva Krzyzjak. I'm Jordan Erica Webber. Thanks for listening.