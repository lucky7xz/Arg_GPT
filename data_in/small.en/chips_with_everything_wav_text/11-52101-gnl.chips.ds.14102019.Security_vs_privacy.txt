 The Guardian. What we have so far is information that up to three people had entered the building and had opened fire on people inside of the building. We do have some preliminary numbers of upwards of 14 people that are dead and upwards of 14 people that are injured. On the 2nd of December 2015, a husband and wife walked into an office Christmas party for employees of the San Bernardino County Department of Public Health in California. They started shooting, killing 14 people and injuring many others. The mass shooting prompted arguments over America's gun laws. There are some steps we could take not to eliminate every one of these mass shootings, but to improve the odds that they don't happen as frequently. Common sense gun safety laws, stronger background checks. But another debate was brewing in the background. A couple of months after the shooting, the FBI and Apple fought a legal battle over whether or not the company should help authorities to break into a phone used by one of the shooters. iPhones have a feature that blocks access if the password is guessed incorrectly multiple times. The FBI wanted Apple to disable it. Apple wouldn't comply. The tech giant, which positions itself as the privacy company, argued that agreeing to these demands would open up a Pandora's box that would sacrifice the trust of users. In the end, this battle fizzled out because the FBI found another way to break into the phone. But the wider argument didn't end there. I think what it showed up was that actually Apple probably weren't able to get into the phone. And that's one of the things that's been a hallmark of this whole debate, is that they've set up these systems precisely so that even if somebody comes to them with all the appropriate legal authorities, they cannot do it. The question of which takes precedence, security or privacy, has been hotly debated since the start of the digital era. US Attorney General William Barr is urging Facebook to give up on plans to encrypt messages across its platform. He signed an open letter along with senior figures from the Australian and the British governments as well, which argues that people's safety could be at risk if the company employs end-to-end encryption in all of its messaging services. In the last couple of weeks, Facebook has stepped into the ring, with its plans to expand its use of end-to-end encryption on all of its messaging services, denying authorities access to what they argue is vital in order to protect people from heinous crimes like terrorism and online child abuse. So will governments from around the world, and the biggest players in Silicon Valley, ever find a compromise? I'm Jordan Erica Webber, and this week I look at what the latest battle between governments and big tech says about where we draw the line on privacy versus security. This is Chips with Everything. Hi, it's Jordan, how are you? I'm good. We're having a very strange technology day in the Bay Area today because we're about to lose power for a week. Julia Carrie Wong is a technology reporter for Guardian U.S. based in San Francisco. She recently reported that Facebook was going full steam ahead with its plans to implement end-to-end encryption across its messaging services. Earlier this year, in the spring, Facebook announced that they wanted to take all of their various messaging platforms, so that's Facebook Messenger, WhatsApp, and Instagram Direct Messages. And they wanted to combine them, you know, integrate them into one universal Facebook messaging system, and that they were also going to take the end-to-end encryption that is already in place with WhatsApp and apply that across the entire platform, which means that people's messages would be encrypted, the meaning of the messages would never be visible to Facebook itself. It's encrypted end-to-end, so the message itself is only visible to the person who sends it and the person who receives it. Before we got into the criticism of these plans, I wanted to understand a bit more about encryption. Right, well, to explain end-to-end encryption, it's worth taking a step back to where things were really pre the Snowden revelations. Professor Alan Woodward is a security expert at the University of Surrey and a consultant to Europol. He says it took the leak of the biggest cache of top-secret documents in history to make the public start demanding greater privacy. When you sent a message, typically, in a messaging app, it would be secured in the same way that things are secured when you go to a website. So you see the little thing, the padlock, HTTPS, it's a thing called TLS, and so from you to the server, it would be encrypted. And then from the server on to the recipient, it would also be encrypted using the same method. But whilst it was out of the server, of course, it wasn't actually encrypted. And what various law enforcement agencies would do is with appropriate warrants, they could sit at the server and intercept those messages. We have breaking news. I'm just going to read it straight off the Washington Post. The United States has charged Edward Snowden with espionage. Here's the quote. The computers have filed a sealed criminal complaint against Edward Snowden, the former national security agency contractor, who leaked a trove of documents about top-secret surveillance programs. The United States has asked Hong Kong to detain him on a provisional arrest warrant, according to US officials. What they then did was after the Snowden revelations, a number of big tech companies responded to worries that were being expressed by the end users, who, of course, you've got to remember are global and not just US or UK oriented, and they were saying, well, we want to be sure that even if a government comes up to you with an appropriate authorization, you can't listen into our messages. And so what they did was introduced end-to-end encryption, which is where the keys for the secret conversation, the shared secret, is only shared between the recipient and the sender. It's not stored anywhere else. Typically, it uses a thing called Diffie-Hellman key exchange, which has been known about for decades. And it's a way of, you can't break it, it's the laws of mathematics, it's a way of exchanging things such that only those two participants in the conversation actually have the keys to the conversation. How common is the use of encryption in companies? Do they just all use it? Well, we all use it. Everybody uses it without realizing it. This is part of the problem. This is the sort of the conundrum. We need it for visiting websites, for sending your emails, for whatever. Anything that goes over the web these days is typically encrypted. When you see that little padlock of HTTPS on a website, you are using encryption. You've got to understand that encryption really is, I suppose, it's the bedrock now of everything. You can't sit on a line somewhere with sort of metaphorical crocodile clips and actually listen in. It's not like old phone calls anymore. And one of the problems is that in the good old days of surveillance, you used to be able to pick out encrypted data because it was gobbledygook, it was scrambled. So if something was encrypted and was intercepted, you could imagine it would be of interest. So those conducting surveillance would zero in on things that were encrypted. But now everything's encrypted. It's very difficult to pick out. I mean, it's just all noise. So how do you pick out what you actually want? There's a whole different set of techniques now I've developed. So it's not unusual for companies to use encryption to ensure that data from clients or staff is safe. Authorities have long been frustrated by how long it takes to access data that they think they should be able to see. Facebook has been criticized in the past for not doing enough to protect its users' privacy. And they say that this is their way of trying to do that. But people have found fault with this plan. The governments right now are focusing very much on saying that if Facebook encrypts all of this information, that will take away a tool that law enforcement agencies and governments have had to investigate really terrible crimes like child abuse imagery, child sexual exploitation, terrorism, and other kinds of transnational crime that might be taking place on these platforms. So some of the concerns against end-to-end encryption have been laid out in this open letter to Mark Zuckerberg at the start of October. Who wrote the letter exactly and how did it come about? The letter was written by the US Attorney General William Barr, the US Acting Secretary of Homeland Security Kevin McAlenan, and then the UK Home Secretary Priti Patel, and also signed by the Australian Minister for Home Affairs Peter Dutton. And I think it's important to note that this letter, it has no legal effect. It's a shot across the bow. It's a warning. At the moment, these governments don't actually have the power to force Facebook to do or not do something that Facebook wants to do with its platform. But what these three countries are saying is that they're issuing a warning. They're saying that we are going to publicly fight you on this. It is possible that they will try to push for legislation, but that of course would have to go through all of the democratic processes to get legislation. But they're basically saying we're preparing to wage a pretty public battle and we are going to make our argument on the sympathetic cases that if you do this, you are going to be enabling child exploitation and you're going to be enabling terrorism. So this was, you know, it was not kind of a legal or regulatory letter, but it was very much trying to set the debate going forward if they attempt to make some kind of legislative or regulatory action. After the break, we'll talk more about why Zuckerberg is likely to ignore the requests outlined in the letter and why the idea of decryption is potentially more dangerous than encryption. It's a very good example of where now you can go online and you can buy copies of those keys. So you've effectively rendered the lock useless. And the same thing would happen if, you know, if you had a master key, some, you know, the bad guys would discover it. It's like leaving the key under the mat. Once somebody knows it's there, they'll find it. We'll be back after this. The way things are isn't the way they have to be. But knowing what to challenge and how to change it isn't always clear. That's why independent journalism has never mattered more. When we are free to follow any lead and question any authority, we can confront the status quo, uncover vital alternatives and bring clarity to the world's most complex. We can help our readers understand the world. So together we can fight for a better one. Hope is power. And with your support, you'll always find it at The Guardian. Welcome back to Tips With Everything. I'm Jordan Erica Webber. This week we're looking at one of the biggest questions of the digital era. How do you protect people's privacy while also ensuring their safety? Before the break, The Guardian's tech reporter in San Francisco, Julia Carrie Wong, told us about an open letter signed by representatives of the US, UK and Australian governments to Facebook founder Mark Zuckerberg. The intention of the letter was to encourage him to create, quote, a means for lawful access to the content of communications. In other words, a backdoor option for authorities to access fully encrypted data from the company's messaging services if and when those authorities deem it necessary. I asked security expert Alan Woodward to explain what that might look like. Basically it would look like things were before the Snowden revelations and before they put end-to-end encryption. You would have it encrypted from you to the server and from the server to the recipient, but actually you could sit on the server and read the things in an unencrypted way. There are a number of potential ways you can tackle these things. People use the generic phrase of backdoor, but the most likely in terms of a messenger system is going to be, as we've just discussed, something where you sit on the server. But there are other ways of tackling encryption because it isn't just the messaging apps, although this open letter was to Facebook about their messaging apps. Of course, as we've talked about, you've got things like iPhones, et cetera. There are other techniques, other methods that people have discussed in the past to try and give lawful, so-called lawful access. They are limited. I mean, for example, encryption is based on having a secret key. If you've got the secret key, you know how the thing's encrypted. You can use the same algorithm and decrypt it. So one of the ways that very early on people said, in order to protect ourselves and be able to do forensic work, for example, law enforcement do forensic work, people should have to lodge that key somewhere. So it's a so-called key escrow. I mean, one of the key problems with key escrow is who has access. It's all very well saying, well, we'll put these things in escrow so that when someone needs lawful access, they can get it. But of course, who's to say that it's just the US and the UK and the Australian government? What about if the Russians or the Chinese or the Iranians wanted to come along and say, well, I want access to these keys now. I mean, it becomes a bit of a nightmare for the organization again, bearing in mind their user base is global, even though they are American oriented. They've got to decide, they've got to become the keeper of who they give these keys to. So that's one big problem with key escrow. The other way of doing it is, and I suppose this is what some people again call a backdoor, is to weaken the encryption. So you make it so that it's relatively easy to break. Not necessarily for you and me, but for somebody with significant resources, they could break the encryption. One of the things about weakening encryption is that you may weaken it so you can track and conduct surveillance on your enemies. But of course, it allows the bad guys to have a go at your friends as well, because we're all using the same encryption. The other way of doing it is to have some kind of master key. But that's a very good example of where now you can go online and you can buy copies of those keys. So you've effectively rendered the lock useless. And the same thing would happen if you had a master key. Some, the bad guys would discover it. It's like leaving the key under the mat. Once somebody knows it's there, they'll find it. So we've got another key analogy to ask you about. So say the government gets access to one of these master keys that lets them gain access to encrypted messages. So if we compare that to an actual physical key, is it more like a key that only opens one door or is it like a key to the city? Could it only be used once or basically whenever a government decided they wanted to? Well, that's actually one of the other issues about master keys. Do you have a master key that opens a whole range of locks or do you have it so that every instance of a particular encryption algorithm has its own master key, in which case if it did, then you're back to the whole key escrow thing again where somebody's got to keep a copy of those. So the only way to really make it workable is with something like a master key would be to have it so they only unlocked a whole slew of different encryptions. And you can imagine the nightmare scenario where that master key became discovered. Its swathes of people would suddenly be made vulnerable. Child protection is one of the criticisms of full end-to-end encryption. In their letter, the ministers wrote that, in 2018, Facebook made 16.8 million reports to the US National Center for Missing and Exploited Children, more than 90% of the 18.4 million total reports that year. It later states that if these plans went through, then the NCMEC estimates that 70% of Facebook's reporting, 12 million reports globally would be lost. The fact that Facebook has such a large share overall of the reports that are being reported by this organization does not necessarily mean that Facebook is the primary platform that is being used by child abusers. It could mean that, but it could also mean that Facebook is doing a much better job than other platforms of actually making these reports. That said, it is true that one of the key ways that Facebook is able to detect this material as it's being shared will go away if they implement end-to-end encryption. Facebook uses a system of hashing images, which is basically kind of applying a distinct fingerprint to an image that it can then be automatically detected every time that it's uploaded or shared. If Facebook has end-to-end encryption, it will no longer be able to detect those images being shared. That will just make that part of the investigative process and the reporting process, it will no longer exist. I also think that one of the points that is raised in the open letter that does make a strong argument is that they say that part of their concern about Facebook is that it combines open profiles with potentially encrypted communication, which could allow child abusers a very particular path to grooming children for abuse. And I do think that that is a real concern. Facebook allows children as young as 13 to be members of its social media profile, which means that you have a situation where potential abusers have kind of the equivalent of a phone book for 13-year-olds, which is not something that in the regular world exists. Children don't have their names and contact information in phone books. In a live-streamed version of Facebook's weekly internal Q&A session, Zuckerberg said that child exploitation risks weighed, quote, most heavily on him when he was making the decision. He also pledged steps outside of encryption to minimise harm. If Facebook goes ahead with their plans, then no one, including its own moderators, will be able to monitor what's happening on these messaging platforms. And that raises fears that things like child abuse might go unnoticed. As Alan explains, it's a difficult issue to navigate. You know, the bad guys are going to misuse this. One of the things we found is increasingly in investigations, encryption and the, I suppose you could call it the misuse of encryption, is actually something that's growing. I mean, people know they can not just render their communications secret, but that, you know, even data on devices can be encrypted so that forensically, you cut, you know, after the fact, even if someone is suspected, you can't get at things that could potentially convict them. Now, does that mean that you should ban encryption? You can't, is the bottom line, because it's too pervasive. So I think where they're going, and if you read the open letter, I'm reading between the lines about this open letter, what they're saying is, please don't implement this any further. So you find, we understand it's in place in certain places, but please don't implement it any further until you've had a discussion with us. And what they're actually talking about is not changing the sort of the technical architecture, keep it as it was when Snowden, before Snowden made his revelations, which is that we could come along and sit on the server and listen to things. I don't implement true end to end encryption, by all means have, you know, the conversation encrypted to the server and from the server, but allow us a window into that, if we've got the appropriate authorisations. This open letter is just the latest in years of governments asking for access to encrypted information, but many security experts are imploring Facebook to continue to refuse them. Is there any indication, do you think, that Facebook might back down anytime soon? One thing about Facebook and this decision is that many observers believe that Facebook's desire to move into end to end encryption and to integrate its various messaging apps has less to do with, you know, some new found belief in privacy and has more to do with Facebook's desire to limit its own exposure to a number of the problems that have caused it huge amounts of kind of public and political grief in recent years. When it comes to end to end encryption, I mean, there have been story after story after story negative articles about Facebook when it comes to their failures to manage the content on the platform. And that includes, you know, hate speech in the United States, that includes, you know, incitement to violence in Myanmar, where the platform was used to help stoke frightening levels of violence against the Rohingya minority, as well as, you know, in India and Sri Lanka, where the platforms have been used, you know, dangerously to stoke violent mobs. Once there is end to end encryption across all of the messaging, Facebook can basically wash its hands of all of that content moderation and simply say, we don't see it. We don't know what's happening. It's not our problem. It will make it much easier for them if they can simply say to all law enforcement, to all, you know, pesky journalists, to all critics that they can't be held responsible for what's being done on their platform when it comes to private messaging, because they don't know what's happening. If Facebook doesn't back down, then this open letter from the US, UK and Australia may well have been futile. But it won't be the last time that governments attempt to stronghold big tech companies into granting them access. At this stage, it's difficult to foresee where we might see a compromise in this debate between privacy and security. You know, there is either going to be strong end to end encryption or not. And when it comes to governments, it's going to be up to them to try to pass the laws in the US and in the UK in a democratic manner. And they're going to have to fight against the privacy advocates against the civil liberties advocates to see if they can make that happen. Alan agrees. I think it's just going to keep going. And I think it, as I said before, it's one of those hardy pyrrhonies, it's going to keep coming up because with the best will in the world, I'm not sure some of the politicians fully understand what they're asking for. However, I think the sheer volume of, you know, the misuse of it, particularly in, you know, really violent areas like child abuse, then there may come a sort of an ethical line that even the big tech companies think, no, we've got to allow people some way in. But having said that, you know, they're profit driven, they are organizations where their users are globally based. And those some of those users are not going to want preferential access for certain governments. So I can imagine that people like Facebook probably will in the end just go for things like end to end encryption, they'll say, no privacy trumps everything and implement it anyway. Unfortunately, the law enforcement agencies will have to deal with the consequences. Huge thanks to Julia Carey Wong and Alan Woodward for coming on the show this week. You can check out Julia's piece as well as her other work on the Guardian website. But that's all from me. Make sure to get in touch with any questions or suggestions for future shows. Email us at chipspodcastattheguardian.com. This is produced by Danielle Stephens. I'm Jordan Erica Webber. And if you want to learn more from the Guardian, just go to theguardian.com slash podcasts.