 The Guardian So Ian, I hear you recently paid for a subscription that you never knew you needed or wanted. And I didn't need it or want it. I signed up for something completely unknowingly and only found out some time later when I noticed money going out of my account. I just traced back what I probably did and I've had to kind of infer what I did and I think I've looked at the sort of process since and really easy to sign up for certain services on certain popular shopping websites without wanting them because of the way the websites are designed. It's an example of a dark pattern. Dark patterns are interface designs that get users to make decisions that really benefit the creator of the interface but not necessarily users themselves. In other words, dark patterns are tricks on websites that make you do things that you didn't mean to, like buying or signing up for something. This week we've teamed up with our sister science podcast, Science Weekly, to find out just how common our experiences are. There are whole industries you might argue are sort of based on it. So gambling is full of examples that involve essentially trying to encourage people to lose more money. Is that for the good of them and the good of society? Probably, probably not. But it can be extremely elaborate and sophisticated use of behavioural science in those sorts of ways. We find out how these companies play on our psyches to pinch our pennies. And ask what we as consumers can do about it. I'm Jordan Erica Webber. And I'm In Sample. And this is Science With Everything. And they make it really hard to unsubscribe quite a lot of the time, especially if it's a magazine. And also I think, oh yeah, magazines are the worst. But also I think like, um, on your bank account... Ian is the science editor of The Guardian and one of the presenters of Science Weekly. And we thought it would be best to start the podcast with the lowdown on dark patterns. That's right, what they are, how commonly they're used, that sort of thing. The title of the paper is Dark Patterns at Scale. So I spoke to Aranesh Mathur, a PhD student in the Department of Computer Science at Princeton University. He recently co-wrote a paper titled Dark Patterns at Scale, findings from a crawl of 11,000 shopping websites. He and the rest of the team conducted a large scale study that looked at 53,000 product pages across those 11,000 sites. And the goal of our study really was to see who are the websites in the retail business specifically that are currently using these patterns and if there's a way we can show them to users and try to understand the different techniques that are being used. But before we get to what he and the rest of the team found, I've compiled a little test to see how savvy you are about the dark patterns you might come across these days. Okay. So, I know you're very aware of hidden subscriptions, but what do you think Sneak to Basket is? What it says, and I had this happen the other day where I went to check out on, um, shopping site online and there was something in the basket. I thought, what on earth even is that? It was something that got put there that I presumably okayed at some point, but not in a very clear way. So I just had to delete it from my basket. So, Sneak into Basket is a pattern where a website adds an additional product to your cart, even if you did not request for one. She's like, oh, you bought, I don't know, a TV. Here are 10 pounds worth of special cloths for cleaning that TV. It's like, no one needs them. It's this extraneous stuff or a two year guarantee that runs over the same period as the guarantee you get with the product. Anyways, that sort of stuff that I find particularly annoying because it's completely unnecessary. And would you say you've ever been affected by visual interference? Well, I don't know what that one is. I mean, I'm sure it's obvious when you hear it, but I don't know what that is. Visual interference is a pattern that uses style and visual presentation to really steer away users from certain options. So you might see a big button and a really small button that's hidden somewhere and you're more likely to click the button that you see is more prominent. So, you know, when you get a pop up that says, do you want to sign up for this thing? And the yes is huge and it's in bright green. And then the no is very, very small and it's kind of gray and you can miss it if you blink. That's exactly how I signed up to the thing I mentioned at the beginning of the program, because the button that I clicked on was the really prominent one in the same color as you think is just for checking out. But it turns out is check out plus some evil stuff as well. OK, last one. Have you ever questioned the origins of testimonials you see on websites you're purchasing from? Constantly. But that's, you know, one of those real life sort of things which is crept online as well, isn't it? Whenever you see sort of, you know, a builder, a builder with a flyer comes around and there's all these testimonials on it from sort of Gareth at number 14. You know, there is no number 14. And, you know, it's it's all that sort of PR is presented as testimonial. I question them all the time. So testimonials of uncertain origin are a dark pattern where a website shows you testimonials from their users, but doesn't really make it clear where these testimonials are sourced from. For example, in the list of such patterns in our study, we found that many websites use these testimonials that are often also available on other websites. It's really not clear who came up with these or who these users are or are they fabricated. So I think I know more about the different types of dark patterns. But how did Arunesh and the team go about finding these patterns in their paper? We focused our efforts on shopping websites. And in order to detect patterns, we built a little bot that would visit shopping websites, discover product pages and try to mimic what a user would do on these websites. That is add a product to cart, go to the cart page and attempt to make a purchase. Of course, we did not actually make purchases. And then our bot would capture all the little pieces of information that it saw during this process. And we then used this information and analyzed it using basic machine learning techniques to discover which of these instances might correspond to dark patterns. So this bot analyzed 53,000 product pages from 11,000 websites, which took less than a week in total. From this, they discovered more than 1,800 instances of dark patterns from more than 1,200 shopping websites, which is about 11% of those examined. That's a lot. But it's not isolated to shopping websites. In fact, the behavioral insights team in the UK has just written a report about something called sludge. Sludge? It harks back to something called nudge, changing people's behavior by making it easier for them to make decisions that are supposedly in their best interest, using tricks from behavioral economics and psychology. What kinds of decisions? Anything really from making healthier choices to paying the right taxes. For instance, if you hadn't paid your car tax, you'd receive a letter with a picture of your car saying pay your tax or lose your Ford Fiesta or whatever it is you happen to own. And it really worked. As you pointed out earlier, online commerce sites are now using these same techniques against us, often to make us part with our cash. So rather than nudge, it's called sludge. And I spoke to one of the authors of the report I mentioned before. His name is David Halpin and he's CEO of the behavioral insights team. Well, it's really like the dark shadow of nudge. So you can use, you know, nudges and hopefully lots of good reason to help people save more or make healthier choices in life. You can also use it sometimes for darker purposes, adding in extra frictions to make it harder for people to find out what's the right thing to do or to get trapped into deals that don't really suit them. And we tend to call that sludge. So who uses these techniques and generally what are they for? So they're used quite widely commercially and arguably they're becoming more prevalent with digital sort of optimization in some ways. So they're normally used by commercial players in order to, well, for economic advantage to catch people. The classic examples of people often misjudge. So they, you know, take up subscriptions, thinking they'll read a magazine, but then they actually they don't and they end up with 20 of them and they never get around to canceling them. So they're quite widely used and, you know, actually quite widely used in media, not at least print media, but they're also spreading into other forms in online and kind of more complicated varieties. And is this really about selling stuff or does it go broader than that? So that's a very interesting question. It definitely does go broader than that. I mean, just as nudge has a narrow and a broader definition, so does sludge really. So the narrow definitions are normally adding a friction, particularly, you know, to exit some kind of subscription, etc. But there are clearly deeper examples. And like behavioral science, like any form of knowledge can be used for good or for bad. So there are whole industries, you might argue, sort of based on it. So gambling is full of examples that involve essentially trying to encourage people to lose more money. Is that for the good of them and the good of society? Probably, probably not. But it can be extremely elaborate and sophisticated use of behavioral science in those sorts of ways. You talked about how some of these manipulations, maybe that's too strong a word, but how some of them can involve quite complex behavioral science. Can you unpick some of that for us? What is the behavioral science going on here? What are the sort of psychological weaknesses that are being exploited, the cognitive biases? So I mean, a classic one is that what's called present bias, we make a decision in the moment and we mispredict our own behavior. So we think, you know, to take a simple example, we think, oh, this looks like a great magazine. I'll sign up to it. Oh, and it's just I can try it out for free for, you know, whatever a few months. Because it might be written in small print, but even if you are aware of it, you actually misjudge whether you might use the product, but also that you misjudge how easy it will be to exit. So that will be just a classic simple example, kind of present bias and sort of certain kind of discounting in the future. There are many other sort of varieties of it. A simple example would be what we call attentional wars, which are basically capturing people's attention. The design of platforms that designed to keep you scrolling, keep you clicking, keeping you active. And of course, fundamentally, for commercial reasons, normally to essentially get you to click through on adverts. But they're very, very sophisticated in their design. They can be literally quite addictive. We actually did some work on online basically our brains go on autopilot when it comes to instant gratification. So how do websites take advantage of that by offering fast delivery at double the price or using time limited offers and countdown clock? These are just some of the ways in which companies tap into our cognitive biases to make us part with our cash. And they're so effective that even David has fallen foul of one or two himself. I remember this is quite a few years ago, but hurrying back, you know, to King's Cross actually. And someone comes along and they say, and they press a little bunch of flowers into your hand and they say, oh, it's for the little children. And before you, you know, you're aware of what you're doing almost, you reach into your pocket and you give them some money. He uses what's called reciprocity. Someone gives you something very powerful. She feel to give something back. And after you thinking, oh, why did I just do that? So, yeah, they're all around us. And most people, I'm sure, have many examples. After the break, we look ahead to the future when experts expect these dark patterns or sludge techniques will only become smarter. One of the really key questions is particularly when you take that experimentation and even machine learning now. It's a massively powerful tool which can be deployed against the consumer in the vendor's interest. And you have to say, what's on the side of the consumer or the citizen? Where's the AI and machine learning to help the citizen consumer get what they might want? And we asked what we as consumers can do to fight back. We'll be back in a minute. It's time to focus. The mood in the UK right now, it seems to me, is a huge set of tensions and contradictions and emotions and feelings about our past. And we're not thinking very much about the future. Today in focus is the new daily podcast from The Guardian. Join me, Anushka Rastana, for the best stories from our journalists around the world. Subscribe now to Today in Focus from The Guardian. Welcome back to Science with Everything. I'm Ian Sample. And I'm Jordan Erica Webber. This week we're looking at various techniques that websites use to get consumers to make decisions that might not be in our best interests. We spoke to David Halpin and Aranesh Mathur about the methods e-commerce use and the psychology behind them. But if we understand that these techniques exist, why do we still fall for them? David says it's because our brains have evolved to take mental shortcuts. So the basic, if you like, fault line, if you want to put it negatively, or actually elegance of human cognition, if you want it more positively, is that a lot of human behavior is driven by what are known as shortcuts or mental heuristics. So we just don't have the time to process every kind of choice or option in the world. And our brains have literally evolved to try and figure out what's going on as rapidly as possible. So we use these mental shortcuts. A simple example would be we estimate the probability of something occurring by how readily we can think of an example of it. And so that's why people often tend to think flying an aeroplane is dangerous because you can easily think of an example of it crashing, even though statistically it's not very likely. So it works in an accrued level, but it's also subject to a sort of systematic error. And that can be exploited by a vendor or someone else in order to kind of fool us, if you like, and get us something which we don't want. And I mean, every example of that would be around gambling, where people are quite widespread now. You'll see adverts for gambling, which are playing on our, quite skillfully, our heuristics, where we estimate how likely something is to happen. And so people then are essentially getting their bet a little bit wrong in a systematic way, which can be exploited in order to get people to essentially gamble more than they should do, get their estimate wrong. And they haven't thought about the other possibilities of how this game might play out. And so they think they're more likely to win than they actually are. And David says that vendors are getting better at tapping into our psyches by experimenting with different methods and seeing which tactics are most effective. It can be. And one of the things that online has definitely cranked the dial right up on is experimentation and empirical methods. So again, that isn't by itself a bad thing. You know, we've ourselves worked on campaigns to help people more successfully quit smoking, redesigning websites to make them more effective. And they enable you to what's called a B formatting to test essentially parallel versions on a random basis to see what's more likely to get someone to do a certain thing to click through, you know, to purchase something. It's estimated that more than one in 10 economic exchanges, probably quite a lot more than that now in the US, are part of an experiment, just massive volume on which is occurring. And online is essentially ubiquitous. So it means that, yeah, you can keep tuning and tuning and tuning. And now also not only in general terms, but you can personalize it. You can work out what for a given individual profile they're most likely to respond to. So one of the really key questions is particularly when you take that experimentation and even machine learning now, it's a massively powerful tool which can be deployed against the consumer in the vendor's interest. And you have to say, what's on the side of the consumer or the citizen? Where's the AI and machine learning to help the citizen consumer get what they might want? And what's more, it's not always the shopping websites themselves that create the dark patterns. Arunesh and the team found third party entities embedded in more than 10% of the websites. Meaning the websites aren't necessarily in control of the dark patterns impacting their customers. How do we know who to blame if we feel we've been conned? So I think in this instance, the responsibility falls on the shoulders of both the first and the third parties. And it also depends in many instances on the specifics of how the third party is being used in the first party's website. For example, if a first party is using the capability third parties provide to generate fabricated messages, the responsibility falls on the first party's head. In cases where the third party is just creating these messages for any first party in a fabricated manner, then definitely the responsibility falls also on the third party. If the vendors are getting better at making us part with our cash, how do we get better at holding onto it? Here's David again. So I think there's several levels of it. And in relation to the behavioral insights team ourselves, we have rather a lot of checks and balances. You know, we're co-owned still by the cabinet office. We have cabinet office on our board. We've literally written into our articles. We only do social impact stuff. So we're kind of tighter. But really, your question is more generally, I think, for society, how would we draw those lines? And they're really important. Well, I mean, the first line of defense is some forms of education or just making people more aware of what these biases are. And people do learn and evolve. A good, simple example is a lot of work on defaults. A very famous everyday example now is auto-enrollment for pensions. More than 10 million people have signed up. That's generally seen as a good thing. And even people who opt out say that's the right thing to do by a large majority. But, you know, you can also, you know, people learn, for example, on online sites now is check what's been clicked already and unclick. There are some airlines that are pretty famous examples of this. And it does seem like people have learned, you know, somewhat. So people can learn and become more aware of their biases. We're big believers in what's called de-shrouding or revealing to consumers the relatively, if you like, sludginess of different products or services like social media, so that it changes consumers' behavior enough to retilt the market. And the final one, I think, which is maybe less discussed, is actually governance changes. So in the key players themselves, so that the users can shape, you know, the nature of the product. And actually, you're not just talking about product in some cases. You're talking about how people interact with each other, the nature of society itself. So it does become quite deep and important, I think. And you mentioned in your report, actually, that there could be other ways of raising awareness of this kind of thing. And you mentioned a sludge prize. We are. And so maybe the Guardian would like to sponsor it. That's right. Well, we already we there's this kind of rather nice event called the Pavell Exchange, where policymakers and sort of leading academics get together. And we've always had kind of prizes for, you know, nudges that have a particularly good or positive impact or most interesting research. But yes, this year for the first time, we're looking at whether to have a sludge award, maybe with a big consumer group or someone bearing in mind, we might also get sued for doing so. But we do think it's worth just highlighting, making it a little bit of reputational risk to companies that excessively engage in these techniques. I love the idea of a sludge prize. But what I don't understand is why aren't any of these techniques illegal? It is interesting. Arinesh makes a similar point. The responsibility of protecting consumers should not fall on consumers themselves. Right. There are there are various consumer protection authorities, both here in the US and in Europe and elsewhere that should really be looking into these patterns to to regulate them and to go after the ones that are particularly problematic for users. What they are. Now, lawmakers are actually looking at this in the US, for example, senators have drafted a bill that could make some dark pattern techniques. Some dark pattern techniques are legal and give the Federal Trade Commission more authority to police how sites are using them. But some say it'll be difficult to pass, even though we know the patterns exist. I asked Arinesh about this and his explanation is one we hear a lot on ships. The technology is developing more quickly than the law. Several of these phenomena are more recent in the online world in shopping websites and social media platforms. So I think people are still beginning to realize the kind of harms these patterns actually cause and lead to. Having said that, I think there is an increasing awareness among senators, for example, here in the US, where there is a proposed bill that bans the use of these patterns called the Detour Act. So I think over time, we will see increased legislation and regulation against the use of these patterns. Right now, we are still in a point where we are trying to understand the effects they have and document what they look like. So, you know, obviously, advertising has often used deception, right? We can trace it back through history, things like advertising cigarettes with people who showed no physical effects from smoking a pack a day. Is this not just the kind of digital evolution of that kind of thing? Like just the whole advertising industry just uses these kinds of tactics because they work and that's just the natural progression of this kind of thing. Yeah, that's a good question. I mean, we have seen cases in the offline world where you have, you know, in your neighborhood, Ruck store that claims to be going out of sale in business, but really is open all year long. I think what really differs between the offline world and the online world here is the scale at which this can happen and the magnitude with which it can affect consumers. So in the digital world, your credit card is tied to your online account and it's very easy for you to make payments and get into hidden subscriptions, for example. That's not as easy in the offline world, I would say. So it's really the magnitude and the ease with which the Internet has made it easy for advertisers to implement these practices. It sounds like lawmakers don't have an easy job ahead if indeed this is possible to police. So how does David feel about the future? Is he optimistic? I think I am optimistic, but I hope to be realistic, too. So, behavioral science is not going back in its box. It's a very, very powerful force. Both commercial players and actually governments, hopefully generally for good, are using this stuff. And the real question people need to be asking often is who nudges the nudges? So what are the countervailing forces, which is why in the end, I do think we have to look at the governance arrangements. I'm also quite optimistic actually about you can redesign markets in order to try and tilt them to compete on things that are good rather than bad. And that's not really being used anywhere near as much as it can be. And every example, it's not just online. You go into a supermarket, you know, you are barraged by lots of very powerful forces to try and affect your behavior. You are very much more likely to buy things at the end of the aisles or by the checkouts, right? So are those forces being deployed to help you make healthier choices or less healthy choices? Do you know, do you personally know the difference between which ones, which supermarkets, when you walk into them, are prompting you generally for healthier choices or less healthy choices? And I'd say the answer is probably not. So you can see there's an opportunity there for a kind of platform basically, which is choose your supermarket on the basis. It'll make you, you know, it'll nudge you towards healthier, you know, greener choices rather than worse. So that's why I think, you know, there's a great deal of power for if you like a certain kind of consumer activism and indeed intermediate platforms who are using this stuff as a force for good rather than bad in order to essentially make markets compete on a good basis rather than a bad one. Do you feel optimistic, Jordan? I think that we are getting more savvy about these kinds of things, especially not to be biased against the elderly, but the younger generation, I think, like learns these things more quickly. I think you hit on an interesting point and an important one as well, because I think there are some people in society who will be hit harder by these things than others. And I think some people will be tricked more easily than others. That's already happens, right? But I think this just wraps it all up. Another level. I mean, no, my dad won't go online because he's just too afraid of what will happen. And it's probably not a bad idea. It's probably for the best. Yeah. And that's what a terrifying thing to think because you're excluding yourself from all that other stuff. But I'm not particularly optimistic. I think there's always this case of buyer beware. But these techniques are so powerful. You know, the techniques used on gambling sites are apparently really clever. And, you know, if you're of that kind of persuasion, if you're of that mind, I think you can be completely exploited. And when emotional stuff starts coming in, which is coming in on these websites, you know, picking when you're at your lowest step and when you're most likely to make a purchase or when you're most likely to pay a ten or more, that starts getting really horribly manipulative in my view. And it's really hard for me to be optimistic. I think you make a really good point there about certain segments of society being more affected than others. But I think that the work that people like Aranesh are doing is really, really helpful, you know, because these are obviously it's they're really clearly delineated. These different practices. And if we can highlight them in that way, then people will be able to understand them more easily. Many thanks to both our guests this week. They were David Halpin and Aranesh Mathur. The producers were Greg Jackson and Danielle Stephens. I'm Jordan Erika Webber. I'm Ian Sample. Goodbye.