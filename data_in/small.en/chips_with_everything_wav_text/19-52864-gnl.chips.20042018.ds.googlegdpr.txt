 The Guardian We've all done things we regret. Perhaps you're one of those people who lies awake at night fretting about something hurtful that you said ten years ago. Or maybe you committed a crime in your youth, served your time, reformed, and are dedicated to a new life as a law-abiding citizen. For a long time, it was relatively easy for someone to leave their past behind them. Memories fade, and you could always just move to a new town and start again. But then, along came the internet. No matter how tidy you are with your life in digital space, you've probably said or done something that isn't really you. It's in the live journal from your teens, or your MSN messenger logs, or in some fantasy you texted to your ex a few years ago while she was abroad, or some photo you were tagged in unbeknownst to you. It's in the Reddit relationships thread, or the image board memes that you forgot you used all those times late at night while drinking corner shop wine. The digital germs of your subconscious are all over everything. And if I can find them all, someone else will find it easy to dredge up at least some, and then everyone sees it, and you're a political liability. This excerpt, read by Monica Turek, was from a short story called The Soft Truth from my friend and colleague Lee Alexander, who also happens to be the former host of this podcast. It illustrates what we digital natives have come to know as a golden rule. Be careful what you post online. But if you're worried about what a potential employer might find if they type your name into Google, there may be a way to wipe the slate clean, though you might have to fight for it in court. In April 2018, Google lost what was called a landmark case in which it was ordered to remove search results mentioning a businessman's decade-old criminal conviction to comply with his right to be forgotten. But what exactly is the right to be forgotten? Why have some people criticized it? And why is this latest case so important? But that's why this was particularly interesting, because it was the first time that the principle had been tested in an English court. And will this and the imminent adoption of the General Data Protection Regulation lead to a wave of new cases of people asking for their information to be removed? It's a really good question, and there is a certain level of anticipation that as of the GDPR coming into effect of May, and as a result of all of the campaigns, particularly by data protection authorities undertaken across the European Union, that people now are so much more aware of their rights, that this will encourage them to then exercise their rights? This is Tips With Everything. I'm Jordan Erica Webber. Hi! Hi, how's it going? I'm good, how are you? I'm all right. Nice to meet you. How are you doing? Jamie Grierson is a reporter for The Guardian. He covered the landmark Right to Be Forgotten case against Google in April. Well, I covered the original court case back in, I think it was February, when the substantial trial was held at the High Court, and I've been following it since then. To start us off, I asked Jamie to give us some background on the case. Two businessmen were not happy with the fact that when you Googled their names, these articles came up, which referred to previous offending and their history of criminal convictions. So they approached Google and requested for links to those articles to be taken down, and the technical term is de-indexed, but we just say taken down from the search results. Google refused on a public interest ground because they thought that the public had the right to know that these men had been convicted of criminal offenses, and that those criminal offenses might be relevant to the work that those men do now. I should add that the offenses were committed over 10 years ago. In one of the cases, it was in the early 90s. When Google refused to do this, they then launched legal proceedings against Google, and that was escalated through the courts and eventually was taken to the High Court. And there was a substantial trial hearing held in February where in two separate hearings, the businessmen came, presented their arguments. Google came, presented their arguments, saying, no, we think yet they're wrong. And then the judge went away to make that decision. So last week, April 13th, the judge handed down his ruling. He ruled in favor of one of the businessmen, and he ruled against the other. We're limited as to what we can say about the businessmen because there were reporting restrictions in place in the court. But the first NT1, he was convicted for conspiracy to account falsely, and that was in the late 1990s, and he was handed a prison sentence of four years. The second businessman was convicted over 10 years ago for conspiracy to intercept communications, and he was jailed for or handed a prison sentence for six of six months. So the businessman with the lower prison sentence, effectively meaning he committed the less serious offense, that's NT2, he was the businessman who won his legal bid, and Google were ordered to de-index or take down the links to those articles, whereas NT1, who was convicted of a more serious offense, he lost his bid or Google won, depending on which way you want to look at it. So what were the arguments that the claimants were making then in seeking to have their information removed? Okay, so their arguments were twofold. One was an argument surrounding data protection, which is just based on the individual's right to privacy, but there was a second side to their argument which related to the rehabilitation of offenders. So the legislation in the 70s, the Rehabilitation of Offenders Act, was all built on the principle that people should be able to go on and live a normal life, if you like, or be able to reintegrate into society once their convictions are spent. And they argued that the access to these articles was inhibiting them. For that reason, we said if you Google your name, like some of us have or may not have done, but if you Google your own name and you see what comes up, and these guys, if you Google their names, this is what comes up, these articles about their criminal convictions. Just to be clear, they're not asking for the articles to be taken down themselves, just the links to them, but some argue that that, in essence, is the same thing, because how would you find them otherwise? Okay. And then what was Google's argument for not removing the information? Well, Google argued on the side of the public's right to know. They argued that the offending was so egregious that it was important that this information stayed within the digital domain, if you like, so that if people wanted to conduct business now with either of these men, they would be able to, as I say, do what a lot must do. You might, if you're thinking about doing business with someone, you might Google their name, see what their previous conduct's been like, or if there's any reviews of their work online, that sort of thing. And the barrister representing Google said the right to be forgotten ruling, it wasn't a right to rewrite history. That's what he said in the court, and that was sort of like, that comes down to the crux of their argument. You shouldn't be able to take advantage of this ruling to rewrite history and change your online portrait if it goes against what the public should be able to know. Have you covered or seen any other cases like this about the right to be forgotten? Well, no. But that's why this was particularly interesting, because it was the first time that the principle had been tested in an English court. Okay, do you think that this is going to have consequences? Do you think you're going to be covering a lot more of these cases in future? So the implications of this ruling will be that people in a similar position to NT2, so those who may have received a sentence of a similar length, so six months, may be a little bit more, but certainly less than NT1, who was sentenced to four years, will maybe see this and see this ruling and the coverage, and they may have articles online that they don't want people to see anymore, and they might be motivated to bring court cases themselves. So it could be that we see a significant rise in the number of people making so-called right to be forgotten applications. The only thing to say about that is that you need money to go to court, and it doesn't necessarily mean there'll be a flood, but it certainly will have been watched closely by people with criminal convictions who think that they might want to do the same thing in the future. So you've been following the case since it came out in February, were you surprised by the ruling? I was surprised, yeah I was surprised because the expert opinion behind the scenes seemed to think that they would both lose, so I wasn't expecting either of them to win. That distinction between the more and less serious offence is important because the original 2014 ruling in the European court made reference to irrelevant data, and it's been criticized by commentators for being far too vague in its language, and what the ruling said was that if the links connect to articles which are no longer relevant anymore, then they should be taken down. And there's been a lot of debate over what does that vague term mean, what's irrelevant, what's not. And the judge clearly made the call here that the less serious offence probably started to move into the bounds of irrelevancy for what that man's doing now with his life, and some of the contrition he's shown was interesting, but still in terms of what he does now and the public's right to know, a less serious offence is probably less relevant and that's probably why he did win. So what happens now then for the claimant who lost? So the claimant who lost does have a right to appeal this decision again at a higher level of court and it will probably go up in front of three judges rather than one this time. Once he's exhausted all avenues though, it will be within the rights of media publications, including the Guardian, to request that the reporting restrictions on naming him are removed. So we may be able to arrive at a position where if he continues to lose in his applications we might be able to reveal more details about him and his offending and what he did and his background. Yeah, so I was going to say in the case, the 2014 case that you mentioned earlier, the kind of landmark ruling in the European court, the Spaniard in question wasn't anonymised, his name is actually out there, and maybe this will also be true for this other claimant who lost in this case. So is there just that risk then that by following this path of pursuing your right to be forgotten you actually become more famous? Yeah, that is definitely a potential. You write the Spanish Citizen in the original application, his name was Mario Costeca Gonzalez, but I think he sort of accepted his role as a champion for this principle and he's done interviews himself since, so he's fully aware that the consequence was that he might have seen his name in headlines and in newspaper print. But yeah, the same could in theory happen to NT1 if we are able to lift those reporting restrictions eventually. So Jamie was surprised by the outcome of this ruling because the judge drew a distinction between what initially seemed like two similar cases. But what will this mean going forward, especially as we look ahead to the enforcement of the upcoming General Data Protection Regulation? I suppose at the end of the day it's very important to know that what is of interest to the public isn't necessarily the public interest as well and they're the kind of balancing acts that have to get undertaken when you think about the right to be forgotten, for example, and delisting. We'll ask an expert after this short break. Here at The Guardian we love podcasts. Not only do we make dozens of award-winning ourselves, but we also write about our favourite podcasts from around the world too. Every week our column Hear Hear, that's here as in hearing and here as in where, comes out filled with recommendations from you, our listeners. We sift through them all to find the hidden gems that the podcasting world has to offer. These podcasts are often small yet mighty productions which you probably wouldn't find highlighted on your usual pod captures. So if you're looking for your next podcast or have one that you want to share with the world, sign up for our weekly Hear Hear newsletter at theguardian.com forward slash podmail and send us an email at podcasts at theguardian.com. Welcome back to Tips With Everything. I'm Jordan Erica Webber. Before the break, I spoke to Jamie Grierson, a Guardian reporter who broke down a right-to-be-forgotten case where a businessman with a criminal past took on Google and won. So what happens now? Well, I mean, data protection legislation has been around since, I mean, the 1995 EU directive has been around now for more than 20 years, soon to be replaced by the general data protection regulation. Dr. Nora Ni-Ludzon is the Director of Information Law and Policy Centre at the Institute of Advanced Legal Studies. Information and data is just so pervasive now and it affects everything we do from the moment we get up, you know, to check. Earlier on, Jamie explained to us that the judge in this case used the length of each complainant's sentence as a factor in determining whether the information about their conviction, which they wanted to be removed from Google, was still relevant. But the problem with relevance is its subjective. So I asked Nora how we're supposed to determine whether a piece of information is relevant or not. The criteria that the court provided in 2014, as you said, is very general. So very soon after the course of Justice delivered that, the advisory group of data protection authorities, which contains representatives from every EU member state, they're called the Article 29 Working Party. They provided some guidance, some guidelines on how this should be interpreted and how this could be applied by data protection authorities, how data controllers, search engines, for example, should be approaching this and what advice, for example, can be provided to citizens. Some critics of the right to be forgotten say that it can't really work because of internet resilience, the idea that once something goes online, it tends to stick around. Just because Google removes its search engine results for a particular article doesn't mean the web page itself has gone away. So is there any way that we could ensure that information could be really, truly wiped? There are a number of new initiatives now or new principles under the general data protection regulation, such as the data protection by design and data protection by default principles. And this requires organizations, governments, for example, to ensure that everything they do complies with data protection. A practical example of that would be that anyone's personal data, once it was no longer useful or no longer being used for legitimate purpose by a company or by the government, should be erased and destroyed. But whether in fact we will be able to verify that throughout the world for every single company third party that has your information is going to be incredibly hard to verify, for example. I mean, you or I right now, we have no idea how many companies in the world have a profile on us and how accurate it is or how inaccurate it is. So at least the right to be forgotten gives individuals some level of control when it comes to search engines as to what information about them is available and is not. And again, it's not an absolute right, it's a balancing between different interests in terms of the control that you have over information from your past and then what's ultimately necessary in a democratic society in the balancing of your rights with freedom of expression, for example. Right. So one of the other criticisms of the right to be forgotten is this notion that removing information from the internet that isn't illegal, so if it isn't libelous, if it's true information, amounts to censorship. So, for example, you know, a politician who maybe had an affair with an adult film actor could ask Google to remove that from the search results. And would that not count as censorship? Like, what do you think about that? Well, it's always a very important question because there has always been attention and need to balance the right to private life and freedom of expression. But in terms of the test itself, I mean, yes, it refers to data that's irrelevant, but it also takes into account the public interest in having access to certain data. So there's different criteria, for example. So in the case of that politician, you know, if they are someone in the public sphere, if they're a public figure, then the different factors that have to be taken into account by a search engine, for example, will include the fact that, well, this person is a public figure and that will have to be balanced against freedom of expression. I suppose at the end of the day, it's very important to know that what is of interest to the public isn't necessarily the public interest as well. And they're the kind of balancing acts that have to get undertaken when you think about the right to be forgotten, for example, and delisting. So you've mentioned the General Data Protection Regulation there a few times, the GDPR that's coming in in May, and Article 17, the right to be a raiser, the right to be forgotten. How does this tie into the current right to be forgotten as it's being discussed in the court case? And how does it do? The GDPR hasn't come in yet. So that must be a different kind of thing. Will it change things or are they just the same? So it's been, it was enacted back in 2016, but it doesn't come into force until, or it doesn't have to be implemented, for example, by governments and by businesses until May of this year. So in the actual judgment, Justice Warby notes the fact that, well, we know that the GDPR is on the horizon, and he makes the point that, and in light of the fact that we're going to have this change in the law, this new regulation, that perhaps this judgment actually won't have that much impact in future. But I actually don't think that's the case at all. I think there's some very useful legal analysis in this case that concern principles of privacy and freedom of expression and data protection that go back decades and that will be relevant in future. So I think that the judgment could prove very valuable still. And the fact that we have the GDPR coming into effect in May isn't going to alter the value of current judgments or case law concerning it. But will there be any big changes after the GDPR does come into force after it has to be enacted? Will it change the way that cases like this are dealt with? In terms of how it will change the way cases are dealt with, it's now made explicit in the GDPR that you have a right to erasure and then in brackets next to it, it provides that you have, that this also applies to the right to be forgotten as people are quite familiar with that term now. And there are actually new requirements under the GDPR that requires search engines and companies to respond to such requests to data subjects more quickly than before. So for example, if you do not receive a response from a search engine with regard to a request for a right to be forgotten or right to erasure, you have an expectation that that will be provided to you within a month, for example. And if you don't, then that is an issue that you can then take up with a search engine as to why there's been a delay. With new stories like this and the imminent enforcement of the GDPR increasing public awareness about the right to be forgotten, should the likes of Google be preparing themselves for hundreds of cases like this one? It's a really good question. And there is a certain level of anticipation that as of this, as of the GDPR coming into effect of May and as a result of all of the campaigns, particularly by data protection authorities undertaken across the European Union, that people now are so much more aware of their rights, that this will encourage them to then exercise their rights. And it will be very interesting to see whether the generation of so-called digital natives decide that, well, that this is something that they're very mindful of in terms of managing their information online and seeing whether there will be a deluge of these cases to search engines. But I do hope that judgments like this and legislation like the GDPR does remind people of the rights that they have and that when they feel that those rights have been interfered with, the GDPR rights, their privacy rights, that they do in fact exercise them. One person who may well seek to enforce his right to be forgotten in future is the subject of this week's Tech Fact. A drug dealer in Wales has been arrested based on fingerprints from a WhatsApp photo. The photo of the dealer's hand holding some pills only showed partial prints, but forensic scientists were able to use those to confirm the suspect's identity and make further arrests in what are the first ever convictions in Wales based on fingerprints from a photo. I'd like to thank Jamie Grierson and Dr. Nora Neeladzon for joining me this week. And if you have any ideas for cool digital stories that we should cover in future episodes, email us at podcasts at theguardian.com. I won't be here next week because I'm going to be in Cardiff teaching undergraduates about philosophy through the lens of video games. The wonderful Alex Hearn, technology reporter for The Guardian, will be in the studio in my place. I'm Jordan Erica Webber, see you next time.