 The Guardian. Supposing we hit the body with a tremendous, whether it's ultraviolet or just very powerful light and I think you said that hasn't been checked but you're going to test it. We are told that you cannot sell bananas in bunches of more than two or three bananas. You cannot sell bananas with abnormal curvature of the fingers. Why should they tell us? There's a lot of bullshit out there. Even in this post-Trump pandemic era, it's something we need to navigate carefully. Understanding what makes someone more or less susceptible to be taken in by utter nonsense could help us in combating the spread of misinformation. One study has now gone back to the old adage and asked, can you bullshit a bullshitter? What we wanted to do was look at the relations between people's self-reported bullshitting frequency and we wanted to compare that to their ratings of how profound, truthful or accurate they found. Pseudoprofound bullshit, pseudoscientific bullshit and also fake news headlines. I'm In Sample and this is Science Weekly. I will say it's been interesting to try to not only study this kind of stuff but to actually get it published. Maybe this last paper, the title, started out as a joke and I'm kind of shocked that it actually made it through review. That's Shane Litrell, a PhD candidate at the University of Waterloo in Canada. Back in 2019, we did an episode of Science Weekly, getting inside the mind of a bullshitter and I spoke to Shane about his work. So when his new study came out, I wanted to find out more. Shane, last time you were here, you were telling us about your bullshitting frequency scale. Now I do want to go over that as it feeds into your new study that we're going to talk about but first off, let's just go back to the beginning. What exactly is bullshit? When it comes to defining bullshit, I will say two things. Everybody seems to have their own definition of it but most people's I found seem to be pretty similar. When I give the definition that I use, I'm not really breaking any new ground here. So what we did was come up with an operational definition which in science, you have to have a definition that is specific, laid out, and consistent in all of your research. And the way that we define bullshit is that it's information intended to impress, persuade, or otherwise mislead people that's sometimes delivered in a way that shows what we call a loose concern for the truth and it still falls just short of lying. I should probably explain what I mean by a loose concern for the truth. What I mean by that is kind of two different things. One is that bullshit can spread unintentionally, meaning that a person can be duped into believing some bit of bullshit. They believe it to be true and then they communicate it to somebody else because they're trying to inform them of this smart new thing they think they just learned. And in that case, we wouldn't consider that person to be engaging in bullshitting because bullshitting is an intentional act and it requires an intent to mislead. And then the other part of the loose concern for truth is the bullshitter's primary goal is not necessarily conveying truth or accuracy in a conversation. Their goal is to tell an impressive, persuasive story basically. They're less concerned with how accurate it is and more concerned with whether it's effective. So in the, I guess we'd say in the heat of bullshitting, they'll sometimes say things they know to be true and they'll sometimes say things that they have no idea if it's true or not because what's important to them is they say things in a way that sounds convincing so that they can kind of further their goals. It's what we call the uses and purposes of bullshitting. And the use and purpose of bullshitting is to manipulate the opinions and attitudes of others. In psychology, we call this impression management because basically trying to control or manipulate how others see you or your ideas. One of the most important fundamental things about bullshitting is that it's always deliberate and strategic. So you're speaking to a group of people. You want to impress them or you want to persuade them to your side of an issue or you're also doing things to try to avoid any kind of hurt feelings or reputational harm. So there's a certain aspect to it that is what we call self-enhancing. Basically you want people at the end of a conversation to think you or your ideas are a lot more awesome than they believed at the beginning of a conversation. And just to get into distinguish it from lying. I mean, lying is intentional as well, right? But does it achieve different goals? The liar's goal is to get you to believe a falsehood. They know the truth and they want you to believe in an untruth. So everything they say is focused on leading you away from the truth and toward believing a lie. Bullshitter's goal isn't to deceive you necessarily. It's to manage social impressions, like I was saying. But they want to do this in a way that doesn't require them to outright lie. And in fact, this is one of the most important distinctions between lying and bullshitting is a bullshitter is trying to mislead or distort things without outright lying. Now remind me and our listeners who may have missed that episode about your bullshit frequency scale. What was that all about? We all have this sense that there's a lot of bullshit in the world. There's a lot of bullshitters out there. So we wanted to come up with a way to kind of get an idea of how frequently people do it in their everyday lives. So we came up with the bullshitting frequency scale and it's designed to measure two types of bullshitting. So we have persuasive and we have evasive. So persuasive bullshitting is intended to impress, persuade, or otherwise fit in with others by using exaggerations, embellishments, or misleading implicatures about things like your knowledge, your ideas, your skills, your accomplishments. So an example might be a person trying to talk intelligently or in a way that merely sounds intelligent about topics they know little to nothing about. So they can hopefully appear smarter or more knowledgeable to the people they're talking to. And then the second type of bullshitting that we look at with this scale is evasive bullshitting. And that involves dodging questions by using non-relevant truths in situations where frankness might result in hurt feelings or reputational harm. And it might go something like this. Your romantic partner gets a drastic, just awful, hideous new haircut and asks you if you like it. If you're a bullshitter or if you're in that situation and you choose to bullshit, you don't want to lie. But if you tell your partner your honest opinion, there could be a social cost to that. It could hurt their feelings and then it could result in you sleeping on the couch for the next week. So you respond with, you always look great to me, honey. So in that situation, you haven't actually answered their question. You've substituted this non-relevant truth. You always look great to me. It doesn't answer the, do you like my hair question? But it satisfies them and it makes them feel like you've answered the question. So you can kind of think of evasive bullshitting as answering without really answering. And there's also another type of bullshitting that we don't look at on our scale and that's social bullshitting. And that's just, you're sitting around with your friends at a pub telling tall tales and you're just trying to entertain and bond with your friends. Some of the traits that we've found that are associated with higher frequency bullshitters, persuasive bullshitting in particular tends to be negatively associated with cognitive ability, which is our fancy way of saying intelligence. Evasive bullshitting actually isn't. Persuasive bullshitters also tend to negatively score on measures of analytic thinking. They tend to score slightly lower on measures of self-worth and something we call open-minded cognition, which is your ability to think openly about new ideas and consider new perspectives. Persuasive bullshitters tend to score lower on that than the average person. And evasive bullshitting seems like it utilizes analytic thinking a little bit more than persuasive bullshitting does, probably because you have to be a little bit more strategic to navigate really tough, emotional, social situations. So your new study looks at can you bullshit a bullshitter and as far as I'm aware, the phrase goes that you can't. But was there actually any evidence or sort of theory before you started looking at this which said one way or another whether that was the case or not? So I'm really interested in folk wisdom and these sayings that people assert as truisms when they often aren't. Like for instance, there's a widespread belief out there that feeding kids candy will give them a sugar rush and they'll start acting hyper. And that's just that's not true. It was disproven about 30 years ago. But that widespread belief is still out there. I myself growing up in the southern United States, the south, I always heard that phrase, you can't bullshit a bullshitter. But in researching this and looking at the research online, a lot of people also have kind of like this intuitive notion that liars are better able to detect lies. The research on that is pretty mixed. Most of the research tends to show that liars, like big liars aren't any better at detecting lies than the rest of us. There's a few studies out there that show that they might have a slight advantage, but it's not like huge. Since in our bullshitting frequency scale paper, we had already kind of found some ways to separate bullshitters from liars on a bunch of different domains. I started wondering if maybe bullshitters and liars different on this domain as well. Tell us how you said about answering the question. What we wanted to do is look at the relations between people's self-reported bullshitting frequency, the frequency within which they engage in both type of bullshitting, persuasive and evasive. We wanted to compare that to their ratings of how profound, truthful or accurate they found pseudoprofound bullshit, pseudoscientific bullshit, and also fake news headlines. We presented these participants with descriptions of various social situations, which they might be tempted to start bullshitting. We asked them how to rate how frequently they engage in their daily lives when they encounter these situations. So, for instance, for persuasive bullshitting, they would rate how frequently they bullshit using items like, when I want to contribute to a conversation or discussion, even though I'm not well informed on the topic. They also rate items like when a direct answer would hurt another person's feelings, you know, to give us an idea of how likely they are to engage in evasive bullshitting. And then when we measure bullshit receptivity, which is how likely you are to fall for bullshit, we present people with a number of statements and some of them are bullshit and some of them are real. And the BS items, they've all been randomly constructed by a computer algorithm. And what that does is it just takes a bunch of new age or scientific sounding buzzwords like quantum interconnectedness and hypermagnetonic refractalization, buzzwords like that, and it randomly assembles them into statements that are syntactically sound. You know, the nouns, the verbs and everything are all in the proper order, but it's semantically meaningless. So when you sit there and think about it, it actually doesn't make much sense. So for that, though, items like perceptual reality transcends subtle truth or suffering is born in the gap where potential has been excluded. They could be real statements, but if you take the time to think about them, like I said, you realize they're actually kind of meaningless nonsense. We also give people actual scientific statements and intentionally profound quotes too. So something like, no man ever steps in the same river twice for it's not the same river and he's not the same man. And that's a quote from Heraclitus. Participants would rate all these quotes and this allows us to calculate a score of how well they're able to distinguish the bullshit from the non-bullshit. And then we gave them five fake news headlines and five real news headlines. And we gave them in the same format that you'd see them on social media, you know, with the picture in the headline below it. The fake news headlines, they all came from a list on Snopes.com, which is a big debunking website for anybody out there that hasn't heard of it. Overall, we found that people who score higher in persuasive bullshitting frequencies, so they're more likely in these social situations to engage in that kind of persuasive bullshitting talk. They were more likely to be duped by the bullshit statements. In other words, they were more likely to believe that these fake statements are profound or truthful or accurate and that the fake news headlines were accurate. This finding held even after we controlled for things like their level of intelligence, how overconfident they were, their analytic thinking skills. And when we tested this further, we found that bigger persuasive bullshitters, they seem to mistakenly interpret the superficial cues of profoundness or truthfulness or accuracy as signals of inherent or intentional profoundness, truthfulness or accuracy. So in other words, for a persuasive bullshitter, if something simply sounds profound or truthful or accurate to them, that means that it really is profound. So basically they have a hard time distinguishing fact from fiction. And this seems to be an error that they're making at a metacognitive level. We're not quite sure why they're making that cognitive error, but that error that they're making was independent of whether or not they were super smart or not, or whether or not they had really high analytic thinking skills. Every other thing that I tried to control for, in other words, take into consideration in the analysis, the relationship between higher persuasive bullshitting and higher likelihood to fall for bullshit remained. Shane, do you think this kind of work can help us with the problem of misinformation? God, I hope so. I think our results provide us with a better understanding of how misinformation is spread and how it's interpreted by people, especially if it's the same person. Because past research already tells us that misinformation is spread intentionally and unintentionally. But these are the first results that I'm aware of that show that being an intentional spreader of misinformation doesn't inoculate you from falling for yourself. Also helps us to understand why this happens. As we know that people who both spread and fall for BS, they experience the metacognitive deficits that prevent them from being able to tell the difference between actual facts and impressive sounding fiction. But there's also something that is potentially a larger issue here. And there's a chance of, I guess, what I would call bullshit amplification. By that I mean that a bullshitter can take bullshit that they either believe is true or that they're not certain if it's true and they just don't care. Because recall that bullshitters have a rather casual relationship with the truth. So if they take bullshit, they believe to be true and then they use it in an instance of persuasive bullshitting where they're misleadingly distorting that information in some way. What they'll have done in essence is distort information that is already distorted, creating misinformation that's potentially even more misleading than it already was. There's a lot of information that's very persuasive. And I think some of that may be because of the language it uses. I wondered if there were sort of bullshitting techniques almost that make misinformation more palatable or attractive, which help it go viral, help it spread better. I don't know, Ian. I'm not sure that I want to teach people how to become better bullshitters. There are certain linguistic features that we've identified that kind of make bullshit more bullshitty, I guess would be the term. One is kind of the basic one that's at the heart of bullshitting in general. And that's just the strategic use of information in a way that distorts or misrepresents reality in some way. And it can also be done in the way that you say it. So for instance, through implicatures. So the way that you say things that might imply in the mind of the other person something else. So for instance, you might see this in marketing for a toothpaste, for instance, where they say nine out of 10 dentists recommends this toothpaste. For some people that are seeing that, especially somebody that's highly receptive to bullshit, you might see that and be like, wow, 90% of dentists think this toothpaste is awesome. What they're not really saying is that they only sent this to like 10 dentists they happen to know and they asked them, hey, if we gave you a free sample, would you recommend this? And I'm like, yeah. So the truthfulness of the statement that nine out of 10 dentists recommend this toothpaste, it's technically true. But it's presented in a way to imply something that's misleading. There's also the issue of what philosopher Cohen calls unclarifiable and clarity, which is the use of really obscure language like jargon, buzzwords, fancy, schmancy, academic speak, the big words that we use to make our sounds sound more intelligent, even though we could have probably put it in much simpler language. I've probably done that a little bit here. I actually heard a term recently that I really liked called strategic ambiguity. And this goes back to Cohen's notion that I mentioned earlier of unclarifiable, unclarity, which is using these really obscure, abstruse kind of language that you're not really quite sure what it means. But when you hear it, you kind of think that, oh, well, I don't understand what they're talking about, but I don't want to admit to anybody that I don't understand what they're talking about. So what they're saying must be smart or it must be profound or it must be accurate. It could be the case that one of the reasons people are more likely to fall for, you know, kind of verbal or written bullshit information is because their verbal dictionaries, their lexicons don't have, you know, the sufficient amount of words to be able to identify these other words as being, you know, bullshit. And because they don't know those words, they interpret their misunderstanding or their lack of understanding as a signal that these words must be very smart and profound and deeply meaningful. I've got to ask you before you go, Shane, just finally, if you have your favorite bit of I don't know what the unit of bullshit is, but if you have your favorite item that you've come across in your time researching this. There was a tweet by Donald Trump that said something to the effect of sorry losers and haters, but my IQ is one of the highest and you all know it. Just I don't know if we would consider that bullshit in a study, but in my life I consider that bullshit. So sort of thing you could have sort of sell a tape on your monitor work to keep you remind you why you're doing this. Yeah, I kind of tape it to my bathroom window like, you know, Rocky Ford did with the picture of Drago to get him hyped up for the fight. They're trying to take you out with bullshit. Shane, thank you so much for coming back on the podcast. Thanks Ian, it was really good coming back and you know, you're welcome to have me back as many times as you like. Thanks again to Shane. If you want to listen to the episode about bullshitting Shane joined us for last time or read about his new study, you can find links on the podcast webpage at theguardian.com. That's it from us today. Stay safe and see you next week.