 This is The Guardian. It hasn't been a great couple of weeks for Elon Musk. One of his rockets is currently on a crash course to the moon. Four tons of metal traveling at 5,000 miles per hour. The moon's gravitational pull, sucking it in. Impact calculated for March 4th. A 19-year-old demanded $50,000 to remove a Twitter account, which tracks Musk's private jet. Imagine scrolling through your phone and Elon Musk slips into your DMs. UCF freshman Jack Sweeney didn't have to imagine it. And just a few days ago it was confirmed that 80% of his SpaceX Starlink satellites that launched last week are expected to burn up instead of reaching their intended orbit. Although in better news for the billionaire, there was a lot of excitement after Musk's other company, Neuralink, began recruiting for a clinical trial director to run tests of their Neural, or brain computer, interface in humans. In the first instance, Musk hopes that this technology, which allows the brain to communicate directly with a computer, could soon be used to help those with severe spinal cord injuries walk again. We hope to have this in our first humans, which will be people that have severe spinal cord injuries like tetraplegics, quadriplegics, next year, pending FDA approval. But of course, his ambitions don't stop there. The ultimate dream is to one day help us all communicate telepathically. And, in Musk's own words, save and replay memories. That might sound like science fiction, but it's not complete fantasy either. And there are concerns that in developing this technology to help others, we might be heading towards something a bit more, well, dystopian. So, what to make of all of this? Is it overblown hype or visionary work that could help thousands of people? From The Guardian, I'm Madeline Finley, and this is Science Weekly. Andrew Jackson, you're a professor of neural interfaces at Newcastle University. As somebody who works in this field, I am curious, what do you think of Neuralink? So, I think like many people in the field, I'm excited about the possibilities of investment in developing technology in neural interfaces. And I think it's very exciting to see how much progress Neuralink have made in a few years, and it's going to be very exciting to see where it goes. But I think that's been an interesting experience for all of us to see, you know, the change in a field as it matures from being a university research to being Silicon Valley tech companies. We're going to take a closer look at Neuralink and its technologies in a moment. But first, can I get the basics of how a brain-computer interface actually works? Yes, so the brain is an electrical organ and all of our sensation and our movements, as well as the thinking that goes on in our brain, is associated with electrical signals being sent from one brain cell to another. And in principle, a brain-computer interface is a way of getting electronics to talk directly to those brain cells, recording the electrical signals in the brain or sending electrical signals into the brain. And it effectively allows our brains to communicate with technology without the need for sensory systems or our motor systems. And now you've made that sound quite simple, but I would imagine that implanting a device into the brain with all its different regions and its unending complexity must be a really difficult thing to do. Yes, so there's different ways to interface with the brain. Some people use electrodes on the surface of the skull to try and pick up the electrical signals in the brain. But really, the closer you can get to the brain cells themselves, the better you can listen to the electrical signals they're sending. So an invasive brain-machine interface, like the one the Neuralink team are developing, puts some very fine wires effectively into the brain to sit close to the brain cells to pick up their signals. And then perhaps most difficult of all, you need to be able to make sense of the signals that are being recorded. You need to find some way of relating these electrical signals in the brain to thoughts or intentions or movements that someone is trying to make. And that, I think, is one of the sort of scientific challenges of brain-machine interfaces. OK, so there's quite a few things that you can do to help you. There's quite a few significant challenges to overcome. But one of the exciting potential applications of this technology is in helping people with spinal cord injuries or who have had strokes. And this is something that Neuralink is trying to do. But it's also something that you're doing in your lab. So how does it work? One of the first ideas of a brain-machine interface was to decode the intention to move. And this is obviously very useful for people whose brain is acting normally, generating signals about movement. But those signals aren't getting out to the muscles because of some kind of injury, for example, to the spinal cord. And the idea is that you could maybe listen to what's going on in the brain and infer the movement that somebody is trying to make and then either relay that information to a computer or a wheelchair or a robotic arm or even relay that signal directly to the spinal cord or the muscle. This is Pager. He's a nine-year-old macaque who had a Neuralink placed in each side of his brain about six weeks ago. If you look carefully, you can see that the fur on his head hasn't quite fully grown back yet. He's learned to interact with a computer for a tasty banana smoothie delivered through a straw. We can interact with the Neuralinks simply by pairing them to an iPhone, just as you might pair your phone to a Bluetooth speaker. The links record from more than 2,000 electrodes implanted in the regions of Pager's motor cortex that coordinate hand and arm movements. Let's talk about Neuralink. They've recently released a video of a monkey playing a simple video game with its brain, but actually this is something that people in the field have been able to do for a while. So, put what Neuralink has done in context for me. I think the important thing to take from that video is actually the fact that the monkey is playing this computer game using its brain, but there are no wires connecting the monkey's brain to the computer screen. The idea of an animal or even a human playing a computer game directly with their mind is not in a sense new. That has been shown before, but almost always the demonstrations have involved cables coming through the skin, sort of large boxes of equipment translating the brain signals into the computer. What the Neuralink team have done, and I think have done very impressively, is put all of that into a small implant that can be implanted under the skin in the bone effectively, and then relay these signals from a large number of different brain cells wirelessly out to a computer. I'm curious about the next step that you mentioned, decoding the neurological signals, because there must be huge challenges when it comes to that research as well. Absolutely, and like I say, what's been demonstrated to date has been a fairly simple decoding of, say, movements to the left and movements to the right. This is a little bit like an election. Effectively what happens is some brain cells will prefer movements to the left, and other brain cells will prefer movements to the right. An individual brain cells will sort of signal their information by sending out a series of spikes, or called action potentials, but they're like little votes for their preference. Decoding from the brain is very much like an election, where we count up the votes that brain cells are making for movements to the left or movements to the right, and once we tally up the vote, we can then decide whether the cursor on the computer screen should move to the left or the right. The problem with that is we need to know in advance which direction our brain cells prefer. Neurons that like movements to the left and movements to the right are all jumbled up in the brain, and it's very hard to know in advance whether a given neuron prefers left or right. So what's needed before we can do this brain interfacing is to learn about the neuron's preferences, often called building the decoder. And in that phase, the user, the monkey, or the human has to imagine movements to the left or the right, and these neurons will fire, and we can use that information to then learn the pattern that we need to look for in the subsequent operation. I mean it sounds fantastically complicated, although I love the idea that there's constant left-right voting going on in my brain. But decoding these signals and understanding the neural language of the brain, that's one difficulty, another one I assume is if you ever wanted to put a signal back into somebody's brain from a computer. Yes, and this is something that the neural link device is certainly being designed to start to do, that it's not just reading from the brain, it's also writing information into the brain. And there I think the challenges are even harder than reading from the brain, because we don't actually have very good ways of getting information into brain cells. We are effectively electrically stimulating the vicinity of the brain cells, so a small electric charge is put into the brain nearby these brain cells. And some of them will indeed respond to that electric charge by sending out their own signals. But it's a little bit like trying to kind of play the piano by hitting it with a large sledgehammer. It's very hard to stimulate just the brain cells that we want to stimulate. Why would you want to send signals into the brain? What kind of practical applications would this have? So we've already talked about one application where we would send these electrical signals into the spinal cord, and from the spinal cord they could then travel to the muscles and produce a movement of a paralyzed limb. If we went kind of more far-fetched, we might be able to send in more abstract information, thoughts, knowledge, even memories potentially. I would sort of caution that this is still very much in the realm of mostly science fiction. We're very far from being able to produce illicit kind of complex thoughts by stimulating the brain. In a way I'm quite glad to hear you say that we're not anywhere near that, because it does sound quite terrifying, and like something at the start of a dystopian novel. Andrew, in your view, a company like Neuralink, are they likely to have a positive impact on the field? It's certainly good for the field, and I don't wish to come across as too negative or dystopian about this technology. This is technologies that I have played my own small part in trying to help develop. I think that also that it's important for there to be a kind of wider conversation that involves everyone, not just sort of scientists and engineers, about what are the applications that we think are most important, and what are the things that we would like these technologies to be able to do, of which there are many possible things. These technologies could radically change the ways that we interact with technology, the ways that we interact with each other. But to some extent, once these technologies are out there and are being widely used, it can be sometimes too late to change course. Andrew, a lot of food for thought there. Thank you so much for coming on the podcast. It's been a pleasure. Lovely to talk to you. Thanks again to Andrew Jackson. You can find a link to the article about Neuralink's work on the podcast web page at theguardian.com. And that's it for this week. This episode was produced by George Cooper, the sound design was by Solomon King, and the executive producer was Max Sanderson. We'll be back on Tuesday. See you then. This is The Guardian.