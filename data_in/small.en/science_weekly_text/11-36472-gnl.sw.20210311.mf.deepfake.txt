 The Queen, talking about toilet roll shortages. Mr Bean starring in a perfume ad. Gollum singing a Sinead O'Connor song. This is the weird world of deepfakes, where artificial intelligence can make celebrities say strange things, change people's faces, and potentially completely undermine our trust in audio-visual media. Recently, a deepfake came out that was really convincing. So much so that some people even wondered whether it might be some kind of meta-joke being played, and that it was the real Tom Cruise pretending to be a deepfake of himself. We wanted to know, how is it done? And now we're reaching a time when it's becoming difficult to tell what's real and what isn't online. What happens next with the technology? I am really a very bad singer, but on the other side I like to sing. It would be really good if I could sing, like for example Nina Simone or Whitney Houston. If I could transfer my voice over their voice so that it looks like I'm singing, that would be wonderful. That's just a nice kind of application. I'm Alex Hern, or at least a voice that sounds like Alex Hern. And this really is Science Weekly. In this reel, you're going to see my amigo, Chris Umi. He's going to introduce to you the wonderful world of deepfakes, how AI and VFX are unlocking the future of our imagination. Chris, I guess firstly, do you want to just introduce yourself? Who are you? Hello, I'm Chris. I'm Chris Hume. I'm a VFX artist from Belgium. I've been working on AI technologies for a few years now. And last week I made a few videos where I made someone look like Tom Cruise and somehow they went viral. Before we get onto that, then, onto those videos, let's start with the basics. How would you even define the term deepfake? The technique is pretty straightforward. So you tell the machine to learn a certain face, a face you use as an input, and you take another video and you change one face with another. So let's say I take your face and I want to put it on the queen, then I can do that using the deepfake technique and the queen will have your face. So for you, the important parts of that definition are it has to use AI and it has to be about swapping faces. Is that kind of integral to what we think of as a deepfake? Yeah, but you could also use an existing piece of video and you could actually change what's being said. You could take a speech from Biden and you can make him say something else visually. It does not have anything to do with the audio. It's pure visually. Tell me about the history of deepfakes. How did they start from day one to when you heard about them? In what I read somewhere in 2017, the end of 2017, if I'm correctly, I could be wrong. There was this guy called deepfake. He posted a video on Reddit and that one got trending. People were fascinated because he managed to change one face with another by using a certain technology. Since then, it got picked up by two big repos. One was called Face Swap and one was called Deep Face Lab. In the end of 2018, I saw a news bulletin that was his headline like deepfake used in x-rated movies. I've never heard of it before, but I was fascinated by the technology like how is this possible? And it's so cool because you can use it for creative stuff and not these x-rated movies because I'm not interested in those at all. But I mean, there's so many creative things you could do with this technique. And since then, I've been working with Deep Face Lab and it's been evolving rapidly. If you do a comparison with the quality of deepfakes back in 2018, what we have now, it's a big difference. At a procedural level, how do you, Chris, make a deepfake? What goes in one end to produce that video of Tom Cruise that comes out the other? You go and look for as much data as possible. Pictures, videos, everything you can find. Then you scrub through them and you clean it up so you only have the best of the best. Important thing is you cover all angles. You have as much expressions as possible and even try to have a lot of different light angles. So the machine knows how Tom's face reacts in certain scenes. Then on the other hand, you'll have to look for a video or create a video of yourself. That's going to be the destination where you're going to put Tom's data on top of, face on top of. Even before all this starts, you'll actually have to pre-train a model. You teach the machine learning what a human face is and how a human face works. Like if a human face smiles, it has to learn like, okay, this is how a human face smiles. In fact, it doesn't really know what it's training on. It doesn't even know those are human faces, but somehow it learns them. Pre-training means you train on 70,000 random faces. Not even one is similar to the other, but the machine learns all these different angles and expressions and faces. After the pre-training, then you start training on a specific face. How much data do you need to be able to do this for or to someone? Tom Cruise is obviously one of the most filmed people in existence. Most normal people might have 30 or 40 Instagram videos up of them. Is that enough yet to do a compelling fake video of them? Do you think that will change in the future? It all depends on the destination video you want to use. If your destination video only has frontal faces, then it doesn't make sense adding all those different angles of Tom Cruise in your dataset because you'll only need the frontal faces to make it work like I did with my videos. I'm trying to make it as difficult as I can, all different angles and all these weird things going on. I have to make sure my dataset is covering all bases. Is it even important for someone doing this sort of thing to understand the deep science behind it? Or is it like we've been hearing for years now that this is just almost a black box and you just sort of pour faces in, get faces out and tweak some almost unlabeled dials to see what happens? For me, it's exactly like a black box. As you experiment, you start learning how it works and how to get certain results. And that's how I learned myself. Here at Science Weekly, we're not fans of black boxes. We like to lift up the lid and peer at exactly what's going on inside. Hi, my name is Maya Pantej. I am an AI scientific research lead in Facebook and I am a professor of machine learning and computer vision at Imperial College London. We got Maya on the line to go behind the curtain of deepfakes and explain just how they work. There are different methodologies to build deepfake videos. And in principle, the two I would say are face swapping and the other one is actually reanimation, we could say. So in the first one, that's the one which was actually used for making the Tom Cruise TikTok videos. So in the face swapping scenario, what's happening is that you actually just take the whole face around the edges and you move the face that you want onto the face in the video where you actually want this face to be. That sounds easy, but it's not that easy, but it was possible because Tom Cruise is a celebrity. So there is a very many different videos and recordings of Tom Cruise from which different faces could be sampled. How this has been done, at least as far as I could understand in the TikTok video of Tom Cruise was really frame by frame. So in every frame of the video, they first recorded the video by Miles Fisher, who is, as I said, a look alike of Tom Cruise. And then for every frame they found an image of Tom Cruise, which is a very similar expression and position to that of Miles Fisher and then exchange that. That's a lot of work, of course. And after that, they did a lot of processing so that everything looks smooth, that the lightning is correctly positioned, that the eyes are correctly positioned, and so on. The color is correct and so on. So in principle, this is only possible because we have so many of the movies of Tom Cruise, which are very long. So we have a very large amount of this kind of data that is needed. The second approach, which I mentioned, is much more difficult. And you start from a single static image and you make that image sing, talk, blink, smile, do everything what you want. And this is the technology that we actually developed at Imperial College. So in this kind of technology, you are using so-called adversarial neural networks, where you have one network that tries to generate realistic videos. And the other network is a discriminator and tries actually to detect whether the generated video is a fake one or a real one. In this process, which is often referred to zero sum game, you want actually to give the generator a feedback so that it knows that it generates badly and certain things well and improve its generation by the fact that the generator will actually detect if something is fake or not. But once the video is taken care of, what about the audio? So the principle is exactly the same. You want actually to transfer the speech rhythm. Somebody speaks slower and somebody speaks faster. So you want to transfer that. You want to transfer the intonations. You want to transfer the accent really. And that's very difficult for already existing speech. So you actually just change the identity of the speaker while the speech remains the same. You will have one network will try to generate this transferred identity. And you will have another network, the discriminator, who will actually try to detect whether this identity of the person is the one that you want or not. So whether you succeed to trick this detector into detecting a person who is actually not the person. And if the discriminator detects this person, then you actually say to your generator that it learned well to fake the identity of a specific person. In just a few years, it seems as if we've gone from badly blended faces in glitchy videos to something that looks real. Maya explained just how quickly this technology is progressing. Currently the technology is not of a quality that you have seen in Tom Cruise Deep Fakes. This is really possible because they had a number of things. One was that they had this detector. They also had this humongous amount of data of Tom Cruise. So that was possible in the case of such a celebrity. However, once we are moving to say regular people, this amount of data does not exist in the world and people will not be able to come to this amount of data to actually impersonate somebody. So I think that the technology is not on that level. And so I don't think we should be worried in that sense. But I think instead of just addressing what are the challenges on that side, and the challenges are things like how you would do things like occlusions. And that was very well done in this TikTok of Tom Cruise, like sunglasses, hat, handy front of the face and so on. But instead of talking about that, I also think it would be very good that we talk about the challenges of detecting Deep Fakes. The one that we currently use and that it is the best performing and it's the state of the art currently is the one from Imperial College and Facebook. And that one is working on checking the lip synchrony with the audio that accompanies a video. So in principle, due to face swapping or due to animation of the, say, still standing image and making it actually to move the lips in a way we want, the lip synchrony is not perfect. And based on that, we are actually detecting the Deep Fake videos. There are so many ways the technology could be used to trick people, whether it's spreading misinformation, discrediting public figures, or even impersonating someone to commit fraud. Then again, there's also plenty of creative opportunities too. So where could this technology go in the future? I think that the technology indeed has many, many potential beneficial uses. Having Carrie Potter moving portraits is one of these very beautiful kind of use of this technology. One example which I often give is I am really very bad singer, but on the other side, I like to sing. I'm just bad in it. So the issue is that it would be really good if I could sing like, for example, Nina Simone or Whitney Houston or these ladies that have fantastic voices and I simply cannot breathe like they do and make these sounds. But if I could have this sound and then transfer my voice over their voice so that it looks like I'm singing and then transfer my face, or have my face reanimated and lip synced so that I can sing, I look like singing that and see myself sing like them, that would be wonderful. That's just a nice kind of application. Right. Back to Chris, who's busy developing deep fake techniques for parodies and improving visual effects. Currently it sounds like an astronomical amount of work to do this to this level of quality. Do you think that's going to change? Could what you did be automated? Do you think it will be automated or is this something that's always going to require a human eye to do that final pass of fine tuning? Well, Photoshop has been up for 20 years. And still, if you want someone to fake a photo and he wanted to look real, you still need a professional to do that or someone with a lot of experience. And it's the same goes with this only with video, it's more difficult. The tech will get better, the deep fakes will get better, but you still need to fine tuning of certain details. And you'll also need a really good actor, because don't underestimate how good the actress I've worked with like Miles Fisher. He's a professional actor. He's so good and what he does, he's so good at impersonating certain things of Tom Cruise, the love, the mannerism. It's insane how good he is. And then if you add me on top of that, a professional deep faker, if you combine those two, you have you've got a small Hollywood studio working on this. That's something people at home just don't have even even if the tech gets better, you still need that certain level of manually fine tuning those small details. And I think it's difficult to replicate that in the next few months or years. Of course, I can predict the future, but that's how I feel about it. What's your response to the argument that even with something as as lighthearted as deep Tom Cruise, you are still making Tom Cruise say and do things that he didn't and maybe that he wouldn't have. Is that an ethical issue that that worries you? In my point of view, I'm using it for entertainment. I'm not a lawyer or jurist. So I think it's still a gray area and people have to talk about it. When I think about Tom Cruise videos, I try to make him as lighthearted as possible. And I wouldn't do anything that would upset him or harm him in any way. It's a new type of comedy and a new technology to create certain types of comedy. But it's something that has to be talked about for sure. When it comes to the platforms themselves, they have been making rules, you know, Facebook and TikTok have both banned deep fakes if they're posted with intention to mislead or attempting to misinform. Could you see yourself coming down the wrong side of one of those rules in the future? I guess like if they ever change their policy in a certain way, maybe they'll tell us to do labeling or in some other way to make sure people aren't confused, then we'll abide those rules for sure. TikTok gave us a warning a few days ago that we have to make sure we're not confusing people, that we are the real Tom Cruise. So now we added like parody plus 20 years younger in the bio. So people can read it and then they think like, okay, and maybe maybe if that's not enough, then maybe we'll have to go further like, Hello, this is a parody account. Like maybe you have to do something like that. I don't want to fool people. I want to tickle their fantasy like what's going on? This is weird. This is this is not possible. Like this is this video is so stupid. Like he's he's eating this lollipop and he's seeing how great it is. I think there's bubble gum inside there. And it's so harmless. And that's, that's why I like these figures. It's so harmless. That's incredible. How come nobody ever told me there's bubble gum? We've talked about sort of a whole range of possible uses here, but we've not got on to any of the sort of the things that people have been worried about with deep fakes for three or four years now, the idea that they might destabilize the the wider information environment that we might end up creating a world where there's just a general lack of belief that you can trust your own eyes. If you compare that sort of nightmarish dystopia with the advantages to the creative industry, is there a possibility the risks outweigh the benefits? I think by allowing it right now, that makes it visible for the public, like how far this technology is getting. And it makes it makes it easier for the for the companies who are working on anti deep fake software to detect fake videos and videos where the mouse have been visually edited to say different things. I think it makes it easier for those companies to work on anti deep fake software, because you have to know, I'm using publicly available software for my personal projects. So if I have access to this thing I'm working with, then just imagine what the big government organizations or the bigger companies have in their private buildings, what they're working with. So people understand it's coming, technology will keep evolving. And even if you if you make it illegal or not, like, people will eventually use it in ways it's not supposed to be used for. Only way I think we have to think about is how are we going to live with it? Because it's not going away. Photoshop didn't disappear as well, like there's still fake photos everywhere. We have to learn to live with it. And journalists have to try and be extra careful when using certain sources or videos. Authenticity is really important. So people have to know there's a way to find legitimate articles that are built on confirmed sources. It sounds a lot like the way magicians talk about their art, right? Like they're not out there to convince you that they have magic powers, but they are very much out there to make you ask how did you pull that off? I did a deep fake off of mount manipulation of Jon Snow like one and a half year ago, maybe two years ago. I made him apologize for season eight of Game of Thrones. I really didn't like the last season, but I did it for fun. But I was thinking like, if I do this, people will think it's funny. That's one. But people will also be upset a bit and they will start thinking like, if this guy can do it, then actually more people can do it. So I'm creating awareness at the same time. And that's what I always try to do. In no way I want to fool the people. I just want to get that out there. But I like to create the illusion like what's going on? What's going on? How did he do it? I'll tease you. I'll make a breakdown where you can see like, this is not real, but you still can figure out how I did it. Our apologies there to HBO's Game of Thrones and anyone else who enjoyed the final series and to Sinead O'Connor and Chrysalis Records for that interesting take on her song we heard at the start. That's it for today. Thanks to Maya Pantich and Chris for joining us. If you want to find out more about deepfakes, you can find Ian Samples' explainer article on the podcast webpage at theguardian.com. We'll be back next week. Hasta la vista, baby. Perhaps that wasn't very convincing. Bye! For more great podcasts from The Guardian, just go to theguardian.com slash podcasts.