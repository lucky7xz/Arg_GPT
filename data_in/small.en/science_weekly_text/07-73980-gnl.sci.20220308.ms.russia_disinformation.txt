 This is The Guardian. To do that, just type Politics Weekly America into Apple, Spotify, or wherever you get your podcasts. We'll be there every Friday. There's a video that's recently been doing the rounds online. You might have seen it. It's slightly blurry, but you can just about make out two fighter jets chasing each other in the sky. A missile gets fired and one of the jets is taken out. This is the ghost of Kiev, a Ukrainian pilot who has reportedly been bringing down scores of Russian planes. Except the footage has actually been traced back to a YouTube video made on a flight simulator game. Which begs the question, is the ghost of Kiev anything more than a myth? Video showing the pilot have been shared even by Ukraine's former president and top defence ministry officials. The identity of the pilot unknown, so too, to be frank, is the veracity of the story, but it's still captivating the nation. Before the viral video was debunked, it was watched millions of times around the world, providing a moment of hope and inspiration for Ukrainians. It was also one of the many, many examples of propaganda and disinformation being used by all sides to push their preferred narratives online. But who is winning the information war? And what impact does it all have in the real world? From the Guardian, I'm Ian Sample, and this is Science Weekly. Dan Milmo, you're the Guardian's global technology editor, so perhaps it didn't surprise you that much when Russian disinformation ramped up over the war in Ukraine. But give us some background here. Russia has a track record in information wars, right? Yeah, I mean, Russia's got a very strong track record in digital naughtiness when we really realised it was quite serious. And I think that's a very important thing to be aware of. And I think that's a very important thing to be aware of. And the digital naughtiness when we really realised it was quite serious was in 2016 with the hacking of the democratic party emails, which did, I think, and people have said, have a material influence on the outcome of the Clinton-Trump election campaign. And basically, within the Russian Military Intelligence, or GRU, there is a hacking arm called APT-28. APT stands for Advanced Persistent Threat. But they're also known as Fuzzy Bear, an oddly cuddly name for a very uncuddly group of people. And they carry out persistent hacking attacks and have done them. Certainly, the 2016 attack was attributed to them. OK, Russia has been linked to a lot of serious interference in other countries, including here in the UK. But how are they actually spreading disinformation? What kinds of tactics are being used? Well, I think the first thing to take on board with this is there are countless platforms through which to sow disinformation, which is deliberately, malevolently misinforming people in order to produce a physical or emotional harm. And there's misinformation which is getting it slightly wrong and then broadcasting it to your mates on Twitter or Facebook. And that word broadcasting is important. There are countless myriad ways that the GRU, Russia, hackers of any stripe, ransomware groups, can target people, whether through email, through SMS text, but obviously through the big platforms, Twitter, Facebook, Instagram, YouTube. And what Metta, the owner of Facebook and Instagram, revealed last week was they discovered a small disinformation network that used all the major platforms to sow disinformation through fake personas, fake accounts and fake news information sites. Some of these fake personas, they're basically headshots created via artificial intelligence programs, including of a former aviation engineer and the editor of a hydrography magazine. They went very granular in terms of the deception. They intercepted this network in its infancy, really, and it was very nascent. But it was obviously sophisticated, 40 accounts with thousands of followers, and you just use those to get retweets and likes and just propagate it across the various social networks that were used. Worse still, now Nazis are treating their own population as human shields. Our military was pointing out that in Donbasque and... When Putin announced the invasion on Russian state TV, it was clear that he was presenting it in a certain way to Russian citizens that he'd push a false narrative to garner support or at least drive down opposition. What kind of disinformation have you seen or heard about online? What have Russia been putting out? Well, NewsGuard, a sort of news verification service, they've done a top 10 Russia, Ukraine, war myths, and they're all propagated by Russian sources. And they appeared across about 114 websites. Obviously, Russia today and Sputnik were the key ones, but there's, for instance, there's a website based in Kansas that is propagating this stuff. And the sort of big ones are that Russian-speaking residents in the Donbasque region of eastern Ukraine have been subjected to genocide. I think everyone sort of heard that one. Polish-speaking saboteurs attempting to bomb a chlorine plant in Donbasque. And obviously, probably the most outrageous one, that Nazism is rife in the top echelons of Ukrainian politics and is being supported by the likes of its Jewish president Zelensky. What NewsGuard found was that these myths are just repeated on a loop across multiple platforms, across dozens of accounts. On the flip side of this, has Russia been restricting access to sites where people might get factual information about what's happening in Ukraine? Russia's produced one great, swinging legislative hit that's shut down a lot of Western media in Russia, and that is passing a law that anyone found spreading fake news or misinformation, which the Kremlin can define themselves, faces 15 years in jail. So the BBC and various others have stopped working within Russia in the wake of this, so that's already pretty damaging in terms of freedom of verifiable information within Russia. But also, Facebook, Twitter have all been blocked in Russia as well, and it kind of tit for tat because they themselves have blocked Russia today and Sputnik across the EU, Facebook and Instagram in the UK as well. We've been talking a lot about Russian disinformation, but it's also happening on Ukraine side too. What kind of myths and disinformation are being shared here? Well, the ghost of Kiev is a very rousing story, but it seems to be a myth. Certainly, one of the sort of foundation videos of the ghost of Kiev story is a simulation from a computer game. So that's an example of not necessarily something orchestrated by anyone, but there is an emotional push behind being pro-Ukraine on social media, and that will inevitably result in misinformation, or indeed disinformation, people putting up videos with misleading captions, etc., in order to sort of maintain that level of support for Ukraine, and it's certainly something I've seen on TikTok, for instance. So in that example, it sounds like disinformation was being used to build morale and garner support, but what are some of the other real world impacts? It just spreads chaos. It just creates uncertainty, which makes it difficult for politicians to bring the public behind them. It's a very effective way of dissipating political support for a certain standpoint, i.e. sanctions against Russians. It could, for instance, make it very difficult to trust any reports of atrocities committed by the Russian forces within Ukraine. It's also very important to win the soft war these days, as it were, which has obviously been waged largely across social media. If you make it very difficult for a certain standpoint to hold, i.e. back Ukraine, then it's done its work. With Russia's prowess in the disinformation sphere, lots of people thought they would be pretty effective in this space compared to Ukraine, but actually lots of commentators are pointing out that the Russians have been pretty underwhelming when it comes to online propaganda. What signs are that the Ukrainians might be winning the sort of information war out there? Well, I guess the Ghost of Kiev example is a classic one. That ran and ran and is still running. I'm sure there's plenty of people who'd be surprised to find out that the Ghost of Kiev is at best something that needs to be proven. I mean, it's obviously very clear also that there's a tremendous amount of support outside of Russia for Ukraine. You're more likely to share, retweet, like a piece of content that is pro-Ukraine, and that therefore creates a snowball effect where Ukraine does win the soft war or is winning it. And that is very important because Ukraine is going to need a lot of support in whatever form that country takes over the next few weeks, months and years. It's going to need that support. But obviously the soft war in Russia is also very important. It's important that the Russian population gets to see what's really happening, and it's going to be difficult for Ukraine to win that particular battle inside the boundaries of Russia because of the fact that Russia has just taken steps and well-rehearsed ones to win the information war within its own borders. Just finally, Dan, I wanted to know because in all likelihood, most of us will see some kind of myths or disinformation in the coming weeks. What's your advice for listeners out there? Well, I suppose the first old-fashioned one as a journalist is just go to trusted news sources. Go to The Guardian, obviously. Go to the BBC. Go to CNN, you know, just the places that you ordinarily would. And they do have presences on all the platforms. A tip from NewsGuard is if you're going down a less verified route, is to check whether this publication does corrections or reveals its ownership. Apparently, that's quite a quick far way of double-checking. And also, if you see a video online, try and see if you can find it elsewhere with the same conclusions being drawn from it. And obviously, hopefully, you might find an alternative publication source for that video or that piece of content that proves the fact that it's trying to state to you. But I think there's a wider point above and beyond that, as if you're in doubt about it, don't like it or share it. Misinformation and disinformation works by propagation, by it being shared and spread and taking hold and being viral. So you can do your bit to stop that, which is if you're in doubt, check it. Don't share it or anything like that. Dan, thanks so much for coming on. You're welcome. Thanks again to Dan Milmo. You can find links to his articles on the podcast web page at theguardian.com. Now, before you go, I want to point you towards our new podcast, Politics Weekly America, which comes out every Friday. In the last episode, Jonathan Friedland spoke to retired Lieutenant Colonel Alexander Vindman, who testified in front of Congress that he heard Donald Trump ask Ukrainian President Vladimir Zelensky to investigate the Bidens. To hear their fascinating discussion, search for Politics Weekly America, wherever you get your podcasts and subscribe. And that's it for today. The producer was Madeleine Finley, the sound design was by Rudy Zagaldo, and the executive producer was Max Sanderson. We'll be back on Thursday. See you then. This is The Guardian.